{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Dashboards\n",
    "\n",
    "We use Callum McDougall's `sae_viz` library for generating feature dashboards. \n",
    "\n",
    "We've written a runner that will wrap Callum's code and log artefacts to wandb / pick-up where it left off if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import webbrowser\n",
    "import os\n",
    "import sys\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sae_vis.model_fns import AutoEncoder, AutoEncoderConfig\n",
    "from sae_vis.utils_fns import get_device\n",
    "from sae_analysis.dashboard_runner import DashboardRunner\n",
    "\n",
    "device = get_device()\n",
    "print(device)\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 8\n",
    "REPO_ID = \"jbloom/GPT2-Small-SAEs\"\n",
    "FILENAME = f\"final_sparse_autoencoder_gpt2-small_blocks.{layer}.hook_resid_pre_24576.pt\"\n",
    "path = hf_hub_download(repo_id=REPO_ID, filename=FILENAME)\n",
    "\n",
    "obj = torch.load(path, map_location=device)\n",
    "state_dict = obj[\"state_dict\"]\n",
    "assert set(state_dict.keys()) == {\"W_enc\", \"b_enc\", \"W_dec\", \"b_dec\"}\n",
    "\n",
    "\n",
    "# Since Callum's library has it's own autoencoder class, it's important to check\n",
    "# that we don't diverge from it in the future. For now, it should be fine\n",
    "# with the SAE above.\n",
    "cfg = AutoEncoderConfig(\n",
    "    d_in=obj[\"cfg\"].d_in,\n",
    "    dict_mult=obj[\"cfg\"].expansion_factor,\n",
    "    device=device,\n",
    ")\n",
    "gpt2_sae = AutoEncoder(cfg)\n",
    "gpt2_sae.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "runner = DashboardRunner(\n",
    "    sae_path=path,  # this will handle a local path.\n",
    "    dashboard_parent_folder=\"../feature_dashboards\",\n",
    "    init_session=True,\n",
    "    n_batches_to_sample_from=2\n",
    "    ** 12,  # sampling more batches helps us get a  more diverse text sample.\n",
    "    n_prompts_to_select=4096 * 6,  # more prompts are important for sparser features.\n",
    "    n_features_at_a_time=128,\n",
    "    max_batch_size=256,\n",
    "    buffer_tokens=8,\n",
    "    use_wandb=False,\n",
    "    continue_existing_dashboard=True,\n",
    ")\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_files = os.listdir(runner.dashboard_folder)\n",
    "# pick 3 random feature files and open them in the web browser\n",
    "for i in range(3):\n",
    "    feature_file = feature_files[i]\n",
    "    url = f\"file://{os.path.abspath(runner.dashboard_folder)}/{feature_file}\"\n",
    "    webbrowser.open(url)\n",
    "    print(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
