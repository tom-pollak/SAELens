{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Outputs for Neuronpedia Upload\n",
    "\n",
    "We use Callum McDougall's `sae_vis` library for generating JSON data to upload to Neuronpedia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL = \"gpt2-small\"\n",
    "LAYER = 8\n",
    "SOURCE = \"res-jb\"\n",
    "REPO_ID = \"jbloom/GPT2-Small-SAEs\"\n",
    "FILENAME = f\"final_sparse_autoencoder_gpt2-small_blocks.{LAYER}.hook_resid_pre_24576.pt\"\n",
    "\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sae_vis.model_fns import AutoEncoder, AutoEncoderConfig\n",
    "from sae_vis.utils_fns import get_device\n",
    "\n",
    "device = get_device()\n",
    "print(device)\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to non-dead features to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Joseph\n",
    "alive_indexes = [1, 99, 40, 5, 3, 999, 123, 345]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = hf_hub_download(repo_id=REPO_ID, filename=FILENAME)\n",
    "\n",
    "obj = torch.load(path, map_location=device)\n",
    "state_dict = obj[\"state_dict\"]\n",
    "assert set(state_dict.keys()) == {\"W_enc\", \"b_enc\", \"W_dec\", \"b_dec\"}\n",
    "\n",
    "# WARNING: If running on Mac, you need to change line 59 in model_fns to: self.to(\"mps\")\n",
    "cfg = AutoEncoderConfig(\n",
    "    d_in=obj[\"cfg\"].d_in,\n",
    "    dict_mult=obj[\"cfg\"].expansion_factor,\n",
    ")\n",
    "gpt2_sae = AutoEncoder(cfg)\n",
    "gpt2_sae.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save JSON to neuronpedia_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_analysis.neuronpedia_runner import NeuronpediaRunner\n",
    "\n",
    "NP_OUTPUT_FOLDER = \"../neuronpedia_outputs\"\n",
    "\n",
    "runner = NeuronpediaRunner(\n",
    "    sae_path=path,\n",
    "    neuronpedia_parent_folder=NP_OUTPUT_FOLDER,\n",
    "    init_session=True,\n",
    "    n_batches_to_sample_from=2 ** 12,\n",
    "    n_prompts_to_select=4096 * 6,\n",
    "    n_features_at_a_time=256,\n",
    "    buffer_tokens=8,\n",
    "    alive_indexes=alive_indexes,\n",
    ")\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Neuronpedia\n",
    "#### This currently only works if you have admin access to the Neuronpedia database via localhost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers that fix weird NaN stuff\n",
    "from decimal import Decimal\n",
    "from typing import Any\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "folder_path = runner.neuronpedia_folder\n",
    "\n",
    "def nanToNeg999(obj: Any) -> Any:\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: nanToNeg999(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [nanToNeg999(v) for v in obj]\n",
    "    elif (isinstance(obj, float) or isinstance(obj, Decimal)) and math.isnan(obj):\n",
    "        return -999\n",
    "    return obj\n",
    "\n",
    "\n",
    "class NanConverter(json.JSONEncoder):\n",
    "    def encode(self, o: Any, *args: Any, **kwargs: Any):\n",
    "        return super().encode(nanToNeg999(o), *args, **kwargs)\n",
    "\n",
    "# Server info\n",
    "host = \"http://localhost:3000\"\n",
    "sourceName = str(LAYER) + \"-\" + SOURCE\n",
    "\n",
    "# Upload alive features\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.startswith(\"batch-\") and file_name.endswith(\".json\"):\n",
    "        print(\"Uploading file: \" + file_name)\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        f = open(file_path, \"r\")\n",
    "        data = json.load(f)\n",
    "\n",
    "        # Replace NaNs\n",
    "        data_fixed = json.dumps(data, cls=NanConverter)\n",
    "        data = json.loads(data_fixed)\n",
    "\n",
    "        url = host + \"/api/internal/upload-features\"\n",
    "        resp = requests.post(\n",
    "            url,\n",
    "            json={\n",
    "                \"modelId\": MODEL,\n",
    "                \"layer\": sourceName,\n",
    "                \"features\": data,\n",
    "            },\n",
    "        )\n",
    "\n",
    "# Upload dead features (just makes blanks features)\n",
    "# We want this for completeness\n",
    "dead_path = os.path.join(folder_path, \"dead.json\")\n",
    "f = open(dead_path, \"r\")\n",
    "data = json.load(f)\n",
    "dead_indexes = data[\"dead_indexes\"]\n",
    "url = host + \"/api/internal/upload-dead-features\"\n",
    "resp = requests.post(\n",
    "    url,\n",
    "    json={\n",
    "        \"modelId\": MODEL,\n",
    "        \"layer\": sourceName,\n",
    "        \"deadIndexes\": dead_indexes,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Automatically validate the uploaded data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
