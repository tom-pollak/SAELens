{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Day 1\n",
    "\n",
    "Main goals:\n",
    "- Get working on toy models of superpos\n",
    "\n",
    "Tasks:\n",
    "- runner\n",
    "- set \n",
    "- train loop\n",
    "- wandb\n",
    "- dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-2l into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf43286e9194744b2ed4d30bec06275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([524288, 512])\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformer_lens import HookedTransformer\n",
    "from sae_training.lm_datasets import preprocess_tokenized_dataset\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "import einops\n",
    "import os\n",
    "from transformer_lens import HookedTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from importlib import reload\n",
    "from sae_training import activations_buffer\n",
    "\n",
    "reload(activations_buffer)\n",
    "\n",
    "cfg = {\n",
    "    \"d_in\": 512,\n",
    "    \"batch_size\": 256,\n",
    "    \"seq_len\": 128,\n",
    "    \"device\": \"cuda\",\n",
    "    \"act_name\": \"blocks.0.hook_mlp_out\",\n",
    "    \"n_batches_in_buffer\": 16,\n",
    "    \"dtype\": torch.float32,\n",
    "}\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\"gelu-2l\")\n",
    "data_loader_buffer = activations_buffer.DataLoaderBuffer(\n",
    "    cfg, model, data_path=\"NeelNanda/c4-code-tokenized-2b\"\n",
    ")\n",
    "# batch_tokens = data_loader_buffer.get_batch_tokens()\n",
    "# activations = data_loader_buffer.get_activations(batch_tokens)\n",
    "# print(activations.shape)\n",
    "\n",
    "buffer = data_loader_buffer.refill_buffer()\n",
    "print(buffer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refill:   0%|          | 0/1 [47:23<?, ?it/s]\n",
      "generate activations:   0%|          | 0/11 [24:03<?, ?it/s]\n",
      "generate activations:   0%|          | 0/11 [23:28<?, ?it/s]\n",
      "generate activations:   0%|          | 0/11 [22:54<?, ?it/s]\n",
      "generate activations:   0%|          | 0/11 [22:38<?, ?it/s]\n",
      "generate activations:   0%|          | 0/11 [22:06<?, ?it/s]\n",
      "generate activations:   0%|          | 0/11 [21:47<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/paperspace/mats_sae_training/dev.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.83.13.90/home/paperspace/mats_sae_training/dev.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(buffer, batch_size\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.83.13.90/home/paperspace/mats_sae_training/dev.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B172.83.13.90/home/paperspace/mats_sae_training/dev.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(dataloader))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.83.13.90/home/paperspace/mats_sae_training/dev.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(item\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/mats_sae_training/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/mats_sae_training/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n",
      "File \u001b[0;32m~/miniconda3/envs/mats_sae_training/lib/python3.11/site-packages/torch/utils/data/dataloader.py:620\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_index\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 620\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sampler_iter)\n",
      "File \u001b[0;32m~/miniconda3/envs/mats_sae_training/lib/python3.11/site-packages/torch/utils/data/sampler.py:282\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m batch \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\n\u001b[1;32m    281\u001b[0m idx_in_batch \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 282\u001b[0m \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msampler:\n\u001b[1;32m    283\u001b[0m     batch[idx_in_batch] \u001b[39m=\u001b[39;49m idx\n\u001b[1;32m    284\u001b[0m     idx_in_batch \u001b[39m+\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mats_sae_training/lib/python3.11/site-packages/torch/utils/data/sampler.py:164\u001b[0m, in \u001b[0;36mRandomSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n):\n\u001b[0;32m--> 164\u001b[0m         \u001b[39myield from\u001b[39;00m torch\u001b[39m.\u001b[39;49mrandperm(n, generator\u001b[39m=\u001b[39;49mgenerator)\u001b[39m.\u001b[39;49mtolist()\n\u001b[1;32m    165\u001b[0m     \u001b[39myield from\u001b[39;00m torch\u001b[39m.\u001b[39mrandperm(n, generator\u001b[39m=\u001b[39mgenerator)\u001b[39m.\u001b[39mtolist()[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m%\u001b[39m n]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(buffer, batch_size=4096, shuffle=True)\n",
    "\n",
    "while True:\n",
    "    item = next(iter(dataloader))\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from functools import partial\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\"gelu-2l\")\n",
    "hook_point = \"blocks.0.hook_mlp_out\"\n",
    "x = torch.stack(item['input_ids'],dim =1)\n",
    "\n",
    "activations = list()\n",
    "def hook_store_activation(x, hook):\n",
    "    activations.append(x)\n",
    "    return x \n",
    "\n",
    "hook_func = partial(hook_store_activation)\n",
    "_ = model.run_with_hooks(\n",
    "    x , fwd_hooks=\n",
    "    [(hook_point, hook_func)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "seq_len = 128\n",
    "\n",
    "batch_tokens = get_batch_tokens(\n",
    "    lm=model,\n",
    "    dataset=iter_dataset,\n",
    "    seq_len=seq_len,\n",
    "    batch_size=batch_size,\n",
    "    pretokenized=True,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "refill_buffer = False\n",
    "batch_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 512])\n"
     ]
    }
   ],
   "source": [
    "activations = model.run_with_cache(\n",
    "    batch_tokens,\n",
    "    names_filter=act_name,\n",
    ")[1][act_name]\n",
    "\n",
    "print(activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refill_iterator = range(0, seq_len, batch_size)\n",
    "total_size = len(refill_iterator) * batch_size * seq_len + buffer.shape[0]\n",
    "refill_iterator = tqdm(refill_iterator, desc=\"Refill\")\n",
    "\n",
    "# Initialize empty tensor buffer of the maximum required size\n",
    "new_buffer = torch.zeros(total_size, *buffer.shape[1:], dtype=buffer.dtype, device=cfg[\"buffer_device\"])\n",
    "\n",
    "# Fill existing buffer\n",
    "new_buffer[:buffer.shape[0]] = buffer\n",
    "\n",
    "# Insert activations directly into pre-allocated buffer\n",
    "insert_idx = buffer.shape[0]\n",
    "for refill_batch_idx_start in refill_iterator:\n",
    "    refill_batch_tokens = batch_tokens[refill_batch_idx_start:refill_batch_idx_start + cfg[\"batch_size\"]]\n",
    "    new_buffer[insert_idx:insert_idx + refill_batch_tokens.numel()] = get_activations(\n",
    "        lm=lm,\n",
    "        cfg=cfg,\n",
    "        batch_tokens=refill_batch_tokens,\n",
    "        act_name=cfg[\"act_name\"],\n",
    "    ).to(cfg[\"buffer_device\"])\n",
    "    insert_idx += refill_batch_tokens.numel()\n",
    "\n",
    "buffer = new_buffer[:insert_idx]\n",
    "buffer = buffer[torch.randperm(buffer.shape[0])]\n",
    "print(\"... done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if refill_buffer:\n",
    "    print(\"Refilling buffer; time elapsed\", time.time()-start_time, \"...\")\n",
    "    if cfg[\"testing\"] and step_idx > 100:\n",
    "        raise Exception(\"We have finished iterating\")\n",
    "        # return\n",
    "\n",
    "    # We need to refill the buffer\n",
    "    # We do a similar thing when Anthropic resampling\n",
    "    refill_iterator = range(0, batch_tokens.shape[0], cfg[\"batch_size\"])\n",
    "    total_size = len(refill_iterator) * cfg[\"batch_size\"] * cfg[\"seq_len\"] + buffer.shape[0]\n",
    "    if cfg[\"testing\"]:\n",
    "        refill_iterator = tqdm(refill_iterator, desc=\"Refill\")\n",
    "\n",
    "    # Initialize empty tensor buffer of the maximum required size\n",
    "    new_buffer = torch.zeros(total_size, *buffer.shape[1:], dtype=buffer.dtype, device=cfg[\"buffer_device\"])\n",
    "\n",
    "    # Fill existing buffer\n",
    "    new_buffer[:buffer.shape[0]] = buffer\n",
    "\n",
    "    # Insert activations directly into pre-allocated buffer\n",
    "    insert_idx = buffer.shape[0]\n",
    "    for refill_batch_idx_start in refill_iterator:\n",
    "        refill_batch_tokens = batch_tokens[refill_batch_idx_start:refill_batch_idx_start + cfg[\"batch_size\"]]\n",
    "        new_buffer[insert_idx:insert_idx + refill_batch_tokens.numel()] = get_activations(\n",
    "            lm=lm,\n",
    "            cfg=cfg,\n",
    "            batch_tokens=refill_batch_tokens,\n",
    "            act_name=cfg[\"act_name\"],\n",
    "        ).to(cfg[\"buffer_device\"])\n",
    "        insert_idx += refill_batch_tokens.numel()\n",
    "\n",
    "    # Truncate unused space in new_buffer\n",
    "    buffer = new_buffer[:insert_idx]\n",
    "\n",
    "    assert cfg[\"activation_training_order\"] == \"shuffled\"\n",
    "    # Shuffle buffer\n",
    "    buffer = buffer[torch.randperm(buffer.shape[0])]\n",
    "    print(\"... done.\")\n",
    "\n",
    "# Pop off the end of the buffer\n",
    "mlp_post_acts = buffer[-sae_batch_size:].to(cfg[\"device\"])\n",
    "buffer = buffer[:-sae_batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if refill_buffer:\n",
    "print(\"Refilling buffer; time elapsed\", time.time()-start_time, \"...\")\n",
    "if cfg[\"testing\"] and step_idx > 100:\n",
    "    raise Exception(\"We have finished iterating\")\n",
    "    # return\n",
    "\n",
    "# We need to refill the buffer\n",
    "# We do a similar thing when Anthropic resampling\n",
    "refill_iterator = range(0, batch_tokens.shape[0], cfg[\"batch_size\"])\n",
    "total_size = len(refill_iterator) * cfg[\"batch_size\"] * cfg[\"seq_len\"] + buffer.shape[0]\n",
    "if cfg[\"testing\"]:\n",
    "    refill_iterator = tqdm(refill_iterator, desc=\"Refill\")\n",
    "\n",
    "# Initialize empty tensor buffer of the maximum required size\n",
    "new_buffer = torch.zeros(total_size, *buffer.shape[1:], dtype=buffer.dtype, device=cfg[\"buffer_device\"])\n",
    "\n",
    "# Fill existing buffer\n",
    "new_buffer[:buffer.shape[0]] = buffer\n",
    "\n",
    "# Insert activations directly into pre-allocated buffer\n",
    "insert_idx = buffer.shape[0]\n",
    "for refill_batch_idx_start in refill_iterator:\n",
    "    refill_batch_tokens = batch_tokens[refill_batch_idx_start:refill_batch_idx_start + cfg[\"batch_size\"]]\n",
    "    new_buffer[insert_idx:insert_idx + refill_batch_tokens.numel()] = get_activations(\n",
    "        lm=lm,\n",
    "        cfg=cfg,\n",
    "        batch_tokens=refill_batch_tokens,\n",
    "        act_name=cfg[\"act_name\"],\n",
    "    ).to(cfg[\"buffer_device\"])\n",
    "    insert_idx += refill_batch_tokens.numel()\n",
    "\n",
    "# Truncate unused space in new_buffer\n",
    "buffer = new_buffer[:insert_idx]\n",
    "\n",
    "assert cfg[\"activation_training_order\"] == \"shuffled\"\n",
    "# Shuffle buffer\n",
    "buffer = buffer[torch.randperm(buffer.shape[0])]\n",
    "print(\"... done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [04:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/paperspace/mats_sae_training/dev.ipynb Cell 14\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.83.13.90/home/paperspace/mats_sae_training/dev.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     token_ids \u001b[39m=\u001b[39m  [\u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(dataset))[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.83.13.90/home/paperspace/mats_sae_training/dev.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     next_input_batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(token_ids, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.83.13.90/home/paperspace/mats_sae_training/dev.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     activations \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mrun_with_cache(\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B172.83.13.90/home/paperspace/mats_sae_training/dev.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         batch_tokens,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.83.13.90/home/paperspace/mats_sae_training/dev.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m         names_filter\u001b[39m=\u001b[39mact_name,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.83.13.90/home/paperspace/mats_sae_training/dev.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     )[\u001b[39m1\u001b[39m][act_name]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.83.13.90/home/paperspace/mats_sae_training/dev.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     activations_list\u001b[39m.\u001b[39mappend(activations)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.83.13.90/home/paperspace/mats_sae_training/dev.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m activations \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(activations_list, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "act_name = \"blocks.0.hook_mlp_out\"\n",
    "import torch\n",
    "activations_list = list()\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(10)):\n",
    "    token_ids =  [\n",
    "        torch.Tensor(next(iter(dataset))['input_ids'], dtype=Long) for _ in range(4)]\n",
    "    next_input_batch = torch.stack(token_ids, dim=1)\n",
    "    activations = model.run_with_cache(\n",
    "        batch_tokens,\n",
    "        names_filter=act_name,\n",
    "    )[1][act_name]\n",
    "    \n",
    "    activations_list.append(activations)\n",
    "    \n",
    "activations = torch.cat(activations_list, dim=0)\n",
    "print(activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate \n",
    "\n",
    "activations_store = list()\n",
    "def hook_store_activation(x, hook):\n",
    "    activations_store.append(x)\n",
    "    return x\n",
    "\n",
    "for i in range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_index = self.chunk_index * self.num_batches_per_chunk * self.batch_size\n",
    "end_index = start_index + self.num_batches_per_chunk * self.batch_size\n",
    "chunk = data[\"tokens\"][start_index:end_index]\n",
    "\n",
    "# Process the chunk\n",
    "chunk = einops.rearrange(chunk, \"batch (x seq_len) -> (batch x) seq_len\", x=8, seq_len=128)\n",
    "chunk[:, 0] = self.model.tokenizer.bos_token_id\n",
    "chunk = chunk[torch.randperm(chunk.shape[0])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
