{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_training.config import LanguageModelSAERunnerConfig\n",
    "from sae_training.utils import LMSparseAutoencoderSessionloader\n",
    "\n",
    "import torch \n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    n_batches_in_buffer=25,\n",
    "    store_batch_size=512,\n",
    "    context_size=128)\n",
    "\n",
    "path =\"artifacts/sparse_autoencoder_gelu-2l_blocks.0.hook_mlp_out_32768:v7/final_sparse_autoencoder_gelu-2l_blocks.0.hook_mlp_out_32768.pt\"\n",
    "model, sparse_autoencoder, activations_loader = LMSparseAutoencoderSessionloader.load_session_from_pretrained(\n",
    "    path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_batch = activations_loader.next_batch()\n",
    "activation_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_out, feature_acts, loss, mse_loss, l1_loss = sparse_autoencoder(activation_batch)\n",
    "print(sae_out.shape)\n",
    "print(feature_acts.shape)\n",
    "print(loss)\n",
    "print(mse_loss)\n",
    "print(l1_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(feature_acts > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = (feature_acts > 0).float().sum(0).mean()\n",
    "l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(feature_acts > 0).float().sum(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(feature_acts > 0).float().sum(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_training.train_sae_on_language_model import get_recons_loss\n",
    "\n",
    "score, loss, recons_loss, zero_abl_loss = get_recons_loss(\n",
    "    sparse_autoencoder, model, activations_loader, num_batches=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_abl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = activations_loader.ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from functools import partial\n",
    "batch_tokens = activations_loader.get_batch_tokens()\n",
    "\n",
    "\n",
    "def replacement_hook(mlp_post, hook, encoder):\n",
    "    mlp_post_reconstr = encoder(mlp_post)[0]\n",
    "    return mlp_post_reconstr\n",
    "\n",
    "\n",
    "def mean_ablate_hook(mlp_post, hook):\n",
    "    mlp_post[:] = mlp_post.mean([0, 1])\n",
    "    return mlp_post\n",
    "\n",
    "\n",
    "def zero_ablate_hook(mlp_post, hook):\n",
    "    mlp_post[:] = 0.0\n",
    "    return mlp_post\n",
    "\n",
    "hook_point= sparse_autoencoder.cfg.hook_point\n",
    "\n",
    "logits = model.run_with_hooks(\n",
    "            batch_tokens,\n",
    "            fwd_hooks=[(hook_point, partial(replacement_hook, encoder=sparse_autoencoder))],\n",
    "        )\n",
    "\n",
    "per_token_loss = model.loss_fn(logits, batch_tokens, True).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(batch_tokens)\n",
    "\n",
    "per_token_loss_original = model.loss_fn(logits, batch_tokens, True).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from plotly import express as px\n",
    "reload(px)\n",
    "\n",
    "\n",
    "fig = px.histogram(per_token_loss.flatten())\n",
    "fig.write_image(\"image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tokenizer.decode(batch_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, cache = model.run_with_cache(batch_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[hook_point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, feature_acts, loss, mse_loss, l1_loss = sparse_autoencoder(cache[hook_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.imshow(per_token_loss, color_continuous_midpoint=0, color_continuous_scale=\"RdBu\")\n",
    "fig.write_image(\"image1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.imshow((feature_acts > 0)[:,1:].sum(-1).detach().cpu().numpy(), color_continuous_midpoint=0, color_continuous_scale=\"RdBu\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tokenizer.batch_decode(batch_tokens[:,1:].flatten())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    x = (feature_acts > 0)[:,1:].sum(-1).flatten().detach().cpu().numpy(),\n",
    "    y = per_token_loss_original.flatten() - per_token_loss.flatten(),\n",
    "    marginal_x=\"histogram\",\n",
    "    marginal_y=\"histogram\",\n",
    "    labels = {\n",
    "        \"x\": \"Number of features that fired\", \"y\": \"Per-token loss\"\n",
    "    },\n",
    "    hover_data=[model.tokenizer.batch_decode(batch_tokens[:,1:].flatten())],\n",
    "    color= torch.tensor([range(1,128) for i in range(32)]).flatten(),\n",
    "    log_x=True,\n",
    "    log_y=True,\n",
    "    opacity=0.5,\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    x = (feature_acts > 0)[:,1:].sum(-1).flatten().detach().cpu().numpy(),\n",
    "    y = per_token_loss.flatten(),\n",
    "    marginal_x=\"histogram\",\n",
    "    marginal_y=\"histogram\",\n",
    "    labels = {\n",
    "        \"x\": \"Number of features that fired\", \"y\": \"Per-token loss\"\n",
    "    },\n",
    "    hover_data=[model.tokenizer.batch_decode(batch_tokens[:,1:].flatten())],\n",
    "    color= torch.tensor([range(1,128) for i in range(32)]).flatten(),\n",
    "    log_x=True,\n",
    "    opacity=0.5,\n",
    ")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([range(1,128) for i in range(32)]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tokenizer.batch_decode(batch_tokens.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
