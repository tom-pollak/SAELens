{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythia 70 M "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Find a Next Token Head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from importlib import reload\n",
    "from tqdm import tqdm\n",
    "\n",
    "import joseph\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "\n",
    "reload(joseph.analysis)\n",
    "reload(joseph.visualisation)\n",
    "reload(joseph.utils)\n",
    "reload(joseph.data)\n",
    "\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "# turn torch grad tracking off\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('jbloom/mats_sae_training_gpt2_small_hook_q_L4H11/sparse_autoencoder_gpt2-small_blocks.4.attn.hook_q_512:v4', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    # \"tiny-stories-2L-33M\",\n",
    "    # \"attn-only-2l\",\n",
    "    # center_unembed=True,\n",
    "    # center_writing_weights=True,\n",
    "    # fold_ln=True,\n",
    "    # refactor_factored_attn_matrices=True,\n",
    ")\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)\n",
    "\n",
    "\n",
    "\n",
    "# path = \"./artifacts/sparse_autoencoder_gpt2-small_blocks.4.attn.hook_q_512:v4/500002816_sparse_autoencoder_gpt2-small_blocks.4.attn.hook_q_512.pt\"\n",
    "# path = \"../checkpoints/4kydzgys/300003328_sparse_autoencoder_gpt2-small_blocks.4.attn.hook_q_2048.pt\"\n",
    "# path = \"../checkpoints/lsl84wm6/750002176_sparse_autoencoder_gpt2-small_blocks.4.attn.hook_q_4096.pt\"\n",
    "path = \"../checkpoints/lsl84wm6/final_sparse_autoencoder_gpt2-small_blocks.4.attn.hook_q_4096.pt\"\n",
    "sparse_autoencoder = SparseAutoencoder.load_from_pretrained(path)\n",
    "\n",
    "print(sparse_autoencoder.cfg)\n",
    "\n",
    "\n",
    "# sanity check\n",
    "text = \"Many important transition points in the history of science have been moments when science 'zoomed in.' At these points, we develop a visualization or tool that allows us to see the world in a new level of detail, and a new field of science develops to study the world through this lens.\"\n",
    "model(text, return_type=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test on individual prompt (random repeating tokens)\n",
    "random_tokens, random_token_groups = generate_random_token_prompt(model, n_random_tokens=16, n_repeat_tokens=2)\n",
    "prompt = model.to_string(random_tokens)\n",
    "print(prompt)\n",
    "\n",
    "(logits, loss), cache = model.run_with_cache(prompt, return_type = \"both\", loss_per_token = True)\n",
    "px.line(loss.squeeze().detach().cpu().numpy()).show()\n",
    "\n",
    "from transformer_lens.head_detector import *\n",
    "\n",
    "model.to(\"cpu\")\n",
    "pattern = get_previous_token_head_detection_pattern(model.to_tokens(prompt))\n",
    "pattern = pattern.to(\"cpu\")\n",
    "px.imshow(detect_head(model, prompt, pattern), title=\"Previous token head detection\").show()\n",
    "# pattern = get_duplicate_token_head_detection_pattern(model.to_tokens(prompt).to(\"cpu\"))\n",
    "# pattern = pattern.to(\"cpu\")\n",
    "# px.imshow(detect_head(model, prompt, pattern), title=\"Duplicate token head detection\").show()\n",
    "# pattern = get_induction_head_detection_pattern(model.to_tokens(prompt).to(\"cpu\"))\n",
    "# pattern = pattern.to(\"cpu\")\n",
    "# px.imshow(detect_head(model, prompt, pattern), title=\"Duplicate token head detection\").show()\n",
    "model = model.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    cache[\"blocks.4.attn.hook_pattern\"][0].detach().cpu(),\n",
    "    facet_col=0,\n",
    "    facet_col_wrap=8,\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tokens, random_token_groups = generate_random_token_prompt(model, n_random_tokens=80, n_repeat_tokens=1)\n",
    "prompt = model.to_string(random_tokens)\n",
    "token_df, original_cache, cache_reconstructed_query, feature_acts = eval_prompt([prompt], model, sparse_autoencoder)\n",
    "print(token_df.columns)\n",
    "filter_cols = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\"]\n",
    "token_df[filter_cols].tail(10).style.background_gradient(\n",
    "    subset=[\"loss_diff\", \"mse_loss\",\"explained_variance\", \"num_active_features\", \"kl_divergence\"],\n",
    "    cmap=\"coolwarm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD_IDX = sparse_autoencoder.cfg.hook_point_head_index\n",
    "LAYER_IDX = sparse_autoencoder.cfg.hook_point_layer\n",
    "patterns_original = original_cache[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")\n",
    "patterns_original = original_cache[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_INTEREST = feature_acts.shape[0] - 9 # index from 0.\n",
    "\n",
    "# reload(joseph.visualisation)\n",
    "# from joseph.visualisation import *\n",
    "\n",
    "print(token_df[\"unique_token\"][POS_INTEREST]) # bos gone.\n",
    "plot_line_with_top_10_labels(feature_acts[POS_INTEREST], \"\", 10)\n",
    "\n",
    "# vals, inds = torch.topk(feature_acts[POS_INTEREST],5)\n",
    "\n",
    "# print(inds)\n",
    "# plot_attn_score_by_feature(model, sparse_autoencoder, inds, original_cache, token_df, pos_interest=POS_INTEREST, vals = vals)\n",
    "# plot_unembed_score_by_feature(model, sparse_autoencoder, inds, token_df, vals=vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis over Training Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_webtext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_token_list = []\n",
    "loss_list = []\n",
    "ablated_loss_list = []\n",
    "# data = get_webtext()\n",
    "\n",
    "NUM_PROMPTS = 10\n",
    "# MAX_PROMPT_LEN = 100\n",
    "# BATCH_SIZE = 10\n",
    "dataframe_list = []\n",
    "feature_acts_list = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(NUM_PROMPTS)):\n",
    "        \n",
    "        # Get Token Data\n",
    "        prompt = data[i]\n",
    "        # new_str = data[BATCH_SIZE * i: BATCH_SIZE * (i + 1)]\n",
    "        \n",
    "\n",
    "        token_df, _, _, feature_acts = eval_prompt(prompt, model, sparse_autoencoder)\n",
    "        feature_acts_list.append(feature_acts)\n",
    "        dataframe_list.append(token_df)\n",
    "        \n",
    "all_token_df = pd.concat(dataframe_list)\n",
    "all_token_df.reset_index(drop=True)\n",
    "all_token_features = torch.cat(feature_acts_list)\n",
    "\n",
    "print(all_token_df.shape)\n",
    "print(all_token_df.columns)\n",
    "all_token_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_mask = (all_token_df.pos.values < 128)\n",
    "all_token_df = all_token_df[all_token_df.pos < 128]\n",
    "all_token_features = all_token_features[torch.tensor(pos_mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_features.sum(dim=0).nonzero().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = (all_token_features > 0).float().mean(dim=0).detach().cpu()\n",
    "log_sparsity = torch.log10(sparsity)\n",
    "print((sparsity > 0).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(log_sparsity, nbins=100).show()\n",
    "px.strip(log_sparsity, hover_data=[[i for i in range(sparse_autoencoder.cfg.d_sae)]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_df.pos = all_token_df.pos.astype(str)\n",
    "# get some random features\n",
    "random_features = torch.randint(0, 1024, (3,))\n",
    "for feature in torch.tensor([235,702,1540]):\n",
    "    all_token_df[f\"feature_{feature}\"] = all_token_features[:,feature].detach().cpu()\n",
    "    feature_density = (all_token_df[f\"feature_{feature}\"] > 0).mean()\n",
    "    if feature_density > 0:\n",
    "        print(f\"Feature {feature} has density {feature_density}\")\n",
    "        px.scatter(\n",
    "            all_token_df,\n",
    "            x = \"pos\",\n",
    "            y = f\"feature_{feature}\",\n",
    "            color=\"pos\",\n",
    "            hover_data=[\"unique_token\", \"context\", \"label\"]\n",
    "            ).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 72\n",
    "mask = [i  % 128 == position  for i in range(all_token_df.shape[0])]\n",
    "scores = (all_token_features[mask, :]>0).float().mean(dim=0)\n",
    "vals, inds = torch.topk(scores, 10)\n",
    "all_token_df[mask].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_with_top_10_labels(scores, \"\", 10)\n",
    "# plot_line_with_top_10_labels(all_token_features[position,], \"\", 3)\n",
    "# plot_line_with_top_10_labels(all_token_features[position+128,], \"\", 3)\n",
    "# plot_line_with_top_10_labels(all_token_features[position+128*2,], \"\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_columns = [\"pos\", \"unique_token\", \"context\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\"]\n",
    "for feature in torch.tensor(inds):\n",
    "    all_token_df[f\"feature_{feature}\"] = all_token_features[:,feature].detach().cpu()\n",
    "    mean_activation = (all_token_df[f\"feature_{feature}\"] > 0).mean()\n",
    "    if mean_activation > 0.001:\n",
    "        print(feature.item(), (all_token_df[f\"feature_{feature}\"] > 0).mean()) # super super dense feature.\n",
    "        display(all_token_df.sort_values(f\"feature_{feature}\", ascending=False)[filter_columns + [f\"feature_{feature}\"]].head(5))\n",
    "    else:\n",
    "        print(f\"feature {feature.item()} is dead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_attn_sae_feature_removal(example_prompt, \n",
    "                                      example_prompt_answer, \n",
    "                                      model, \n",
    "                                      sparse_autoencoder,\n",
    "                                      features_to_remove=[0],\n",
    "                                      token_unembed_to_remove=[]):\n",
    "    \n",
    "    layer_index = sparse_autoencoder.cfg.hook_point_layer\n",
    "    head_index = sparse_autoencoder.cfg.hook_point_head_index\n",
    "    \n",
    "    example_prompt_tokens = model.to_tokens(example_prompt)\n",
    "    attn_df, original_cache, cache_reconstructed_query, feature_acts = eval_prompt([example_prompt], model, sparse_autoencoder)\n",
    "\n",
    "    original_acts = original_cache[sparse_autoencoder.cfg.hook_point]\n",
    "    print(original_acts.shape)\n",
    "    sae_out, feature_acts, loss, mse_loss, l1_loss = sparse_autoencoder(\n",
    "       original_acts[0,:,head_index]\n",
    "    )\n",
    "    \n",
    "\n",
    "    def remove_feature_hook(hook_in, hook, head = head_index, features_to_remove = features_to_remove):\n",
    "        for feature_to_remove in features_to_remove:\n",
    "            feature_dir = feature_acts[-1,feature_to_remove]*sparse_autoencoder.W_dec[feature_to_remove]\n",
    "            hook_in[:, :, head] -= feature_dir\n",
    "        return hook_in\n",
    "    \n",
    "    with model.hooks(fwd_hooks=[(sparse_autoencoder.cfg.hook_point, remove_feature_hook)]):\n",
    "        _, cache_removed_feature = model.run_with_cache(example_prompt_tokens, return_type=\"loss\", loss_per_token=True)\n",
    "        \n",
    "        \n",
    "    def replace_with_feature_hook(hook_in, hook, head = head_index, features_to_add = features_to_remove):\n",
    "        new_act = torch.zeros_like(hook_in[:, :, head])\n",
    "        for features_to_add in features_to_remove:\n",
    "            feature_dir = feature_acts[-1,features_to_add]*sparse_autoencoder.W_dec[features_to_add]\n",
    "            new_act += feature_dir\n",
    "        hook_in[:, :, head] = new_act\n",
    "        return hook_in\n",
    "    \n",
    "    with model.hooks(fwd_hooks=[(sparse_autoencoder.cfg.hook_point, replace_with_feature_hook)]):\n",
    "        _, cache_only_features = model.run_with_cache(example_prompt_tokens, return_type=\"loss\", loss_per_token=True)\n",
    "        \n",
    "\n",
    "    def remove_token_unembed_hook(hook_in, hook, head = head_index, token_unembed_to_remove = token_unembed_to_remove):\n",
    "        for token_id in token_unembed_to_remove:\n",
    "            unembed_dir = model.W_U[:, token_id] @ model.W_Q[LAYER_IDX,head_index]\n",
    "            unembed_dir_proj =  hook_in[:, :, head] @ unembed_dir.T\n",
    "            hook_in[:, :, head] -= unembed_dir_proj[:,:,None]*unembed_dir\n",
    "        return hook_in\n",
    "    \n",
    "    with model.hooks(fwd_hooks=[(sparse_autoencoder.cfg.hook_point, remove_token_unembed_hook)]):\n",
    "        _, cache_removed_token_unembed = model.run_with_cache(example_prompt_tokens, return_type=\"loss\", loss_per_token=True)\n",
    "\n",
    "    patterns = original_cache[f\"blocks.{layer_index}.attn.hook_pattern\"][0,head_index].detach().cpu()\n",
    "    attn_df = make_token_df(model, example_prompt_tokens)\n",
    "    # remove last row of attn df\n",
    "    attn_df[\"original_attn\"] = patterns[-1,]\n",
    "    patterns = cache_reconstructed_query[f\"blocks.{layer_index}.attn.hook_pattern\"][0,head_index].detach().cpu()\n",
    "    attn_df[\"reconstructed_attn\"] = patterns[-1,]\n",
    "    patterns = cache_removed_feature[f\"blocks.{layer_index}.attn.hook_pattern\"][0,head_index].detach().cpu()\n",
    "    attn_df[\"ablated_feature_attn\"] = patterns[-1,]\n",
    "    patterns = cache_only_features[f\"blocks.{layer_index}.attn.hook_pattern\"][0,head_index].detach().cpu()\n",
    "    attn_df[\"cache_only_features\"] = patterns[-1,]\n",
    "    patterns = cache_removed_token_unembed[f\"blocks.{layer_index}.attn.hook_pattern\"][0,head_index].detach().cpu()\n",
    "    attn_df[\"cache_removed_token_unembed\"] = patterns[-1,]\n",
    "    \n",
    "    if len(token_unembed_to_remove) > 0:\n",
    "        fig = px.line(attn_df, \n",
    "                    y=[\"original_attn\",\"reconstructed_attn\", \"ablated_feature_attn\", \"cache_only_features\", \"cache_removed_token_unembed\"],\n",
    "                    hover_name=\"str_tokens\", \n",
    "                    hover_data=[\"pos\", \"batch\", \"label\"], \n",
    "                    title=\"Original vs Reconstructed attention\")\n",
    "    else:\n",
    "        fig = px.line(attn_df, \n",
    "                    y=[\"original_attn\",\"reconstructed_attn\", \"ablated_feature_attn\", \"cache_only_features\"],\n",
    "                    hover_name=\"str_tokens\", \n",
    "                    hover_data=[\"pos\", \"batch\", \"label\"], \n",
    "                    title=\"Original vs Reconstructed attention\")\n",
    "    \n",
    "    # increase figure height\n",
    "    fig.update_layout(height=800)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "random_tokens, random_token_groups = generate_random_token_prompt(model, n_random_tokens=4, n_repeat_tokens=2)\n",
    "example_prompt = model.to_string(random_tokens[:-1])\n",
    "example_prompt_answer = model.to_string(random_tokens[:-1])\n",
    "attn_df, original_cache, cache_reconstructed_query, feature_acts = eval_prompt([example_prompt], model, sparse_autoencoder)\n",
    "attn_df.tail(2).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_original = original_cache[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "plot_attn(both_patterns.detach().cpu(), attn_df, title=\"Original and Reconstructed Attention Distribution\")\n",
    "\n",
    "POS_INTEREST = feature_acts.shape[0] - 1 # index from 0.\n",
    "print(attn_df[\"unique_token\"][POS_INTEREST]) # bos gone.\n",
    "plot_line_with_top_10_labels(feature_acts[POS_INTEREST], \"\", 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  673, 3252, 3218, 1518, 1344, 1185, 311\n",
    "test_get_attn_sae_feature_removal(\n",
    "    example_prompt, \n",
    "    example_prompt_answer, model, \n",
    "    sparse_autoencoder, features_to_remove=[673])\n",
    "\n",
    "\n",
    "# test_get_attn_sae_feature_removal(\n",
    "#     example_prompt, \n",
    "#     example_prompt_answer, model, \n",
    "#     sparse_autoencoder, features_to_remove=[1344])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directly Search for Positional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how can we automatically match features to positions?\n",
    "# for position in position:\n",
    "#     for feature in features: -> get recall and precision\n",
    "\n",
    "positions = list(range(128)) # for the first 10 positions\n",
    "features = list(range(sparse_autoencoder.cfg.d_sae)) # check all features\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "for position in tqdm(positions):\n",
    "    for feature in features:\n",
    "        mask = [i  % 128 == position  for i in range(all_token_df.shape[0])]\n",
    "        score = all_token_features[mask, feature].mean().item()\n",
    "        all_scores.append([position, feature, score])\n",
    "        \n",
    "        \n",
    "scores_df = pd.DataFrame(all_scores, columns=[\"pos\", \"feature\", \"score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top positiion for each feature\n",
    "# get the top score per feature (criteria: activates at that pos)\n",
    "top_feature_pos_scores_df = scores_df.groupby([\"feature\",\"pos\"]).score.mean().reset_index().sort_values(\"score\", ascending=False).groupby(\"feature\").head(1).sort_values(\"pos\")\n",
    "# then for each pos, get the features who's maximal top score is at that position (criteria: activates more than anything else)\n",
    "top_feature_pos_scores_df = top_feature_pos_scores_df.sort_values(\"score\", ascending=False).groupby(\"pos\").head(3).sort_values(\"pos\")\n",
    "top_feature_pos_scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = scores_df.pivot(index=\"pos\", columns=\"feature\", values=\"score\")\n",
    "print(tmp.shape)\n",
    "px.imshow(tmp, color_continuous_scale=\"RdBu_r\", title=\"Feature Scores by Position\").show()\n",
    "tmp = pd.DataFrame(\n",
    "    tmp.loc[:,top_feature_pos_scores_df.feature.values].values,\n",
    "    index = list(tmp.index.to_flat_index()),\n",
    "    columns = [str(i) for i in list(top_feature_pos_scores_df.feature)],\n",
    ")\n",
    "px.imshow(tmp.T, color_continuous_scale=\"RdBu_r\", title=\"Feature Scores by Position\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(tmp[[\"2674\"]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "px.line(tmp)\n",
    "# px.line(tmp / tmp.values.max(axis=0, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.line(tmp[[\"430\"]]).show()\n",
    "px.line(tmp[[\"1012\",\"241\",\"1703\", \"280\"]]).show()\n",
    "# px.line(tmp[[\"545\"]]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "\n",
    "def plot_cosine_similarity_heatmap(df, restricted_labels, reorder = False, title=\"Pairwise Cosine Similarity Heatmap\"):\n",
    "    data_array = df.to_numpy()\n",
    "    linkage = hierarchy.linkage(data_array)\n",
    "    dendrogram = hierarchy.dendrogram(\n",
    "        linkage, no_plot=True, color_threshold=-np.inf\n",
    "    )\n",
    "    if reorder:\n",
    "        reordered_ind = dendrogram[\"leaves\"]\n",
    "        # reorder df by ind\n",
    "        df = df.iloc[reordered_ind, reordered_ind]\n",
    "        # data_array = df.to_numpy()\n",
    "\n",
    "    # plot the cosine similarity matrix\n",
    "    fig  = px.imshow(\n",
    "            df.values,\n",
    "            color_continuous_scale=\"RdBu\",\n",
    "            color_continuous_midpoint=0.0,\n",
    "            labels={\"color\": \"Cosine Similarity\"},\n",
    "        )\n",
    "    fig.update_xaxes(\n",
    "        tickmode=\"array\",\n",
    "        tickvals=list(range(len(restricted_labels))),\n",
    "        ticktext=restricted_labels,\n",
    "        showgrid=False,\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        tickmode=\"array\",\n",
    "        tickvals=list(range(len(restricted_labels))),\n",
    "        ticktext=restricted_labels,\n",
    "        showgrid=False,\n",
    "    )\n",
    "\n",
    "    # don't show axes if there are more than 20 rows \n",
    "    if df.shape[0] > 20:\n",
    "        fig.update_xaxes(\n",
    "            visible=False,\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            visible=False,\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "feature_dirs = pd.DataFrame(sparse_autoencoder.W_dec.detach().cpu()).reset_index(drop=True).T.corr()\n",
    "plot_cosine_similarity_heatmap(feature_dirs, restricted_labels=[i for i in range(sparse_autoencoder.cfg.d_sae)], reorder =True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what about non-positional features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=11)\n",
    "tmp = top_feature_pos_scores_df.sort_values(\"score\", ascending=True).head(256)\n",
    "tmp[\"mean_activation\"] = tmp.feature.apply(lambda x: all_token_features[:,x].mean().item())\n",
    "clusterer.fit(tmp[[\"score\", \"mean_activation\"]])\n",
    "tmp[\"group\"] = [f\"group_{i}\" for i in clusterer.labels_]\n",
    "px.scatter(tmp, x=\"score\", y=\"mean_activation\", color=\"group\",\n",
    "           hover_data=[\"feature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_columns = [\"pos\", \"unique_token\", \"context\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\"]\n",
    "for feature in torch.tensor([9, 545, 42]):\n",
    "    all_token_df[f\"feature_{feature}\"] = all_token_features[:,feature].detach().cpu()\n",
    "    print(feature.item(), (all_token_df[f\"feature_{feature}\"] > 0).mean()) # super super dense feature.\n",
    "    display(all_token_df.sort_values(f\"feature_{feature}\", ascending=False)[filter_columns + [f\"feature_{feature}\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap \n",
    "import hdbscan\n",
    "\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=8,\n",
    "    min_dist=0.15,\n",
    "    n_components=2,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=4)\n",
    "\n",
    "\n",
    "ummap_result = reducer.fit_transform(feature_acts.T.detach().cpu())\n",
    "# ummap_result = reducer.fit_transform(sparse_autoencoder.W_dec.detach().cpu())\n",
    "clusterer.fit(ummap_result)\n",
    "print(clusterer.labels_)\n",
    "\n",
    "\n",
    "fig = px.scatter(\n",
    "        ummap_result, \n",
    "        x= 0,\n",
    "        y=1,\n",
    "        color=[str(i) for i in clusterer.labels_],\n",
    "        hover_data = [[f\"feature_{i}\" for i in range(sparse_autoencoder.cfg.d_sae)]],\n",
    "        opacity=0.5,\n",
    "        template=\"plotly\",\n",
    "    )\n",
    "\n",
    "# make points larger\n",
    "fig.update_traces(marker=dict(size=12))\n",
    "\n",
    "# make it wide and tall\n",
    "fig.update_layout(height=800, width=1200)\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pandas col width limit\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "groups = pd.DataFrame(ummap_result, columns=[\"x\",\"y\"])\n",
    "groups[\"group\"] = [f\"{i}\" for i in clusterer.labels_]\n",
    "groups[\"feature\"] = [f\"{i}\" for i in range(sparse_autoencoder.cfg.d_sae)]\n",
    "groups = groups[[\"feature\", \"group\", \"x\", \"y\"]]\n",
    "\n",
    "\n",
    "feature_group = \"41\"\n",
    "features = groups[groups.group == feature_group].feature.astype(int).values\n",
    "for feature in torch.tensor(features):\n",
    "    all_token_df[f\"feature_{feature}\"] = all_token_features[:,feature].detach().cpu()\n",
    "    mean_activation = (all_token_df[f\"feature_{feature}\"] > 0).mean()\n",
    "    if mean_activation > 0.001:\n",
    "        print(feature.item(), (all_token_df[f\"feature_{feature}\"] > 0).mean()) # super super dense feature.\n",
    "        display(all_token_df.sort_values(f\"feature_{feature}\", ascending=False)[filter_columns + [f\"feature_{feature}\"]].head(5))\n",
    "    else:\n",
    "        print(f\"feature {feature.item()} is dead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap \n",
    "import hdbscan\n",
    "\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=2,\n",
    "    min_dist=0.12,\n",
    "    n_components=2,\n",
    "    metric=\"euclidean\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5)\n",
    "\n",
    "\n",
    "ummap_result = reducer.fit_transform(sparse_autoencoder.W_dec.detach().cpu())\n",
    "clusterer.fit(ummap_result)\n",
    "# print(clusterer.labels_)\n",
    "\n",
    "\n",
    "fig = px.scatter(\n",
    "        ummap_result, \n",
    "        x= 0,\n",
    "        y=1,\n",
    "        color=[str(i) for i in clusterer.labels_],\n",
    "        hover_data = [[f\"feature_{i}\" for i in range(sparse_autoencoder.cfg.d_sae)]],\n",
    "        opacity=0.5,\n",
    "        template=\"plotly\",\n",
    "    )\n",
    "\n",
    "# make points larger\n",
    "fig.update_traces(marker=dict(size=12))\n",
    "\n",
    "# make it wide and tall\n",
    "fig.update_layout(height=800, width=1200)\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pandas col width limit\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "groups = pd.DataFrame(ummap_result, columns=[\"x\",\"y\"])\n",
    "groups[\"group\"] = [f\"{i}\" for i in clusterer.labels_]\n",
    "groups[\"feature\"] = [f\"{i}\" for i in range(sparse_autoencoder.cfg.d_sae)]\n",
    "groups = groups[[\"feature\", \"group\", \"x\", \"y\"]]\n",
    "\n",
    "\n",
    "feature_group = \"229\"\n",
    "features = groups[groups.group == feature_group].feature.astype(int).values\n",
    "for feature in torch.tensor(features):\n",
    "    all_token_df[f\"feature_{feature}\"] = all_token_features[:,feature].detach().cpu()\n",
    "    mean_activation = (all_token_df[f\"feature_{feature}\"] > 0).mean()\n",
    "    if mean_activation > 0.001:\n",
    "        print(feature.item(), (all_token_df[f\"feature_{feature}\"] > 0).mean()) # super super dense feature.\n",
    "        display(all_token_df.sort_values(f\"feature_{feature}\", ascending=False)[filter_columns + [f\"feature_{feature}\"]].head(5))\n",
    "    else:\n",
    "        print(f\"feature {feature.item()} is dead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
