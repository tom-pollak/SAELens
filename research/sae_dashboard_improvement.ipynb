{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAE Dashboard Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import joseph\n",
    "\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "reload(joseph.analysis)\n",
    "reload(joseph.visualisation)\n",
    "reload(joseph.utils)\n",
    "reload(joseph.data)\n",
    "\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "# turn torch grad tracking off\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "LAYER_IDX, HEAD_IDX = (10, 7)\n",
    "\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    # refactor_factored_attn_matrices=True,\n",
    ")\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)\n",
    "\n",
    "\n",
    "\n",
    "# path = \"checkpoints/ikig1wjm/final_sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_32768.pkl\"\n",
    "# path=\"../artifacts/sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_4096:v15/final_sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_4096.pkl\"#\n",
    "# path=\"../artifacts/sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_4096:v16/final_sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_4096.pkl\"\n",
    "# path=\"../artifacts/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_24576:v56/final_sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_24576.pkl\"\n",
    "# hacky solution to saved with cuda load on mps:\n",
    "# path = \"artifacts/sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_4096:v13/final_sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_4096.pkl\"\n",
    "# sparse_autoencoder = SparseAutoencoder.load_from_pretrained(path)\n",
    "\n",
    "\n",
    "from sae_training.sparse_autoencoder import SparseAutoencoder\n",
    "from sae_training.config import LanguageModelSAERunnerConfig\n",
    "\n",
    "# path = \"checkpoints/peu1onjp/132669440_sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_8192.pkl\"\n",
    "# path = \"checkpoints/g2zrx9ho/final_sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_8192.pkl\"\n",
    "path = \"artifacts/sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_65536:v28/1076002816_sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_65536.pkl\" \n",
    "\n",
    "\n",
    "with open(path, 'rb') as file:\n",
    "    state_dict = CPU_Unpickler(file).load()\n",
    "\n",
    "cfg = state_dict[\"cfg\"].__dict__\n",
    "print(cfg)\n",
    "cfg[\"total_training_tokens\"] = 5_000_000\n",
    "cfg[\"device\"] = \"mps\"\n",
    "cfg[\"hook_point_layer\"] = 10\n",
    "del cfg[\"d_sae\"]\n",
    "del cfg[\"tokens_per_buffer\"]\n",
    "cfg = LanguageModelSAERunnerConfig(**cfg)\n",
    "sparse_autoencoder = SparseAutoencoder(cfg)\n",
    "sparse_autoencoder.load_state_dict(state_dict[\"state_dict\"])\n",
    "del state_dict\n",
    "del cfg\n",
    "\n",
    "new_path = \"artifacts/sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_65536:v28/1076002816_sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_65536_mps.pt\"\n",
    "sparse_autoencoder.save_model(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sae_training.utils import LMSparseAutoencoderSessionloader\n",
    "model, sparse_autoencoder, activation_store = LMSparseAutoencoderSessionloader.load_session_from_pretrained(\n",
    "    new_path\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_in = activation_store.next_batch()\n",
    "sae_out, feature_acts, loss, mse_loss, l1_loss = sparse_autoencoder(sae_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacement_hook(mlp_post, hook, encoder):\n",
    "    mlp_post_reconstr = encoder(mlp_post)[0]\n",
    "    return mlp_post_reconstr\n",
    "hook_point = activation_store.cfg.hook_point\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_tokens = activation_store.get_batch_tokens()\n",
    "    _, cache = model.run_with_cache(batch_tokens, prepend_bos=False)\n",
    "    original_act = cache[sparse_autoencoder.cfg.hook_point][:,:,sparse_autoencoder.cfg.hook_point_head_index]\n",
    "    sae_out, feature_acts, loss, mse_loss, l1_loss = sparse_autoencoder(\n",
    "        original_act\n",
    "    )\n",
    "    # del cache\n",
    "    \n",
    "    # all round metrics\n",
    "    \n",
    "    original_act = cache[sparse_autoencoder.cfg.hook_point][:,:,sparse_autoencoder.cfg.hook_point_head_index]\n",
    "    per_token_l2_loss = (sae_out - original_act).pow(2).sum(dim=-1).squeeze()\n",
    "    total_variance = original_act.pow(2).sum(-1)\n",
    "    explained_variance = per_token_l2_loss/total_variance\n",
    "\n",
    "    print(\"explained variance mean:\", explained_variance.mean().item())\n",
    "    print(\"explained_variance std:\", explained_variance.std().item())\n",
    "    \n",
    "    \n",
    "    per_token_l2_loss = (sae_out - original_act).pow(2).sum(dim=-1).squeeze()\n",
    "    px.histogram(per_token_l2_loss.flatten().cpu().numpy()).show()\n",
    "    \n",
    "    l0 = (feature_acts > 0).float().sum(-1).detach()\n",
    "    print(\"average l0\", l0.mean().item())\n",
    "    print(\"l0 std\", l0.std().item())\n",
    "    # px.histogram(l0.flatten().cpu().numpy()).show()\n",
    "    \n",
    "    l2_norm = original_act.pow(2).sum(-1).sqrt()\n",
    "    print(\"l2 norm mean\", l2_norm.mean().item())\n",
    "    print(\"l2 norm std\", l2_norm.std().item())\n",
    "    px.histogram(l2_norm.flatten().cpu().numpy()).show()\n",
    "    px.line(l2_norm.mean(0).cpu().numpy(), title=\"l2 norm by position\").show()\n",
    "    \n",
    "    \n",
    "    # by position\n",
    "    px.line(l0.mean(0).cpu().numpy(), title=\"L0 by Position\").show()\n",
    "    px.line(per_token_l2_loss.mean(0).cpu().numpy(), title = \"MSE Loss by Position\").show()\n",
    "    px.scatter(\n",
    "        x = per_token_l2_loss.flatten().cpu().numpy(),\n",
    "        y = l0.flatten().cpu().numpy(),\n",
    "        color = np.arange(per_token_l2_loss.shape[1]).repeat(per_token_l2_loss.shape[0]),\n",
    "        opacity=0.5,\n",
    "        labels = {\"color\": \"position\", \"x\": \"MSE Loss\", \"y\": \"L0\"},\n",
    "        title = \"L0 vs MSE Loss\",\n",
    "        marginal_x=\"histogram\",\n",
    "        marginal_y=\"histogram\",\n",
    "    ).show()\n",
    "    \n",
    "    px.scatter(\n",
    "        x = l2_norm.flatten().cpu().numpy(),\n",
    "        y =  per_token_l2_loss.flatten().cpu().numpy(),\n",
    "        color = np.arange(per_token_l2_loss.shape[1]).repeat(per_token_l2_loss.shape[0]),\n",
    "        opacity=0.5,\n",
    "        labels={\"color\": \"position\", \"x\": \"L2 Norm\", \"y\": \"MSE Loss\"},\n",
    "        title = \"MSE Loss vs L2 Norm\",\n",
    "        marginal_x=\"histogram\",\n",
    "        marginal_y=\"histogram\",\n",
    "    ).show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming l2_norm is a 2D tensor with shape [num_samples, num_positions]\n",
    "mean_l2_norm = l2_norm.mean(0).cpu().numpy()\n",
    "std_l2_norm = l2_norm.std(0).cpu().numpy()\n",
    "num_samples = l2_norm.shape[0]\n",
    "\n",
    "# Calculate the standard error of the mean\n",
    "sem_l2_norm = std_l2_norm / np.sqrt(num_samples)\n",
    "\n",
    "# 95% confidence intervals\n",
    "ci = 1.96 * sem_l2_norm\n",
    "\n",
    "# Modify the line plot command to include error bars\n",
    "px.line(\n",
    "    y=mean_l2_norm, \n",
    "    error_y=ci, \n",
    "    title=\"l2 norm by position\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacement_hook(mlp_post, hook, encoder):\n",
    "    mlp_post_reconstr = encoder(mlp_post)[0]\n",
    "    return mlp_post_reconstr\n",
    "hook_point = activation_store.cfg.hook_point\n",
    "\n",
    "\n",
    "def mean_ablate_hook(mlp_post, hook):\n",
    "    mlp_post[:] = mlp_post.mean([0, 1])\n",
    "    return mlp_post\n",
    "\n",
    "\n",
    "def zero_ablate_hook(mlp_post, hook):\n",
    "    mlp_post[:] = 0.0\n",
    "    return mlp_post\n",
    "\n",
    "\n",
    "def kl_divergence_attention(y_true, y_pred):\n",
    "\n",
    "    # Compute log probabilities for KL divergence\n",
    "    log_y_true = torch.log2(y_true + 1e-10)\n",
    "    log_y_pred = torch.log2(y_pred + 1e-10)\n",
    "\n",
    "    return y_true * (log_y_true - log_y_pred)\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_tokens = activation_store.get_batch_tokens()\n",
    "    _, cache = model.run_with_cache(batch_tokens, prepend_bos=False)\n",
    "    original_act = cache[sparse_autoencoder.cfg.hook_point][:,:,sparse_autoencoder.cfg.hook_point_head_index]\n",
    "    sae_out, feature_acts, loss, mse_loss, l1_loss = sparse_autoencoder(\n",
    "        original_act\n",
    "    )\n",
    "\n",
    "    # get attn when using reconstructed activations\n",
    "    with model.hooks(fwd_hooks=[(hook_point, partial(replacement_hook, encoder=sparse_autoencoder))]):\n",
    "        _, new_cache = model.run_with_cache(batch_tokens)\n",
    "        \n",
    "    # get attn when using reconstructed activations\n",
    "    with model.hooks(fwd_hooks=[(hook_point, partial(replacement_hook, encoder=sparse_autoencoder))]):\n",
    "        _, zero_ablation_cache = model.run_with_cache(batch_tokens)\n",
    "\n",
    "\n",
    "    # get the attention scores\n",
    "\n",
    "    patterns_original = cache[utils.get_act_name(\"pattern\", LAYER_IDX)][:,HEAD_IDX].detach().cpu()\n",
    "    patterns_reconstructed = new_cache[utils.get_act_name(\"pattern\", LAYER_IDX)][:,HEAD_IDX].detach().cpu()\n",
    "    patterns_ablation = zero_ablation_cache[utils.get_act_name(\"pattern\", LAYER_IDX)][:,HEAD_IDX].detach().cpu()\n",
    "    \n",
    "    # show patterns before/after\n",
    "    px.imshow(patterns_original.numpy(), animation_frame = 0, title=\"original attn scores\", width=800, height=800,\n",
    "          color_continuous_midpoint=0, color_continuous_scale=\"RdBu\").show()\n",
    "    px.imshow(patterns_reconstructed.numpy(), animation_frame = 0, title=\"reconstructed attn scores\", width=800, height=800,\n",
    "            color_continuous_midpoint=0, color_continuous_scale=\"RdBu\").show()\n",
    "    \n",
    "    # get the average non-bos_attn_score\n",
    "    score_original = cache[utils.get_act_name(\"attn_scores\", LAYER_IDX)][:,HEAD_IDX].detach().cpu()\n",
    "    score_reconstructed = new_cache[utils.get_act_name(\"attn_scores\", LAYER_IDX)][:,HEAD_IDX].detach().cpu()\n",
    "    \n",
    "    print(patterns_original[:,:,1:,].mean().item())\n",
    "    print(patterns_reconstructed[:,:,1:].mean().item())\n",
    "    \n",
    "    # ratio\n",
    "    kl_result = kl_divergence_attention(patterns_original, patterns_reconstructed)\n",
    "    kl_result = kl_result.sum(dim=-1).numpy()\n",
    "    print(kl_result.mean().item())\n",
    "    # px.imshow(kl_result, title=\"KL Divergence\", width=800, height=800,\n",
    "    #       color_continuous_midpoint=0, color_continuous_scale=\"RdBu\").show()\n",
    "    px.histogram(kl_result.flatten()).show()\n",
    "    px.line(kl_result.mean(0), title=\"KL Divergence by Position\").show()\n",
    "    \n",
    "    kl_result = kl_divergence_attention(patterns_original, patterns_ablation)\n",
    "    kl_result = kl_result.sum(dim=-1).numpy()\n",
    "    print(kl_result.mean().item())\n",
    "    # px.imshow(kl_result, title=\"KL Divergence\", width=800, height=800,\n",
    "    #       color_continuous_midpoint=0, color_continuous_scale=\"RdBu\").show()\n",
    "    px.histogram(kl_result.flatten()).show()\n",
    "    px.line(kl_result.mean(0), title=\"KL Divergence by Position\").show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD_IDX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
