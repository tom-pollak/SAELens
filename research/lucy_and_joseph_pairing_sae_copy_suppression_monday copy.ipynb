{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuesday Analyze Hook Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import wandb\n",
    "import json\n",
    "import plotly.express as px\n",
    "from transformer_lens import utils\n",
    "from datasets import load_dataset\n",
    "from typing import  Dict\n",
    "from pathlib import Path\n",
    "\n",
    "from functools import partial\n",
    "sys.path.append(\"..\")\n",
    "from sae_training.utils import LMSparseAutoencoderSessionloader\n",
    "from sae_analysis.visualizer import data_fns, html_fns\n",
    "from sae_analysis.visualizer.data_fns import get_feature_data, FeatureData\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\" \n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "def imshow(x, **kwargs):\n",
    "    x_numpy = utils.to_numpy(x)\n",
    "    px.imshow(x_numpy, **kwargs).show()\n",
    "    \n",
    "    \n",
    "from sae_training.sparse_autoencoder import SparseAutoencoder\n",
    "# Load model from Huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# run = wandb.init()\n",
    "# artifact = run.use_artifact('jbloom/mats_sae_training_gpt2_small_hook_q/sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_4096:v16', type='model')\n",
    "# artifact_dir = artifact.download()\n",
    "\n",
    "\n",
    "# import wandb\n",
    "# run = wandb.init()\n",
    "# artifact = run.use_artifact('jbloom/mats_sae_training_gpt2_small_hook_q/sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_4096:v15', type='model')\n",
    "# artifact_dir = artifact.download()\n",
    "# run.finish()\n",
    "\n",
    "\n",
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('jbloom/mats_sae_training_gpt2_small/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_24576:v56', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load in Model\n",
    "# path=artifact_dir+\"/\"+os.listdir(artifact_dir)[0]\n",
    "# print(path)\n",
    "from sae_training.utils import LMSparseAutoencoderSessionloader\n",
    "from sae_training.config import LanguageModelSAERunnerConfig\n",
    "path=\"../artifacts/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_24576:v56/final_sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_24576.pkl\"\n",
    "# path=\"../artifacts/sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_4096:v16/final_sparse_autoencoder_gpt2-small_blocks.10.attn.hook_q_4096.pkl\"#.gz\"\n",
    "\n",
    "from sae_training.sparse_autoencoder import CPU_Unpickler\n",
    "with open(path, 'rb') as file:\n",
    "    state_dict = CPU_Unpickler(file).load()\n",
    "\n",
    "cfg = state_dict[\"cfg\"].__dict__\n",
    "cfg[\"device\"] = \"mps\"\n",
    "del cfg[\"d_sae\"]\n",
    "del cfg[\"tokens_per_buffer\"]\n",
    "from sae_training.sparse_autoencoder import SparseAutoencoder\n",
    "cfg = LanguageModelSAERunnerConfig(**cfg)\n",
    "sparse_autoencoder = SparseAutoencoder(cfg)\n",
    "sparse_autoencoder.load_state_dict(state_dict[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\")\n",
    "\n",
    "from sae_training.activations_store import ActivationsStore\n",
    "\n",
    "activations_loader = ActivationsStore(\n",
    "            cfg, model,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L0 Test and Reconstruction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch_tokens = activations_loader.get_batch_tokens()\n",
    "    print(batch_tokens.shape)\n",
    "    _, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
    "    activations =  cache[sparse_autoencoder.cfg.hook_point]\n",
    "    \n",
    "    sae_out, feature_acts, loss, mse_loss, l1_loss = sparse_autoencoder(\n",
    "        cache[sparse_autoencoder.cfg.hook_point]\n",
    "    )\n",
    "    # del cache\n",
    "    \n",
    "    l2_norms_of_input = torch.norm(activations[:,1:], dim=-1)\n",
    "    l2_norms_of_sae_out = torch.norm(sae_out[:,1:], dim=-1)\n",
    "    print(\"l2_norms_of_input\", l2_norms_of_input.mean().item())\n",
    "    print(\"l2_norms_of_sae_out\", l2_norms_of_sae_out.mean().item())\n",
    "    \n",
    "    l0 = (feature_acts > 0).float().sum(-1).detach()\n",
    "    print(\"average l0\", l0.mean().item())\n",
    "    px.histogram(l0.flatten().cpu().numpy()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monday Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cache.apply_ln_to_stack(x_reconstruct[0],layer=10).mean()\n",
    "# example_batch = torch.randint(0,32,(1,)).item(); example_position = torch.randint(0, 10, (1,)).item()\n",
    "# print(example_batch, example_position)\n",
    "# print(model.to_str_tokens(batch_tokens[example_batch])[max(example_position-5,0):min(example_position+3,128)])\n",
    "# px.line(feature_acts[example_batch,example_position].cpu().numpy()).show()\n",
    "# lnd_activations = cache.apply_ln_to_stack(activations, layer=10)\n",
    "# _, feature_acts_after_ln, _, _, _ = sparse_autoencoder(\n",
    "#         lnd_activations\n",
    "#     )\n",
    "# px.line(feature_acts_after_ln[example_batch,example_position].cpu().numpy()).show()\n",
    "# vals, inds = torch.topk(feature_acts[example_batch,example_position].detach(), 10)\n",
    "# px.bar(\n",
    "#     x=utils.to_numpy(vals),\n",
    "#     y=[str(i.item()) for i in inds],\n",
    "#     orientation=\"h\",\n",
    "# ).show()\n",
    "# utils.test_prompt(\n",
    "#     prompt = model.to_string(batch_tokens[example_batch][1:example_position+1]),\n",
    "#     answer = model.to_string(batch_tokens[example_batch][example_position+1]),\n",
    "#     model = model)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def plot_feature_unembed_bar(feature_id, sparse_autoencoder, feature_name = \"\"):\n",
    "    \n",
    "    # norm_unembed = model.W_U / model.W_U.norm(dim=0)[None: None]\n",
    "    # feature_unembed = sparse_autoencoder.W_dec[feature_id] @ norm_unembed\n",
    "    # feature_unembed = sparse_autoencoder.W_dec[feature_id] @ model.W_Q[10,7].T @  model.W_U\n",
    "    feature_unembed = sparse_autoencoder.W_dec[feature_id] @  model.W_U\n",
    "    # torch.topk(unembed_4795,10)\n",
    "\n",
    "    feature_unembed_df = pd.DataFrame(\n",
    "        feature_unembed.detach().cpu().numpy(),\n",
    "        columns = [feature_name],\n",
    "        index = [model.tokenizer.decode(i) for i in list(range(50257))]\n",
    "    )\n",
    "\n",
    "    feature_unembed_df = feature_unembed_df.sort_values(feature_name, ascending=False).reset_index().rename(columns={'index': 'token'})\n",
    "    fig = px.bar(feature_unembed_df.head(20).sort_values(feature_name, ascending=True),\n",
    "                 color_continuous_midpoint=0,\n",
    "                 color_continuous_scale=\"RdBu\",\n",
    "            y = 'token', x = feature_name, orientation='h', color = feature_name, hover_data=[feature_name])\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=500,\n",
    "        height=600,\n",
    "    )\n",
    "\n",
    "    # fig.write_image(f\"figures/{str(feature_id)}_{feature_name}.png\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "plot_feature_unembed_bar(3541, sparse_autoencoder, feature_name = str(3457))\n",
    "# for i in inds:\n",
    "#     plot_feature_unembed_bar(int(i), sparse_autoencoder, feature_name = str(i.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Capability Test\n",
    "\n",
    "Validating model performance on specific tasks when using the reconstructed activation is quite important when studying specific tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"When John and Mary went to the shops, John gave the bag to\"\n",
    "example_answer = \" Mary\"\n",
    "utils.test_prompt(example_prompt, example_answer, model, prepend_bos=False)\n",
    "\n",
    "logits, cache = model.run_with_cache(example_prompt, prepend_bos=True)\n",
    "tokens = model.to_tokens(example_prompt)\n",
    "sae_out, feature_acts, loss, mse_loss, l1_loss = sparse_autoencoder(\n",
    "    cache[sparse_autoencoder.cfg.hook_point]\n",
    ")\n",
    "\n",
    "def reconstr_hook(mlp_out, hook, new_mlp_out):\n",
    "    return new_mlp_out\n",
    "\n",
    "def reconstr_key_hook(mlp_out, hook, reconstructed_key):\n",
    "    return reconstructed_key\n",
    "\n",
    "def reconstr_query_hook(mlp_out, hook, reconstructed_query):\n",
    "    return reconstructed_query\n",
    "\n",
    "\n",
    "def zero_abl_hook(mlp_out, hook):\n",
    "    return torch.zeros_like(mlp_out)\n",
    "\n",
    "print(\"Orig\", model(tokens, return_type=\"loss\").item())\n",
    "print(\n",
    "    \"reconstr\",\n",
    "    model.run_with_hooks(\n",
    "        tokens,\n",
    "        fwd_hooks=[\n",
    "            (\n",
    "                sparse_autoencoder.cfg.hook_point,\n",
    "                partial(reconstr_hook, new_mlp_out=sae_out),\n",
    "            )\n",
    "        ],\n",
    "        return_type=\"loss\",\n",
    "    ).item(),\n",
    ")\n",
    "print(\n",
    "    \"Zero\",\n",
    "    model.run_with_hooks(\n",
    "        tokens,\n",
    "        return_type=\"loss\",\n",
    "        fwd_hooks=[(sparse_autoencoder.cfg.hook_point, zero_abl_hook)],\n",
    "    ).item(),\n",
    ")\n",
    "\n",
    "\n",
    "with model.hooks(\n",
    "    fwd_hooks=[\n",
    "        (\n",
    "            sparse_autoencoder.cfg.hook_point,\n",
    "            partial(reconstr_hook, new_mlp_out=sae_out),\n",
    "        )\n",
    "    ]\n",
    "):\n",
    "    utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_acts = feature_acts[0]\n",
    "print((feature_acts[0,-1].detach() > 0 ).float().sum())\n",
    "px.line(feature_acts[0,-1].detach().cpu().numpy()).show()\n",
    "vals, inds = torch.topk(feature_acts[0,-1].detach().cpu(),10)\n",
    "px.bar(x=[str(i) for i in inds], y=vals).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_unembed_bar(feature_id, sparse_autoencoder, feature_name = \"\"):\n",
    "    \n",
    "    # norm_unembed = model.W_U / model.W_U.norm(dim=0)[None: None]\n",
    "    # feature_unembed = sparse_autoencoder.W_dec[feature_id] @ norm_unembed\n",
    "    feature_unembed = sparse_autoencoder.W_dec[feature_id] @ model.W_Q[10,7].T @ model.W_U\n",
    "    # torch.topk(unembed_4795,10)\n",
    "\n",
    "    feature_unembed_df = pd.DataFrame(\n",
    "        feature_unembed.detach().cpu().numpy(),\n",
    "        columns = [feature_name],\n",
    "        index = [model.tokenizer.decode(i) for i in list(range(50257))]\n",
    "    )\n",
    "\n",
    "    feature_unembed_df = feature_unembed_df.sort_values(feature_name, ascending=False).reset_index().rename(columns={'index': 'token'})\n",
    "    fig = px.bar(feature_unembed_df.head(20).sort_values(feature_name, ascending=True),\n",
    "                 color_continuous_midpoint=0,\n",
    "                 color_continuous_scale=\"RdBu\",\n",
    "            y = 'token', x = feature_name, orientation='h', color = feature_name, hover_data=[feature_name])\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=500,\n",
    "        height=600,\n",
    "    )\n",
    "\n",
    "    # fig.write_image(f\"figures/{str(feature_id)}_{feature_name}.png\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "for i in inds:\n",
    "    plot_feature_unembed_bar(int(i), sparse_autoencoder, feature_name = str(i.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reconstructed_q = cache_reconstructed_res_stream[\"blocks.10.attn.hook_q\"].detach()\n",
    "reconstructed_k = cache_reconstructed_res_stream[\"blocks.10.attn.hook_k\"].detach()\n",
    "\n",
    "\n",
    "def reconstr_key_hook(key, hook, reconstructed_key):\n",
    "    return reconstructed_key\n",
    "\n",
    "def reconstr_query_hook(query, hook, reconstructed_query):\n",
    "    print(\"reconstr_query_hook\", query.shape, reconstructed_query.shape)\n",
    "    if query.shape == reconstructed_query.shape:\n",
    "        return reconstructed_query\n",
    "    else:\n",
    "        new_query = torch.concat(\n",
    "            [query[:,0].unsqueeze(1), reconstructed_query],\n",
    "            dim=1\n",
    "        )\n",
    "        return new_query\n",
    "\n",
    "model.reset_hooks()\n",
    "with model.hooks(\n",
    "    fwd_hooks=[\n",
    "        (\n",
    "            \"blocks.10.attn.hook_q\",\n",
    "            partial(reconstr_query_hook, reconstructed_query=reconstructed_q),\n",
    "        )\n",
    "    ]\n",
    "):\n",
    "    utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)\n",
    "    _, cache_reconstructed_queries = model.run_with_cache(example_prompt, prepend_bos=True)\n",
    "\n",
    "model.reset_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the MSE Loss by Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse_loss_cache_df(original_cache, intervention_cache):\n",
    "    mse_loss = lambda x, y: (x - y).pow(2).mean()\n",
    "    keys = []\n",
    "    values = []\n",
    "    for key in cache_original.keys():\n",
    "        keys.append(key)\n",
    "        values.append(mse_loss(original_cache[key], intervention_cache[key]).item())\n",
    "    df = pd.DataFrame({\"key\": keys, \"mse_loss\": values})\n",
    "    \n",
    "    # get the index of the first non-zero mse_loss\n",
    "    first_non_zero_idx = df[df[\"mse_loss\"] > 0].index[0]\n",
    "    # filter from there onward\n",
    "    df = df.iloc[first_non_zero_idx:]\n",
    "    return df\n",
    "\n",
    "df = get_mse_loss_cache_df(cache_original, cache_reconstructed_res_stream)\n",
    "px.line(df, x=\"key\", y=\"mse_loss\").show()\n",
    "\n",
    "df = get_mse_loss_cache_df(cache_original, cache_reconstructed_queries)\n",
    "px.line(df, x=\"key\", y=\"mse_loss\").show()\n",
    "\n",
    "df = get_mse_loss_cache_df(cache_original, cache_reconstructed_keys)\n",
    "px.line(df, x=\"key\", y=\"mse_loss\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize attn patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuitsvis.attention import attention_patterns\n",
    "patterns_original = cache_original[\"blocks.10.attn.hook_pattern\"].detach().cpu()[0]\n",
    "attention_patterns(tokens=model.to_str_tokens(example_prompt), attention=patterns_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(patterns_original[7].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_reconstructed = cache_reconstructed_queries[\"blocks.10.attn.hook_pattern\"][0].detach().cpu()\n",
    "px.imshow(patterns_reconstructed[7].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patterns_reconstructed = cache_reconstructed_res_stream[\"blocks.10.attn.hook_pattern\"][0].detach().cpu()\n",
    "# patterns_reconstructed = cache_reconstructed_keys[\"blocks.10.attn.hook_pattern\"][0].detach().cpu()\n",
    "patterns_reconstructed = cache_reconstructed_queries[\"blocks.10.attn.hook_pattern\"][0].detach().cpu()\n",
    "attention_patterns(tokens=model.to_str_tokens(example_prompt), attention=patterns_reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize change in Attn Scores/Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_cache = cache_reconstructed_queries\n",
    "scores_original = cache_original[\"blocks.10.attn.hook_attn_scores\"][0].detach().cpu()\n",
    "scores_reconstructed = intervention_cache[\"blocks.10.attn.hook_attn_scores\"][0].detach().cpu()\n",
    "patterns_original = cache_original[\"blocks.10.attn.hook_pattern\"][0].detach().cpu()\n",
    "patterns_reconstructed = intervention_cache[\"blocks.10.attn.hook_pattern\"][0].detach().cpu()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def tensor_to_long_data_frame(tensor_result, dimension_names, value_name = \"Score\"):\n",
    "    assert len(tensor_result.shape) == len(\n",
    "        dimension_names\n",
    "    ), \"The number of dimension names must match the number of dimensions in the tensor\"\n",
    "\n",
    "    tensor_2d = tensor_result.reshape(-1).detach().cpu()\n",
    "    df = pd.DataFrame(tensor_2d.detach().numpy(), columns=[value_name])\n",
    "\n",
    "    indices = pd.MultiIndex.from_tuples(\n",
    "        list(np.ndindex(tensor_result.shape)),\n",
    "        names=dimension_names,\n",
    "    )\n",
    "    df.index = indices\n",
    "    \n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    # set all dimensions except Score to categorical\n",
    "    for i in range(len(dimension_names)):\n",
    "        df[dimension_names[i]] = df[dimension_names[i]].astype(\"category\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "scores_df = tensor_to_long_data_frame(scores_original, [\"Head\", \"Query\", \"Key\"], value_name = \"Original\")\n",
    "scores_df[\"Reconstructed\"] = scores_reconstructed.flatten().detach().cpu().numpy()\n",
    "scores_df[\"Pattern Original\"] = patterns_original.flatten().detach().cpu().numpy()\n",
    "scores_df[\"Pattern Reconstructed\"] = patterns_reconstructed.flatten().detach().cpu().numpy()\n",
    "scores_df = scores_df[scores_df[\"Original\"] != float(\"inf\")]\n",
    "scores_df = scores_df[scores_df[\"Reconstructed\"] != float(\"inf\")]\n",
    "scores_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pandas default width/height\n",
    "fig = px.scatter(scores_df, x=\"Original\", y=\"Reconstructed\", color = \"Head\", hover_data=[\"Head\", \"Query\", \"Key\"])\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(scores_df, x=\"Pattern Original\", y=\"Pattern Reconstructed\", color = \"Head\", hover_data=[\"Head\", \"Query\", \"Key\"], log_x=True, log_y=True)\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(scores_df, x=\"Pattern Original\", y=\"Pattern Reconstructed\", color = \"Key\", hover_data=[\"Head\", \"Query\", \"Key\"], log_x=True, log_y=True)\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from einops import einsum\n",
    "\n",
    "\n",
    "def kl_divergence_attention(y_true, y_pred):\n",
    "\n",
    "    # Compute log probabilities for KL divergence\n",
    "    log_y_true = torch.log(y_true)\n",
    "    log_y_pred = torch.log(y_pred)\n",
    "\n",
    "    return y_true * (log_y_true - log_y_pred)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "print(patterns_original.shape)\n",
    "kl_result = kl_divergence_attention(patterns_original, patterns_reconstructed)\n",
    "kl_result[kl_result.isnan()] = 0\n",
    "fig = px.imshow(kl_result.sum(dim=-1).detach().cpu(), color_continuous_midpoint=0, color_continuous_scale=\"RdBu\",\n",
    "                labels = dict(x=\"Query\", y=\"Head\"), text_auto=\".2f\")\n",
    "fig.layout.coloraxis.colorbar.title = \"KL Divergence\"\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
