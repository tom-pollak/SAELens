{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from importlib import reload\n",
    "from tqdm import tqdm\n",
    "\n",
    "import joseph\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "\n",
    "reload(joseph.analysis)\n",
    "reload(joseph.visualisation)\n",
    "reload(joseph.utils)\n",
    "reload(joseph.data)\n",
    "\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "# turn torch grad tracking off\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "\n",
    "    fold_ln=True,\n",
    ")\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# path = \"../week_8_jan/artifacts/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152:v28/1100001280_sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152.pt\"\n",
    "path = \"../week_8_jan/artifacts/sparse_autoencoder_gpt2-small_blocks.5.hook_resid_pre_49152:v9/final_sparse_autoencoder_gpt2-small_blocks.5.hook_resid_pre_49152.pt\"\n",
    "sparse_autoencoder = SparseAutoencoder.load_from_pretrained(path)\n",
    "\n",
    "print(sparse_autoencoder.cfg)\n",
    "\n",
    "\n",
    "# sanity check\n",
    "text = \"Many important transition points in the history of science have been moments when science 'zoomed in.' At these points, we develop a visualization or tool that allows us to see the world in a new level of detail, and a new field of science develops to study the world through this lens.\"\n",
    "model(text, return_type=\"loss\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_feature_sparsity = torch.load(\"../week_8_jan/artifacts/sparse_autoencoder_gpt2-small_blocks.5.hook_resid_pre_49152:v9/log_feature_sparsity_5000_4.pt\")\n",
    "# px.histogram(log_feature_sparsity, nbins=100, title=\"log_fe|ature_sparsity\")\n",
    "px.histogram(log_feature_sparsity[log_feature_sparsity>-9], title=\"log_feature_sparsity (excluding dead neurons)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_training.utils import LMSparseAutoencoderSessionloader\n",
    "model, sparse_autoencoder, activation_store = LMSparseAutoencoderSessionloader.load_session_from_pretrained(\n",
    "    path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "path_to_html = \"../week_8_jan/gpt2_small_features_layer_5\"\n",
    "def render_feature_dashboard(feature_id):\n",
    "    \n",
    "    path = f\"{path_to_html}/data_{feature_id:04}.html\"\n",
    "    \n",
    "    print(f\"Feature {feature_id}\")\n",
    "    if os.path.exists(path):\n",
    "        # with open(path, \"r\") as f:\n",
    "        #     html = f.read()\n",
    "        #     display(HTML(html))\n",
    "        webbrowser.open_new_tab(\"file://\" + os.path.abspath(path))\n",
    "    else:\n",
    "        print(\"No HTML file found\")\n",
    "    \n",
    "    return\n",
    "\n",
    "# for feature in [100,300,400]:\n",
    "#     render_feature_dashboard(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does GPT2 do induction well on HP paragraph one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tokens, random_token_groups = generate_random_token_prompt(model, n_random_tokens=5, n_repeat_tokens=2, token_of_interest=\" Mary\")\n",
    "prompt = model.to_string(random_tokens)\n",
    "token_df, original_cache, cache_reconstructed_query, feature_acts = eval_prompt([prompt], model, sparse_autoencoder, head_idx_override=5)\n",
    "print(token_df.columns)\n",
    "filter_cols = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\"]\n",
    "token_df[filter_cols].tail(10).style.background_gradient(\n",
    "    subset=[\"loss_diff\", \"mse_loss\",\"explained_variance\", \"num_active_features\", \"kl_divergence\"],\n",
    "    cmap=\"coolwarm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn(patterns, token_df, title=\"\", facet_col_labels = [\"Original\", \"Reconstructed\"]):\n",
    "    '''\n",
    "    # patterns_original = cache[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "    # patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "    patterns_original = cache[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "    patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "    both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "    plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")\n",
    "    \n",
    "    '''\n",
    "    fig = px.imshow(patterns, text_auto=\".2f\", title=title,\n",
    "                    facet_col=0,\n",
    "                    color_continuous_midpoint=0,\n",
    "                    color_continuous_scale=\"RdBu\",\n",
    "                    )\n",
    "    \n",
    "    tickvals = np.arange(patterns.shape[2])\n",
    "    ticktext = token_df[\"unique_token\"].tolist()\n",
    "    \n",
    "    # add tokens as x-ticks and y-ticks, for each facet\n",
    "    # Update x-ticks and y-ticks for each facet\n",
    "    for i in range(len(facet_col_labels)):\n",
    "        fig.update_xaxes(\n",
    "            dict(tickmode='array', tickvals=tickvals, ticktext=ticktext),\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            dict(tickmode='array', tickvals=tickvals, ticktext=ticktext),\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # add facet col labels:\n",
    "    for i, label in enumerate(facet_col_labels):\n",
    "        fig.layout.annotations[i].text = label\n",
    "        fig.layout.annotations[i].font.size = 20\n",
    "        \n",
    "    fig.update_layout(\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "HEAD_IDX = 5\n",
    "LAYER_IDX = sparse_autoencoder.cfg.hook_point_layer\n",
    "patterns_original = original_cache[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "# plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")\n",
    "patterns_original = original_cache[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_INTEREST = 10\n",
    "UNIQUE_TOKEN_INTEREST = token_df[\"unique_token\"][POS_INTEREST]\n",
    "feature_acts_of_interest = feature_acts[POS_INTEREST]\n",
    "title = \"test\"\n",
    "\n",
    "# plot_line_with_top_10_labels(feature_acts_of_interest, \"\", 25)\n",
    "\n",
    "top_k_feature_inds = (feature_acts[1:] > 0).sum(dim=0).nonzero().squeeze()\n",
    "\n",
    "features_acts_by_token_df = pd.DataFrame(\n",
    "    feature_acts[:,top_k_feature_inds[:]].detach().cpu().T,\n",
    "    index = [f\"feature_{i}\" for i in top_k_feature_inds.flatten().tolist()],\n",
    "    columns = token_df[\"unique_token\"])\n",
    "\n",
    "tmp = features_acts_by_token_df.sort_values(UNIQUE_TOKEN_INTEREST, ascending=False).T\n",
    "px.line(tmp, \n",
    "        title=f\"{title}: Features Activation by Token in Prompt\", \n",
    "        color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "        height=400).show()\n",
    "\n",
    "px.line(tmp + 1e-4,\n",
    "        log_y=True, \n",
    "        title=f\"{title}: Features Activation by Token in Prompt\", \n",
    "        color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "        height=400).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_feature_dashboard(16263)\n",
    "# render_feature_dashboard(5673)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intervene and calculate attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cache.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_ablation_effect_on_attn_experiment(\n",
    "    tokens,\n",
    "    token_df,\n",
    "    original_cache,\n",
    "    cache_reconstructed_query,\n",
    "    key_pos=None,\n",
    "    query_pos=-1,\n",
    "    layer_idx=sparse_autoencoder.cfg.hook_point_layer,\n",
    "    head_idx=5,\n",
    "    pattern_or_score = \"pattern\",\n",
    "):\n",
    "    \"\"\"\n",
    "    if key_pos is unspecified, intervene at query pos.\n",
    "    else:\n",
    "        intervene at key pos.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if pattern_or_score == \"pattern\":\n",
    "        hook_text = \"hook_pattern\"\n",
    "    else:\n",
    "        hook_text = \"hook_attn_scores\"\n",
    "        \n",
    "    token_df = make_token_df(model, tokens)\n",
    "    patterns = (\n",
    "        original_cache[f\"blocks.{layer_idx}.attn.{hook_text}\"][0, head_idx]\n",
    "        .detach()\n",
    "        .cpu()\n",
    "    )\n",
    "    token_df[\"original_attn\"] = patterns[query_pos,]\n",
    "    patterns = (\n",
    "        cache_reconstructed_query[f\"blocks.{layer_idx}.attn.{hook_text}\"][0, head_idx]\n",
    "        .detach()\n",
    "        .cpu()\n",
    "    )\n",
    "    token_df[\"reconstructed_attn\"] = patterns[query_pos,]\n",
    "\n",
    "    if key_pos is not None:\n",
    "        intervene_pos = key_pos\n",
    "    else:\n",
    "        intervene_pos = query_pos\n",
    "\n",
    "    head_hook_query_name = utils.get_act_name(\"q\", layer_idx)\n",
    "\n",
    "    vals, inds = torch.topk(feature_acts[intervene_pos], 35)\n",
    "    original_act = original_cache[sparse_autoencoder.cfg.hook_point]\n",
    "\n",
    "    for feature in inds:\n",
    "        features_to_remove = [feature]\n",
    "        sae_out, _, _, mse_loss, _ = sparse_autoencoder(original_act)\n",
    "\n",
    "        # need to generate query\n",
    "        def replacement_hook(resid_pre, hook, new_resid_pre=sae_out):\n",
    "            return new_resid_pre\n",
    "\n",
    "        with model.hooks(\n",
    "            fwd_hooks=[\n",
    "                (\n",
    "                    utils.get_act_name(\n",
    "                        \"resid_pre\", sparse_autoencoder.cfg.hook_point_layer\n",
    "                    ),\n",
    "                    replacement_hook,\n",
    "                )\n",
    "            ]\n",
    "        ):\n",
    "            _, resid_pre_cache = model.run_with_cache(\n",
    "                tokens, return_type=\"loss\", loss_per_token=True\n",
    "            )\n",
    "            sae_out = resid_pre_cache[head_hook_query_name][:, :, head_idx]\n",
    "\n",
    "        def remove_feature_hook(\n",
    "            hook_in, hook, position=intervene_pos, features_to_remove=features_to_remove\n",
    "        ):\n",
    "            for feature_to_remove in features_to_remove:\n",
    "                # print(feature_acts[0,position,feature_to_remove].item())\n",
    "                feature_dir = (\n",
    "                    feature_acts[position, feature_to_remove]\n",
    "                    * sparse_autoencoder.W_dec[feature_to_remove]\n",
    "                )\n",
    "                hook_in -= feature_dir\n",
    "            return hook_in\n",
    "\n",
    "        with model.hooks(\n",
    "            fwd_hooks=[(sparse_autoencoder.cfg.hook_point, remove_feature_hook)]\n",
    "        ):\n",
    "            _, cache_removed_feature = model.run_with_cache(\n",
    "                tokens, return_type=\"loss\", loss_per_token=True\n",
    "            )\n",
    "\n",
    "        patterns = (\n",
    "            cache_removed_feature[f\"blocks.{layer_idx}.attn.hook_pattern\"][0, head_idx]\n",
    "            .detach()\n",
    "            .cpu()\n",
    "        )\n",
    "        token_df[f\"ablated_feature_{feature}\"] = patterns[query_pos,]\n",
    "        \n",
    "    # then do the same with original act - sae_out\n",
    "    sae_out, _, _, mse_loss, _ = sparse_autoencoder(original_act)\n",
    "    dummy_feature = original_act - sae_out\n",
    "\n",
    "    def replacement_hook(resid_pre, hook, new_resid_pre=sae_out):\n",
    "        return new_resid_pre\n",
    "\n",
    "    with model.hooks(\n",
    "        fwd_hooks=[\n",
    "            (\n",
    "                utils.get_act_name(\n",
    "                    \"resid_pre\", sparse_autoencoder.cfg.hook_point_layer\n",
    "                ),\n",
    "                replacement_hook,\n",
    "            )\n",
    "        ]\n",
    "    ):\n",
    "        _, resid_pre_cache = model.run_with_cache(\n",
    "            tokens, return_type=\"loss\", loss_per_token=True\n",
    "        )\n",
    "        sae_out = resid_pre_cache[head_hook_query_name][:, :, head_idx]\n",
    "\n",
    "    def remove_feature_hook(\n",
    "        hook_in, hook, position=intervene_pos, features_to_remove=features_to_remove\n",
    "    ):\n",
    "        hook_in -= dummy_feature\n",
    "        return hook_in\n",
    "\n",
    "    with model.hooks(\n",
    "        fwd_hooks=[(sparse_autoencoder.cfg.hook_point, remove_feature_hook)]\n",
    "    ):\n",
    "        _, cache_removed_feature = model.run_with_cache(\n",
    "            tokens, return_type=\"loss\", loss_per_token=True\n",
    "        )\n",
    "\n",
    "    patterns = (\n",
    "        cache_removed_feature[f\"blocks.{layer_idx}.attn.hook_pattern\"][0, head_idx]\n",
    "        .detach()\n",
    "        .cpu()\n",
    "    )\n",
    "    token_df[f\"ablated_sae_residual\"] = patterns[query_pos,]\n",
    "\n",
    "    return token_df\n",
    "\n",
    "\n",
    "query_pos = 10\n",
    "tokens = torch.concat(\n",
    "    [torch.tensor(model.tokenizer.eos_token_id).unsqueeze(0), random_tokens.cpu()],\n",
    "    dim=0,\n",
    ").unsqueeze(0)\n",
    "test_query = feature_ablation_effect_on_attn_experiment(\n",
    "    tokens,\n",
    "    token_df,\n",
    "    original_cache,\n",
    "    cache_reconstructed_query,\n",
    "    key_pos=None,\n",
    "    query_pos=query_pos,\n",
    "    layer_idx=sparse_autoencoder.cfg.hook_point_layer,\n",
    "    head_idx=5,\n",
    "    pattern_or_score=\"pattern\"\n",
    ")\n",
    "\n",
    "fig = px.line(\n",
    "    test_query,\n",
    "    x=\"unique_token\",\n",
    "    y=[\"original_attn\", \"reconstructed_attn\", \"ablated_sae_residual\"]\n",
    "    + [i for i in test_query.columns if \"ablated_feature\" in i],\n",
    "    hover_name=\"str_tokens\",\n",
    "    hover_data=[\"pos\", \"batch\", \"label\"],\n",
    "    title=\"Original vs Reconstructed attention\",\n",
    "    width=1000,\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "key_pos = 5\n",
    "query_pos = 10\n",
    "tokens = torch.concat(\n",
    "    [torch.tensor(model.tokenizer.eos_token_id).unsqueeze(0), random_tokens.cpu()],\n",
    "    dim=0,\n",
    ").unsqueeze(0)\n",
    "test_key = feature_ablation_effect_on_attn_experiment(\n",
    "    tokens,\n",
    "    token_df,\n",
    "    original_cache,\n",
    "    cache_reconstructed_query,\n",
    "    key_pos=key_pos,\n",
    "    query_pos=query_pos,\n",
    "    layer_idx=sparse_autoencoder.cfg.hook_point_layer,\n",
    "    head_idx=5,\n",
    "    pattern_or_score=\"pattern\"\n",
    ")\n",
    "\n",
    "fig = px.line(\n",
    "    test_key,\n",
    "    x=\"unique_token\",\n",
    "    y=[\"original_attn\", \"reconstructed_attn\", \"ablated_sae_residual\"]\n",
    "    + [i for i in test_key.columns if \"ablated_feature\" in i],\n",
    "    hover_name=\"str_tokens\",\n",
    "    hover_data=[\"pos\", \"batch\", \"label\"],\n",
    "    title=\"Original vs Reconstructed attention\",\n",
    "    width=1000,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual Weight Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = sparse_autoencoder.cfg.hook_point_layer\n",
    "W_QK_5 = torch.stack(\n",
    "    [model.W_Q[layer,i] @ model.W_K[layer,i].T for i in range(12)],\n",
    "    dim=0\n",
    ").cpu()\n",
    "W_QK_5.norm(dim=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_feature_weight_proj(W_dec_features, feature_indices, sparse_autoencoder=sparse_autoencoder, model = model):\n",
    "    W_dec_features = W_dec_features.cpu() - W_dec_features.cpu().mean(dim=0, keepdim=True)\n",
    "    layer = sparse_autoencoder.cfg.hook_point_layer\n",
    "    W_QK_5 = torch.stack(\n",
    "        [model.W_Q[layer,i] @ model.W_K[layer,i].T for i in range(12)],\n",
    "        dim=0\n",
    "    ).cpu()\n",
    "    W_QK_5 = W_QK_5 / W_QK_5.norm(dim=(1,2), keepdim=True)\n",
    "\n",
    "    query_proj_dec_weights = W_dec_features @ (W_QK_5 - W_QK_5.mean(dim=0, keepdim=True))\n",
    "    query_proj_dec_weights_df = pd.DataFrame(\n",
    "        query_proj_dec_weights.norm(dim=-1).detach().cpu().numpy().T,\n",
    "        columns = [f\"L{layer}H\" + str(i) for i in range(12)],\n",
    "        index = [f\"feature_{i}\" for i in feature_indices])\n",
    "\n",
    "\n",
    "\n",
    "    key_proj_dec_weights = W_dec_features @ W_QK_5.transpose(2,1)\n",
    "    key_proj_dec_weights_df = pd.DataFrame(\n",
    "        key_proj_dec_weights.norm(dim=-1).detach().cpu().numpy().T,\n",
    "        columns = [f\"L{layer}H\" + str(i) for i in range(12)],\n",
    "        index = [f\"feature_{i}\" for i in feature_indices])\n",
    "    \n",
    "    \n",
    "    return query_proj_dec_weights_df, key_proj_dec_weights_df\n",
    "\n",
    "\n",
    "\n",
    "query_proj_dec_weights_df, key_proj_dec_weights_df = get_feature_weight_proj(sparse_autoencoder.W_dec, range(sparse_autoencoder.cfg.d_sae))\n",
    "query_proj_dec_weights_df[\"log_feature_sparsity\"] = log_feature_sparsity\n",
    "key_proj_dec_weights_df[\"log_feature_sparsity\"] = log_feature_sparsity\n",
    "\n",
    "layer = sparse_autoencoder.cfg.hook_point_layer\n",
    "head_list = [f\"L{layer}H\" + str(i) for i in range(12)]\n",
    "max_prox = max(query_proj_dec_weights_df.max().max(), key_proj_dec_weights_df.max().max())\n",
    "\n",
    "px.histogram(\n",
    "    query_proj_dec_weights_df[query_proj_dec_weights_df[\"log_feature_sparsity\"]>-9],\n",
    "    x=head_list,\n",
    "    barmode='overlay',\n",
    "    title = \"Query projection onto decoder weights\",\n",
    "    width = 1000,\n",
    "    height = 600,\n",
    "    nbins=1000,\n",
    "    range_x=[0, max_prox]\n",
    ").show()\n",
    "\n",
    "px.histogram(\n",
    "    key_proj_dec_weights_df[key_proj_dec_weights_df[\"log_feature_sparsity\"]>-9],   \n",
    "    x=head_list,    \n",
    "    barmode='overlay',\n",
    "    title = \"Key projection onto decoder weights\",\n",
    "    width = 1000,\n",
    "    height = 600,\n",
    "    nbins =1000,\n",
    "    range_x=[0, max_prox]\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_proj_dec_weights_df = query_proj_dec_weights_df.join(key_proj_dec_weights_df, how=\"inner\", lsuffix=\"_query\", rsuffix=\"_key\")\n",
    "all_proj_dec_weights_df[\"log_feature_sparsity\"] = log_feature_sparsity\n",
    "\n",
    "for head in [5]:\n",
    "    px.scatter(\n",
    "        all_proj_dec_weights_df[all_proj_dec_weights_df[\"log_feature_sparsity\"]>-9],\n",
    "        x=f\"L5H{head}_query\",\n",
    "        y=f\"L5H{head}_key\",\n",
    "        color = \"log_feature_sparsity\",\n",
    "        title = f\"Norm of Query vs Key projection onto decoder weights (head {head})\",\n",
    "        height = 1000,\n",
    "        width = 1500,\n",
    "        hover_name=all_proj_dec_weights_df[all_proj_dec_weights_df[\"log_feature_sparsity\"]>-9].index,\n",
    "        marginal_x=\"histogram\",\n",
    "        marginal_y=\"histogram\",\n",
    "        opacity=0.5,\n",
    "    ).show()\n",
    "# px.parallel_coordinates(\n",
    "#     all_proj_dec_weights_df[all_proj_dec_weights_df[\"log_feature_sparsity\"]>-9],\n",
    "#     dimensions=[\"L5H5_query\", \"L5H5_key\", \"log_feature_sparsity\"],\n",
    "#     title = \"Query vs Key projection onto decoder weights\",\n",
    "#     height = 1000,\n",
    "#     width = 1500,\n",
    "# ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(torch.svd(sparse_autoencoder.W_dec[log_feature_sparsity>-9].cpu())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(model.b_Q[5,:].cpu().norm(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(model.b_K[5,:].cpu().norm(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_proj_dec_weights_df[all_proj_dec_weights_df[\"log_feature_sparsity\"]>-9].sort_values(\"L5H5_query\", ascending=False).head(10).style.background_gradient(\n",
    "    cmap=\"coolwarm\", axis=0)\n",
    "for feature in all_proj_dec_weights_df[all_proj_dec_weights_df[\"log_feature_sparsity\"]>-9].sort_values(\"L5H5_query\", ascending=False).head(10).index:\n",
    "    render_feature_dashboard(feature.split(\"_\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_proj_dec_weights_df[all_proj_dec_weights_df[\"log_feature_sparsity\"]>-9].sort_values(\"L5H5_key\", ascending=False).head(10).style.background_gradient(\n",
    "    cmap=\"coolwarm\", axis=0)\n",
    "for feature in all_proj_dec_weights_df[all_proj_dec_weights_df[\"log_feature_sparsity\"]>-9].sort_values(\"L5H5_key\", ascending=False).head(10).index:\n",
    "    render_feature_dashboard(feature.split(\"_\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(all_proj_dec_weights_df.sort_values(\"L5H5_query\", ascending=False).head(30)[[\"L5H5_query\", \"L5H5_key\", \"log_feature_sparsity\"]].style.background_gradient(\n",
    "    cmap=\"coolwarm\", axis=0))\n",
    "\n",
    "top_query_features = all_proj_dec_weights_df.sort_values(\"L5H5_query\", ascending=False).head(30).index\n",
    "top_query_features = [int(i.split(\"_\")[1]) for i in top_query_features]\n",
    "\n",
    "for feature in top_query_features:\n",
    "    render_feature_dashboard(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(all_proj_dec_weights_df.sort_values(\"L5H5_key\", ascending=False).head(30)[[\"L5H5_query\", \"L5H5_key\", \"log_feature_sparsity\"]].style.background_gradient(\n",
    "    cmap=\"coolwarm\", axis=0))\n",
    "\n",
    "top_query_features = all_proj_dec_weights_df.sort_values(\"L5H5_key\", ascending=False).head(30).index\n",
    "top_query_features = [int(i.split(\"_\")[1]) for i in top_query_features]\n",
    "\n",
    "for feature in top_query_features:\n",
    "    render_feature_dashboard(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bipartite Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_QK_5_5 = model.W_Q[5,5].cpu() @ model.W_K[5,5].T.cpu()\n",
    "expanded_qk_W_dec = sparse_autoencoder.W_dec.cpu() @ W_QK_5_5 @ sparse_autoencoder.W_dec.T.cpu()\n",
    "expanded_qk_W_dec_alive = expanded_qk_W_dec[log_feature_sparsity>-9][:,log_feature_sparsity>-9]\n",
    "expanded_qk_W_dec_alive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(expanded_qk_W_dec_alive.flatten()[torch.randperm(expanded_qk_W_dec_alive.flatten().shape[0])[:10000]], nbins=1000, title=\"expanded_qk_W_dec_alive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_qk_W_dec = expanded_qk_W_dec_alive.flatten().cpu()\n",
    "ids_flattend = np.arange(flattened_qk_W_dec.shape[0])\n",
    "ids_flattend = ids_flattend[flattened_qk_W_dec.abs()>0.1]\n",
    "query_ids = ids_flattend // flattened_qk_W_dec.shape[0]\n",
    "key_ids = ids_flattend % flattened_qk_W_dec.shape[0]\n",
    "tmp = pd.DataFrame(\n",
    "   [flattened_qk_W_dec, query_ids, key_ids],\n",
    "    index=[\"val\", \"query\", \"key\"]\n",
    ").T\n",
    "tmp = tmp.sort_values(\"val\", ascending=False)\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_qk_W_dec = expanded_qk_W_dec_alive.flatten().cpu()\n",
    "query_id = np.array(range(len(flattened_qk_W_dec))) // expanded_qk_W_dec_alive.shape[1]\n",
    "key_id = np.array(range(len(flattened_qk_W_dec))) % expanded_qk_W_dec_alive.shape[1]\n",
    "query_key_df = pd.DataFrame(dict(query_id=query_id, key_id=key_id, val=flattened_qk_W_dec))\n",
    "query_key_df= query_key_df[query_key_df[\"val\"].abs()>0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### try to get a sparse graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "\n",
    "edge_weights = expanded_qk_W_dec_alive\n",
    "edge_weights[edge_weights.abs()<0.3] = 0\n",
    "print(edge_weights.nonzero().shape)\n",
    "# convert to numpy sparse matrix\n",
    "edge_weights = csr_matrix(edge_weights.detach().cpu().numpy())\n",
    "n_components, labels = connected_components(csgraph=edge_weights, directed=True, return_labels=True)\n",
    "n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(log_feature_sparsity>-9).nonzero().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(\n",
    "    [labels, log_feature_sparsity[log_feature_sparsity>-9].tolist(), (log_feature_sparsity>-9).nonzero().squeeze().tolist()],\n",
    "    index=[\"component\", \"log_feature_sparsity\", \"feature_id\"]).T\n",
    "\n",
    "# group by connected component \n",
    "tmp.groupby(\"component\").feature_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_embeddings = sparse_autoencoder.W_dec.cpu() @ model.W_K[5,5].cpu()\n",
    "key_feature_labels = [f\"key_feature_{i}\" for i in range(key_embeddings.shape[0])]\n",
    "print(key_embeddings.shape)\n",
    "\n",
    "query_embeddings = sparse_autoencoder.W_dec.cpu() @ model.W_Q[5,5].cpu()\n",
    "query_feature_labels = [f\"query_feature_{i}\" for i in range(query_embeddings.shape[0])]\n",
    "print(query_embeddings.shape)\n",
    "\n",
    "# filter out features which are dead\n",
    "key_embeddings = key_embeddings[log_feature_sparsity>-9]\n",
    "query_embeddings = query_embeddings[log_feature_sparsity>-9]\n",
    "key_feature_labels = [key_feature_labels[i] for i in (log_feature_sparsity>-9).nonzero().squeeze().tolist()]\n",
    "query_feature_labels = [query_feature_labels[i] for i in (log_feature_sparsity>-9).nonzero().squeeze().tolist()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Filter + Neighbours (not super great)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see a filter around a \n",
    "\n",
    "all_features_we_care_about = []\n",
    "\n",
    "feature = 86\n",
    "vals, inds = torch.topk(expanded_qk_W_dec[feature], 10)\n",
    "all_features_we_care_about += inds.tolist()\n",
    "\n",
    "for feature in inds:\n",
    "    vals, inds = torch.topk(expanded_qk_W_dec[:, feature], 10)\n",
    "    all_features_we_care_about += inds.tolist()\n",
    "    \n",
    "all_features_we_care_about = list(set(all_features_we_care_about))\n",
    "print(len(all_features_we_care_about))\n",
    "\n",
    "\n",
    "tmp = pd.DataFrame(expanded_qk_W_dec[all_features_we_care_about,:][:,all_features_we_care_about],\n",
    "                   index = [f\"feature_{i}\" for i in all_features_we_care_about],\n",
    "                     columns = [f\"feature_{i}\" for i in all_features_we_care_about])\n",
    "\n",
    "px.imshow(tmp, color_continuous_midpoint=0, color_continuous_scale=\"RdBu\", height = 800,\n",
    "          range_color=[-1,1]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_embeddings = (sparse_autoencoder.W_dec.cpu() @ model.W_K[5,5].cpu()) + model.b_K[5,5].cpu()\n",
    "key_embeddings = key_embeddings - key_embeddings.mean(dim=0)\n",
    "key_feature_labels = [f\"key_feature_{i}\" for i in range(key_embeddings.shape[0])]\n",
    "print(key_embeddings.shape)\n",
    "\n",
    "query_embeddings = (sparse_autoencoder.W_dec.cpu() @ model.W_Q[5,5].cpu()) + model.b_Q[5,5].cpu()\n",
    "query_embeddings = query_embeddings - query_embeddings.mean(dim=0)\n",
    "query_feature_labels = [f\"query_feature_{i}\" for i in range(query_embeddings.shape[0])]\n",
    "print(query_embeddings.shape)\n",
    "\n",
    "# filter out features which are dead\n",
    "key_embeddings = key_embeddings[log_feature_sparsity>-9]\n",
    "query_embeddings = query_embeddings[log_feature_sparsity>-9]\n",
    "key_feature_labels = [key_feature_labels[i] for i in (log_feature_sparsity>-9).nonzero().squeeze().tolist()]\n",
    "query_feature_labels = [query_feature_labels[i] for i in (log_feature_sparsity>-9).nonzero().squeeze().tolist()]\n",
    "\n",
    "\n",
    "all_embeddings = torch.cat([key_embeddings, query_embeddings], dim=0)\n",
    "print(all_embeddings.shape)\n",
    "all_embeddings_labels = key_feature_labels + query_feature_labels\n",
    "print(all_embeddings_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(key_embeddings.norm(dim=-1), nbins=1000, title=\"key_embeddings\", width = 500).show()\n",
    "px.histogram(query_embeddings.norm(dim=-1), nbins=1000, title=\"key_embeddings\", width = 500).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap \n",
    "import hdbscan\n",
    "\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0001,\n",
    "    n_components=2,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "all_embeddings_normalized = all_embeddings / all_embeddings.norm(dim=-1).unsqueeze(1)\n",
    "ummap_result = reducer.fit_transform(all_embeddings_normalized.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import trustworthiness\n",
    "\n",
    "n_neighbors_list = 3 + np.arange(100)\n",
    "trust_scores = []\n",
    "for n_neighbors in n_neighbors_list:\n",
    "    random_indices = np.random.permutation(all_embeddings.shape[0])[:1000]\n",
    "    trust = trustworthiness(\n",
    "        all_embeddings_normalized[random_indices].numpy(),\n",
    "        ummap_result[random_indices],\n",
    "        n_neighbors=n_neighbors,\n",
    "        metric=\"cosine\",\n",
    "    )\n",
    "    trust_scores.append(trust)\n",
    "    \n",
    "px.line(x= n_neighbors_list, y = trust_scores, title=\"Trustworthiness of UMAP embeddings\", width=500).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def knn_overlap(X_high, X_low, n_neighbors=5):\n",
    "    nn_high = NearestNeighbors(n_neighbors=n_neighbors).fit(X_high)\n",
    "    nn_low = NearestNeighbors(n_neighbors=n_neighbors).fit(X_low)\n",
    "\n",
    "    _, indices_high = nn_high.kneighbors(X_high)\n",
    "    _, indices_low = nn_low.kneighbors(X_low)\n",
    "\n",
    "    overlap = np.mean([len(np.intersect1d(indices_high[i], indices_low[i])) for i in range(X_high.shape[0])])\n",
    "    return overlap / n_neighbors\n",
    "\n",
    "overlap_score = knn_overlap(all_embeddings_normalized.numpy(), ummap_result, n_neighbors=3)\n",
    "overlap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "umap_df = pd.DataFrame(ummap_result, columns=[\"ummap_x\", \"ummap_y\"])\n",
    "umap_df[\"feature_sparsity\"] = log_feature_sparsity[log_feature_sparsity>-9].detach().cpu().numpy().tolist() + log_feature_sparsity[log_feature_sparsity>-9].detach().cpu().numpy().tolist()\n",
    "umap_df[\"label\"] = all_embeddings_labels\n",
    "umap_df[\"key_or_query\"] = [\"key\"]*len(key_feature_labels) + [\"query\"]*len(query_feature_labels)\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10)\n",
    "clusterer.fit(ummap_result)\n",
    "umap_df[\"cluster\"] = clusterer.labels_\n",
    "umap_df[\"cluster\"] = umap_df[\"cluster\"].astype(str)\n",
    "umap_df[\"feature_sparsity\"] = log_feature_sparsity[log_feature_sparsity>-9].detach().cpu().numpy().tolist() + log_feature_sparsity[log_feature_sparsity>-9].detach().cpu().numpy().tolist()\n",
    "umap_df[\"label\"] = all_embeddings_labels\n",
    "umap_df[\"key_or_query\"] = [\"key\"]*len(key_feature_labels) + [\"query\"]*len(query_feature_labels)\n",
    "\n",
    "fig = px.scatter(\n",
    "        umap_df,\n",
    "        x=\"ummap_x\",\n",
    "        y=\"ummap_y\",\n",
    "        color=\"key_or_query\",\n",
    "        # color=\"feature_sparsity\",\n",
    "        # color=\"cluster\",\n",
    "        color_continuous_midpoint=-2,\n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        hover_name=\"label\",\n",
    "        hover_data=[\"feature_sparsity\", \"cluster\", \"key_or_query\"],\n",
    "        # opacity=0.1,\n",
    "        template=\"plotly\",\n",
    "    )\n",
    "\n",
    "# don't show legend\n",
    "# fig.update_layout(showlegend=False)\n",
    "\n",
    "# make points larger\n",
    "fig.update_traces(marker=dict(size=4))\n",
    "\n",
    "# make it wide and tall\n",
    "fig.update_layout(height=1200, width=1600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_label = \"query_feature_18\"\n",
    "query_embedding_feature_normalized = query_embeddings[query_feature_labels.index(feature_label)] / query_embeddings[query_feature_labels.index(feature_label)].norm()\n",
    "umap_df[\"cosine_distance_with_query_feature_18\"] = 1 - (all_embeddings_normalized @ query_embedding_feature_normalized).detach().cpu().numpy()\n",
    "feature_index_in_all_embeddings = query_feature_labels.index(feature_label) + len(key_feature_labels) if \"query\" in feature_label else key_feature_labels.index(feature_label)\n",
    "umap_df[\"umap_distance_from_query_feature_18\"] = np.linalg.norm((ummap_result - ummap_result[feature_index_in_all_embeddings]), axis=1)\n",
    "# umap_df.sort_values(\"distance_from_query_feature_18\", ascending=True).head(10)\n",
    "\n",
    "\n",
    "display(umap_df[(umap_df.label == \"key_feature_86\") | (umap_df.label == \"query_feature_18\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the spearman rank correlation between cosine distance and umap distance\n",
    "from scipy.stats import spearmanr\n",
    "print(spearmanr(umap_df[\"cosine_distance_with_query_feature_18\"], umap_df[\"umap_distance_from_query_feature_18\"]))\n",
    "\n",
    "px.scatter(\n",
    "    umap_df,\n",
    "    x=\"cosine_distance_with_query_feature_18\",\n",
    "    y=\"umap_distance_from_query_feature_18\",\n",
    "    color = \"key_or_query\",\n",
    "    color_continuous_midpoint=0,\n",
    "    color_continuous_scale=\"RdBu\",\n",
    "    hover_name=\"label\",\n",
    "    hover_data=[\"feature_sparsity\", \"cluster\", \"key_or_query\"],\n",
    "    template=\"plotly\",\n",
    "    marginal_x=\"histogram\",\n",
    "    marginal_y=\"histogram\",\n",
    "    height=1000,\n",
    "    width=1000,\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_df.sort_values(\"cosine_distance_with_query_feature_18\", ascending=True).query(\"key_or_query=='key'\").head(10).style.background_gradient(\n",
    "    cmap=\"coolwarm\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a cluster and sample the dashboards\n",
    "cluster_of_interest = 913\n",
    "cluster_examples = tmp_df[tmp_df[\"cluster\"]==str(cluster_of_interest)].sample(5)\n",
    "display(cluster_examples)\n",
    "for feature in cluster_examples[\"label\"]:\n",
    "    render_feature_dashboard(feature.split(\"_\")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
