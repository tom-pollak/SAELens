{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from importlib import reload\n",
    "from tqdm import tqdm\n",
    "\n",
    "import joseph\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "\n",
    "reload(joseph.analysis)\n",
    "reload(joseph.visualisation)\n",
    "reload(joseph.utils)\n",
    "reload(joseph.data)\n",
    "\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "# turn torch grad tracking off\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "\n",
    "    fold_ln=True,\n",
    ")\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# path = \"../week_8_jan/artifacts/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152:v28/1100001280_sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152.pt\"\n",
    "path = \"../week_8_jan/artifacts/sparse_autoencoder_gpt2-small_blocks.5.hook_resid_pre_49152:v9/final_sparse_autoencoder_gpt2-small_blocks.5.hook_resid_pre_49152.pt\"\n",
    "sparse_autoencoder = SparseAutoencoder.load_from_pretrained(path)\n",
    "\n",
    "print(sparse_autoencoder.cfg)\n",
    "\n",
    "\n",
    "# sanity check\n",
    "text = \"Many important transition points in the history of science have been moments when science 'zoomed in.' At these points, we develop a visualization or tool that allows us to see the world in a new level of detail, and a new field of science develops to study the world through this lens.\"\n",
    "model(text, return_type=\"loss\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_feature_sparsity = torch.load(\"../week_8_jan/artifacts/sparse_autoencoder_gpt2-small_blocks.5.hook_resid_pre_49152:v9/log_feature_sparsity_5000_4.pt\")\n",
    "# px.histogram(log_feature_sparsity, nbins=100, title=\"log_feature_sparsity\")\n",
    "px.histogram(log_feature_sparsity[log_feature_sparsity>-9], title=\"log_feature_sparsity (excluding dead neurons)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_training.utils import LMSparseAutoencoderSessionloader\n",
    "model, sparse_autoencoder, activation_store = LMSparseAutoencoderSessionloader.load_session_from_pretrained(\n",
    "    path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "path_to_html = \"../week_8_jan/gpt2_small_features_layer_5\"\n",
    "def render_feature_dashboard(feature_id):\n",
    "    \n",
    "    path = f\"{path_to_html}/data_{feature_id:04}.html\"\n",
    "    \n",
    "    print(f\"Feature {feature_id}\")\n",
    "    if os.path.exists(path):\n",
    "        # with open(path, \"r\") as f:\n",
    "        #     html = f.read()\n",
    "        #     display(HTML(html))\n",
    "        webbrowser.open_new_tab(\"file://\" + os.path.abspath(path))\n",
    "    else:\n",
    "        print(\"No HTML file found\")\n",
    "    \n",
    "    return\n",
    "\n",
    "# for feature in [100,300,400]:\n",
    "#     render_feature_dashboard(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does GPT2 do induction well on HP paragraph one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "title = \"HP Paragraph 1\"\n",
    "prompt = \"Mr and Mrs Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. Mr\"\n",
    "answer = \" D\"\n",
    "model.reset_hooks()\n",
    "utils.test_prompt(prompt, answer, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joseph\n",
    "reload(joseph.analysis)\n",
    "from joseph.analysis import *\n",
    "\n",
    "\n",
    "title = \"HP Paragraph 1\"\n",
    "prompt = \"Mr and Mrs Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. Mr Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large moustache. Mrs Dursley was thin and blonde and had nearly twice the usual amount of neck,\"\n",
    "# POS_INTEREST = 59\n",
    "POS_INTEREST = 99 # WTF MOUSTACHE?\n",
    "\n",
    "token_df, original_cache, cache_reconstructed_query, feature_acts = eval_prompt([prompt], model, sparse_autoencoder, head_idx_override=5)\n",
    "filter_cols = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\",\n",
    "            \"top_k_features\"]\n",
    "display(token_df[filter_cols].style.background_gradient(\n",
    "    subset=[\"loss_diff\", \"mse_loss\",\"explained_variance\", \"num_active_features\", \"kl_divergence\"],\n",
    "    cmap=\"coolwarm\"))\n",
    "\n",
    "\n",
    "\n",
    "UNIQUE_TOKEN_INTEREST = token_df[\"unique_token\"][POS_INTEREST]\n",
    "feature_acts_of_interest = feature_acts[POS_INTEREST]\n",
    "# plot_line_with_top_10_labels(feature_acts_of_interest, \"\", 25)\n",
    "# vals, inds = torch.topk(feature_acts_of_interest,39)\n",
    "\n",
    "top_k_feature_inds = (feature_acts[1:] > 0).sum(dim=0).nonzero().squeeze()\n",
    "\n",
    "features_acts_by_token_df = pd.DataFrame(\n",
    "    feature_acts[:,top_k_feature_inds[:]].detach().cpu().T,\n",
    "    index = [f\"feature_{i}\" for i in top_k_feature_inds.flatten().tolist()],\n",
    "    columns = token_df[\"unique_token\"])\n",
    "\n",
    "# features_acts_by_token_df.sort_values(by=\",/12\", ascending=False).head(10).style.background_gradient(\n",
    "#     cmap=\"coolwarm\", axis=0)\n",
    "\n",
    "# px.imshow(features_acts_by_token_df.sort_values(by=\",/12\", ascending=False).head(10).T.corr(), color_continuous_midpoint=0, color_continuous_scale=\"RdBu\")\n",
    "\n",
    "tmp = features_acts_by_token_df.sort_values(UNIQUE_TOKEN_INTEREST, ascending=False).T\n",
    "\n",
    "dashboard_features = features_acts_by_token_df.sort_values(UNIQUE_TOKEN_INTEREST, ascending=False).index[:10].to_series().apply(lambda x: x.split(\"_\")[1]).tolist()\n",
    "for feature in dashboard_features[:5]:\n",
    "    render_feature_dashboard(feature)\n",
    "\n",
    "px.line(tmp, \n",
    "        title=f\"{title}: Features Activation by Token in Prompt\", \n",
    "        color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "        height=400).show()\n",
    "\n",
    "tmp = features_acts_by_token_df.head(100).T\n",
    "px.imshow(tmp, \n",
    "            title=f\"{title}: Top k features by activation\", \n",
    "            color_continuous_midpoint=0, \n",
    "            color_continuous_scale=\"RdBu\", \n",
    "            height=400).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, and do we have attention from D to Urs? Yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(original_cache[\"pattern\",5, \"attn\"][0,5].detach().cpu().numpy(), columns = token_df.unique_token, index = token_df.unique_token)\n",
    "px.imshow(tmp, color_continuous_midpoint=0, color_continuous_scale=\"RdBu\", height = 800).show()\n",
    "px.line(tmp.T, color_discrete_sequence=px.colors.qualitative.Plotly, height=300).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we want to attribute the attention score to specific heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, inds = torch.topk(feature_acts[59], 10)\n",
    "print(vals)\n",
    "print(inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intervene and calculate attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Mr and Mrs Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. Mr D\"\n",
    "answer = \"urs\"\n",
    "tokens = model.to_tokens(prompt)\n",
    "\n",
    "token_df, original_cache, cache_reconstructed_query, feature_acts = eval_prompt(prompt, model, sparse_autoencoder, head_idx_override=5)\n",
    "# filter_cols = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\",\n",
    "#                \"top_k_features\"]\n",
    "# token_df[filter_cols].style.background_gradient(\n",
    "#     subset=[\"loss_diff\", \"mse_loss\",\"explained_variance\", \"num_active_features\", \"kl_divergence\"],\n",
    "#     cmap=\"coolwarm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = sparse_autoencoder.cfg.hook_point_layer\n",
    "head_idx = 5\n",
    "head_hook_query_name = utils.get_act_name(\"q\", layer_idx)\n",
    "\n",
    "\n",
    "attn_df = make_token_df(model, tokens)\n",
    "patterns = original_cache[f\"blocks.{layer_idx}.attn.hook_pattern\"][0,head_idx].detach().cpu()\n",
    "attn_df[\"original_attn\"] = patterns[-1,]\n",
    "patterns = cache_reconstructed_query[f\"blocks.{layer_idx}.attn.hook_pattern\"][0,head_idx].detach().cpu()\n",
    "attn_df[\"reconstructed_attn\"] = patterns[-1,]\n",
    "\n",
    "print(feature_acts.shape)\n",
    "plot_line_with_top_10_labels(feature_acts[-1], \"\", 10)\n",
    "vals, inds = torch.topk(feature_acts[-1], 10)\n",
    "\n",
    "\n",
    "for feature in inds:\n",
    "    features_to_remove = [feature]\n",
    "    original_act = original_cache[sparse_autoencoder.cfg.hook_point]\n",
    "    sae_out, feature_acts, _, mse_loss, _ = sparse_autoencoder(original_act)\n",
    "\n",
    "    # need to generate query\n",
    "    def replacement_hook(resid_pre, hook, new_resid_pre=sae_out):\n",
    "        return new_resid_pre\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(utils.get_act_name(\"resid_pre\", sparse_autoencoder.cfg.hook_point_layer), replacement_hook)]):\n",
    "        _, resid_pre_cache = model.run_with_cache(tokens, return_type=\"loss\", loss_per_token=True)\n",
    "        sae_out = resid_pre_cache[head_hook_query_name][:,:,head_idx]\n",
    "\n",
    "\n",
    "    def remove_feature_hook(hook_in, hook, position=-1, features_to_remove = features_to_remove):\n",
    "        for feature_to_remove in features_to_remove:\n",
    "            # print(feature_acts[0,position,feature_to_remove].item())\n",
    "            feature_dir = feature_acts[0,position,feature_to_remove]*sparse_autoencoder.W_dec[feature_to_remove]\n",
    "            hook_in -= feature_dir\n",
    "        return hook_in\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(sparse_autoencoder.cfg.hook_point, remove_feature_hook)]):\n",
    "        _, cache_removed_feature = model.run_with_cache(tokens, return_type=\"loss\", loss_per_token=True)\n",
    "\n",
    "    patterns = cache_removed_feature[f\"blocks.{layer_idx}.attn.hook_pattern\"][0,head_idx].detach().cpu()\n",
    "    attn_df[f\"ablated_feature_{feature}\"] = patterns[-1,]\n",
    "\n",
    "fig = px.line(attn_df, \n",
    "            x=\"unique_token\",\n",
    "            y=[\"original_attn\",\"reconstructed_attn\"] + [f\"ablated_feature_{feature}\" for feature in inds],\n",
    "            hover_name=\"str_tokens\", \n",
    "            hover_data=[\"pos\", \"batch\", \"label\"], \n",
    "            title=\"Original vs Reconstructed attention\")\n",
    "\n",
    "# increase figure height\n",
    "fig.update_layout(height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = sparse_autoencoder.cfg.hook_point_layer\n",
    "head_idx = 5\n",
    "head_hook_query_name = utils.get_act_name(\"q\", layer_idx)\n",
    "head_hook_key_name = utils.get_act_name(\"k\", layer_idx)\n",
    "\n",
    "key_pos = 5\n",
    "attn_df = make_token_df(model, tokens)\n",
    "patterns = original_cache[f\"blocks.{layer_idx}.attn.hook_pattern\"][0,head_idx].detach().cpu()\n",
    "attn_df[\"original_attn\"] = patterns[-1,]\n",
    "patterns = cache_reconstructed_query[f\"blocks.{layer_idx}.attn.hook_pattern\"][0,head_idx].detach().cpu()\n",
    "attn_df[\"reconstructed_attn\"] = patterns[-1,]\n",
    "\n",
    "\n",
    "plot_line_with_top_10_labels(feature_acts[0,key_pos], \"\", 10)\n",
    "\n",
    "vals, inds = torch.topk(feature_acts[0,key_pos], 10)\n",
    "\n",
    "for feature in inds:\n",
    "    features_to_remove = [feature]\n",
    "    original_act = original_cache[sparse_autoencoder.cfg.hook_point]\n",
    "    sae_out, feature_acts, _, mse_loss, _ = sparse_autoencoder(original_act)\n",
    "\n",
    "    # need to generate query\n",
    "    def replacement_hook(resid_pre, hook, new_resid_pre=sae_out):\n",
    "        return new_resid_pre\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(utils.get_act_name(\"resid_pre\", sparse_autoencoder.cfg.hook_point_layer), replacement_hook)]):\n",
    "        _, resid_pre_cache = model.run_with_cache(tokens, return_type=\"loss\", loss_per_token=True)\n",
    "        sae_out = resid_pre_cache[head_hook_key_name][:,:,head_idx]\n",
    "\n",
    "\n",
    "    def remove_feature_hook(hook_in, hook, position=key_pos, features_to_remove = features_to_remove):\n",
    "        for feature_to_remove in features_to_remove:\n",
    "            feature_dir = feature_acts[0,position,feature_to_remove]*sparse_autoencoder.W_dec[feature_to_remove]\n",
    "            hook_in -= feature_dir\n",
    "        return hook_in\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(sparse_autoencoder.cfg.hook_point, remove_feature_hook)]):\n",
    "        _, cache_removed_feature = model.run_with_cache(tokens, return_type=\"loss\", loss_per_token=True)\n",
    "\n",
    "    patterns = cache_removed_feature[f\"blocks.{layer_idx}.attn.hook_pattern\"][0,head_idx].detach().cpu()\n",
    "    attn_df[f\"ablated_feature_{feature}\"] = patterns[-1,]\n",
    "\n",
    "fig = px.line(attn_df, \n",
    "            x=\"unique_token\",\n",
    "            y=[\"original_attn\",\"reconstructed_attn\"] + [f\"ablated_feature_{feature}\" for feature in inds],\n",
    "            hover_name=\"str_tokens\", \n",
    "            hover_data=[\"pos\", \"batch\", \"label\"], \n",
    "            title=\"Original vs Reconstructed attention\")\n",
    "\n",
    "# increase figure height\n",
    "fig.update_layout(height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_score_by_feature(\n",
    "    model: HookedTransformer, \n",
    "    sparse_autoencoder: SparseAutoencoder, \n",
    "    feature_ids, \n",
    "    cache, \n",
    "    token_df, \n",
    "    pos_interest, \n",
    "    vals = None,\n",
    "    head_index = None):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    layer_index = sparse_autoencoder.cfg.hook_point_layer\n",
    "    head_index = sparse_autoencoder.cfg.hook_point_head_index if head_index is None else head_index\n",
    "\n",
    "    k = cache[f\"blocks.{layer_index}.attn.hook_k\"][0,:pos_interest,head_index].cpu()\n",
    "    score_contributions = (sparse_autoencoder.W_dec[feature_ids].cpu() @ model.W_Q[layer_index,head_index].cpu()) @ k.T.cpu()\n",
    "\n",
    "    print(score_contributions.sum())\n",
    "\n",
    "    if vals is not None:\n",
    "        score_contributions = score_contributions.cpu() * vals.unsqueeze(1).cpu()\n",
    "    fig = px.imshow(score_contributions.detach().cpu(), \n",
    "                    color_continuous_scale=\"RdBu\",\n",
    "                    color_continuous_midpoint=0,\n",
    "                    labels = dict(y=\"Feature\", x=\"Token\"),\n",
    "                    text_auto=\".2f\", title=\"\")\n",
    "    # add xticks and y ticks\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            tickmode='array',\n",
    "            tickvals=1+np.arange(score_contributions.shape[1]),\n",
    "            ticktext=token_df[\"str_tokens\"].tolist(),\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            tickmode='array',\n",
    "            tickvals=np.arange(score_contributions.shape[0]),\n",
    "            ticktext=list(feature_ids.detach().cpu().numpy()),\n",
    "        ),\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "fig = plot_attn_score_by_feature(model, sparse_autoencoder, inds[:10], original_cache, token_df, pos_interest=POS_INTEREST, head_index = 5, vals = vals[:10])\n",
    "fig.update_layout(width = 2000, height = 1200)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual Weight Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_feature_weight_proj(W_dec_features, feature_indices, sparse_autoencoder=sparse_autoencoder, model = model):\n",
    "    W_dec_features = W_dec_features.cpu()\n",
    "    layer = sparse_autoencoder.cfg.hook_point_layer\n",
    "    W_QK_5 = torch.stack(\n",
    "        [model.W_Q[layer,i] @ model.W_K[layer,i].T for i in range(12)],\n",
    "        dim=0\n",
    "    ).cpu()\n",
    "\n",
    "\n",
    "    query_proj_dec_weights = W_dec_features @ W_QK_5\n",
    "    query_proj_dec_weights_df = pd.DataFrame(\n",
    "        query_proj_dec_weights.norm(dim=-1).detach().cpu().numpy().T,\n",
    "        columns = [f\"L{layer}H\" + str(i) for i in range(12)],\n",
    "        index = [f\"feature_{i}\" for i in feature_indices])\n",
    "\n",
    "\n",
    "\n",
    "    key_proj_dec_weights = W_dec_features @ W_QK_5.transpose(2,1)\n",
    "    key_proj_dec_weights_df = pd.DataFrame(\n",
    "        key_proj_dec_weights.norm(dim=-1).detach().cpu().numpy().T,\n",
    "        columns = [f\"L{layer}H\" + str(i) for i in range(12)],\n",
    "        index = [f\"feature_{i}\" for i in feature_indices])\n",
    "    \n",
    "    \n",
    "    return query_proj_dec_weights_df, key_proj_dec_weights_df\n",
    "\n",
    "\n",
    "\n",
    "query_proj_dec_weights_df, key_proj_dec_weights_df = get_feature_weight_proj(sparse_autoencoder.W_dec, range(sparse_autoencoder.cfg.d_sae))\n",
    "query_proj_dec_weights_df[\"log_feature_sparsity\"] = log_feature_sparsity\n",
    "key_proj_dec_weights_df[\"log_feature_sparsity\"] = log_feature_sparsity\n",
    "\n",
    "layer = sparse_autoencoder.cfg.hook_point_layer\n",
    "head_list = [f\"L{layer}H\" + str(i) for i in range(12)]\n",
    "max_prox = max(query_proj_dec_weights_df.max().max(), key_proj_dec_weights_df.max().max())\n",
    "\n",
    "px.histogram(\n",
    "    query_proj_dec_weights_df[query_proj_dec_weights_df[\"log_feature_sparsity\"]>-9],\n",
    "    x=head_list,\n",
    "    barmode='overlay',\n",
    "    title = \"Query projection onto decoder weights\",\n",
    "    width = 1000,\n",
    "    height = 600,\n",
    "    nbins=1000,\n",
    "    range_x=[0, max_prox]\n",
    ").show()\n",
    "\n",
    "px.histogram(\n",
    "    key_proj_dec_weights_df[key_proj_dec_weights_df[\"log_feature_sparsity\"]>-9],   \n",
    "    x=head_list,    \n",
    "    barmode='overlay',\n",
    "    title = \"Key projection onto decoder weights\",\n",
    "    width = 1000,\n",
    "    height = 600,\n",
    "    nbins =1000,\n",
    "    range_x=[0, max_prox]\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_proj_dec_weights_df = query_proj_dec_weights_df.join(key_proj_dec_weights_df, how=\"inner\", lsuffix=\"_query\", rsuffix=\"_key\")\n",
    "all_proj_dec_weights_df[\"log_feature_sparsity\"] = log_feature_sparsity\n",
    "\n",
    "for head in [5]:\n",
    "    px.scatter(\n",
    "        all_proj_dec_weights_df[all_proj_dec_weights_df[\"log_feature_sparsity\"]>-9],\n",
    "        x=f\"L5H{head}_query\",\n",
    "        y=f\"L5H{head}_key\",\n",
    "        color = \"log_feature_sparsity\",\n",
    "        title = f\"Norm of Query vs Key projection onto decoder weights (head {head})\",\n",
    "        height = 1000,\n",
    "        width = 1500,\n",
    "        hover_name=all_proj_dec_weights_df[all_proj_dec_weights_df[\"log_feature_sparsity\"]>-9].index,\n",
    "        marginal_x=\"histogram\",\n",
    "        marginal_y=\"histogram\",\n",
    "        opacity=0.5,\n",
    "    ).show()\n",
    "# px.parallel_coordinates(\n",
    "#     all_proj_dec_weights_df[all_proj_dec_weights_df[\"log_feature_sparsity\"]>-9],\n",
    "#     dimensions=[\"L5H5_query\", \"L5H5_key\", \"log_feature_sparsity\"],\n",
    "#     title = \"Query vs Key projection onto decoder weights\",\n",
    "#     height = 1000,\n",
    "#     width = 1500,\n",
    "# ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(torch.svd(sparse_autoencoder.W_dec[log_feature_sparsity>-9].cpu())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(model.b_Q[5,:].cpu().norm(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(model.b_K[5,:].cpu().norm(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_proj_dec_weights_df[all_proj_dec_weights_df[\"log_feature_sparsity\"]>-9].sort_values(\"L5H5_query\", ascending=False).head(10).style.background_gradient(\n",
    "    cmap=\"coolwarm\", axis=0)\n",
    "for feature in all_proj_dec_weights_df[all_proj_dec_weights_df[\"log_feature_sparsity\"]>-9].sort_values(\"L5H5_query\", ascending=False).head(10).index:\n",
    "    render_feature_dashboard(feature.split(\"_\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_proj_dec_weights_df[all_proj_dec_weights_df[\"log_feature_sparsity\"]>-9].sort_values(\"L5H5_key\", ascending=False).head(10).style.background_gradient(\n",
    "    cmap=\"coolwarm\", axis=0)\n",
    "for feature in all_proj_dec_weights_df[all_proj_dec_weights_df[\"log_feature_sparsity\"]>-9].sort_values(\"L5H5_key\", ascending=False).head(10).index:\n",
    "    render_feature_dashboard(feature.split(\"_\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(all_proj_dec_weights_df.sort_values(\"L5H5_query\", ascending=False).head(30)[[\"L5H5_query\", \"L5H5_key\", \"log_feature_sparsity\"]].style.background_gradient(\n",
    "    cmap=\"coolwarm\", axis=0))\n",
    "\n",
    "top_query_features = all_proj_dec_weights_df.sort_values(\"L5H5_query\", ascending=False).head(30).index\n",
    "top_query_features = [int(i.split(\"_\")[1]) for i in top_query_features]\n",
    "\n",
    "for feature in top_query_features:\n",
    "    render_feature_dashboard(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(all_proj_dec_weights_df.sort_values(\"L5H5_key\", ascending=False).head(30)[[\"L5H5_query\", \"L5H5_key\", \"log_feature_sparsity\"]].style.background_gradient(\n",
    "    cmap=\"coolwarm\", axis=0))\n",
    "\n",
    "top_query_features = all_proj_dec_weights_df.sort_values(\"L5H5_key\", ascending=False).head(30).index\n",
    "top_query_features = [int(i.split(\"_\")[1]) for i in top_query_features]\n",
    "\n",
    "for feature in top_query_features:\n",
    "    render_feature_dashboard(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bipartite Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_QK_5_5 = model.W_Q[5,5].cpu() @ model.W_K[5,5].T.cpu()\n",
    "expanded_qk_W_dec = sparse_autoencoder.W_dec.cpu() @ W_QK_5_5 @ sparse_autoencoder.W_dec.T.cpu()\n",
    "expanded_qk_W_dec_alive = expanded_qk_W_dec[log_feature_sparsity>-9][:,log_feature_sparsity>-9]\n",
    "expanded_qk_W_dec_alive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(expanded_qk_W_dec_alive.flatten()[torch.randperm(expanded_qk_W_dec_alive.flatten().shape[0])[:10000]], nbins=1000, title=\"expanded_qk_W_dec_alive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_qk_W_dec = expanded_qk_W_dec_alive.flatten().cpu()\n",
    "ids_flattend = np.arange(flattened_qk_W_dec.shape[0])\n",
    "ids_flattend = ids_flattend[flattened_qk_W_dec.abs()>0.1]\n",
    "query_ids = ids_flattend // flattened_qk_W_dec.shape[0]\n",
    "key_ids = ids_flattend % flattened_qk_W_dec.shape[0]\n",
    "tmp = pd.DataFrame(\n",
    "   [flattened_qk_W_dec, query_ids, key_ids],\n",
    "    index=[\"val\", \"query\", \"key\"]\n",
    ").T\n",
    "tmp = tmp.sort_values(\"val\", ascending=False)\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_qk_W_dec = expanded_qk_W_dec_alive.flatten().cpu()\n",
    "query_id = np.array(range(len(flattened_qk_W_dec))) // expanded_qk_W_dec_alive.shape[1]\n",
    "key_id = np.array(range(len(flattened_qk_W_dec))) % expanded_qk_W_dec_alive.shape[1]\n",
    "query_key_df = pd.DataFrame(dict(query_id=query_id, key_id=key_id, val=flattened_qk_W_dec))\n",
    "query_key_df= query_key_df[query_key_df[\"val\"].abs()>0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### try to get a sparse graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "\n",
    "edge_weights = expanded_qk_W_dec_alive\n",
    "edge_weights[edge_weights.abs()<0.3] = 0\n",
    "print(edge_weights.nonzero().shape)\n",
    "# convert to numpy sparse matrix\n",
    "edge_weights = csr_matrix(edge_weights.detach().cpu().numpy())\n",
    "n_components, labels = connected_components(csgraph=edge_weights, directed=True, return_labels=True)\n",
    "n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(log_feature_sparsity>-9).nonzero().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(\n",
    "    [labels, log_feature_sparsity[log_feature_sparsity>-9].tolist(), (log_feature_sparsity>-9).nonzero().squeeze().tolist()],\n",
    "    index=[\"component\", \"log_feature_sparsity\", \"feature_id\"]).T\n",
    "\n",
    "# group by connected component \n",
    "tmp.groupby(\"component\").feature_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_embeddings = sparse_autoencoder.W_dec.cpu() @ model.W_K[5,5].cpu()\n",
    "key_feature_labels = [f\"key_feature_{i}\" for i in range(key_embeddings.shape[0])]\n",
    "print(key_embeddings.shape)\n",
    "\n",
    "query_embeddings = sparse_autoencoder.W_dec.cpu() @ model.W_Q[5,5].cpu()\n",
    "query_feature_labels = [f\"query_feature_{i}\" for i in range(query_embeddings.shape[0])]\n",
    "print(query_embeddings.shape)\n",
    "\n",
    "# filter out features which are dead\n",
    "key_embeddings = key_embeddings[log_feature_sparsity>-9]\n",
    "query_embeddings = query_embeddings[log_feature_sparsity>-9]\n",
    "key_feature_labels = [key_feature_labels[i] for i in (log_feature_sparsity>-9).nonzero().squeeze().tolist()]\n",
    "query_feature_labels = [query_feature_labels[i] for i in (log_feature_sparsity>-9).nonzero().squeeze().tolist()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Filter + Neighbours (not super great)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see a filter around a \n",
    "\n",
    "all_features_we_care_about = []\n",
    "\n",
    "feature = 86\n",
    "vals, inds = torch.topk(expanded_qk_W_dec[feature], 10)\n",
    "all_features_we_care_about += inds.tolist()\n",
    "\n",
    "for feature in inds:\n",
    "    vals, inds = torch.topk(expanded_qk_W_dec[:, feature], 10)\n",
    "    all_features_we_care_about += inds.tolist()\n",
    "    \n",
    "all_features_we_care_about = list(set(all_features_we_care_about))\n",
    "print(len(all_features_we_care_about))\n",
    "\n",
    "\n",
    "tmp = pd.DataFrame(expanded_qk_W_dec[all_features_we_care_about,:][:,all_features_we_care_about],\n",
    "                   index = [f\"feature_{i}\" for i in all_features_we_care_about],\n",
    "                     columns = [f\"feature_{i}\" for i in all_features_we_care_about])\n",
    "\n",
    "px.imshow(tmp, color_continuous_midpoint=0, color_continuous_scale=\"RdBu\", height = 800,\n",
    "          range_color=[-1,1]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_embeddings = (sparse_autoencoder.W_dec.cpu() @ model.W_K[5,5].cpu()) + model.b_K[5,5].cpu()\n",
    "key_embeddings = key_embeddings - key_embeddings.mean(dim=0)\n",
    "key_feature_labels = [f\"key_feature_{i}\" for i in range(key_embeddings.shape[0])]\n",
    "print(key_embeddings.shape)\n",
    "\n",
    "query_embeddings = (sparse_autoencoder.W_dec.cpu() @ model.W_Q[5,5].cpu()) + model.b_Q[5,5].cpu()\n",
    "query_embeddings = query_embeddings - query_embeddings.mean(dim=0)\n",
    "query_feature_labels = [f\"query_feature_{i}\" for i in range(query_embeddings.shape[0])]\n",
    "print(query_embeddings.shape)\n",
    "\n",
    "# filter out features which are dead\n",
    "key_embeddings = key_embeddings[log_feature_sparsity>-9]\n",
    "query_embeddings = query_embeddings[log_feature_sparsity>-9]\n",
    "key_feature_labels = [key_feature_labels[i] for i in (log_feature_sparsity>-9).nonzero().squeeze().tolist()]\n",
    "query_feature_labels = [query_feature_labels[i] for i in (log_feature_sparsity>-9).nonzero().squeeze().tolist()]\n",
    "\n",
    "\n",
    "all_embeddings = torch.cat([key_embeddings, query_embeddings], dim=0)\n",
    "print(all_embeddings.shape)\n",
    "all_embeddings_labels = key_feature_labels + query_feature_labels\n",
    "print(all_embeddings_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(key_embeddings.norm(dim=-1), nbins=1000, title=\"key_embeddings\", width = 500).show()\n",
    "px.histogram(query_embeddings.norm(dim=-1), nbins=1000, title=\"key_embeddings\", width = 500).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap \n",
    "import hdbscan\n",
    "\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=10,\n",
    "    min_dist=0.0001,\n",
    "    n_components=2,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "all_embeddings_normalized = all_embeddings / all_embeddings.norm(dim=-1).unsqueeze(1)\n",
    "ummap_result = reducer.fit_transform(all_embeddings_normalized.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "umap_df = pd.DataFrame(ummap_result, columns=[\"ummap_x\", \"ummap_y\"])\n",
    "umap_df[\"feature_sparsity\"] = log_feature_sparsity[log_feature_sparsity>-9].detach().cpu().numpy().tolist() + log_feature_sparsity[log_feature_sparsity>-9].detach().cpu().numpy().tolist()\n",
    "umap_df[\"label\"] = all_embeddings_labels\n",
    "umap_df[\"key_or_query\"] = [\"key\"]*len(key_feature_labels) + [\"query\"]*len(query_feature_labels)\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10)\n",
    "clusterer.fit(ummap_result)\n",
    "umap_df[\"cluster\"] = clusterer.labels_\n",
    "umap_df[\"cluster\"] = umap_df[\"cluster\"].astype(str)\n",
    "umap_df[\"feature_sparsity\"] = log_feature_sparsity[log_feature_sparsity>-9].detach().cpu().numpy().tolist() + log_feature_sparsity[log_feature_sparsity>-9].detach().cpu().numpy().tolist()\n",
    "umap_df[\"label\"] = all_embeddings_labels\n",
    "umap_df[\"key_or_query\"] = [\"key\"]*len(key_feature_labels) + [\"query\"]*len(query_feature_labels)\n",
    "\n",
    "fig = px.scatter(\n",
    "        umap_df,\n",
    "        x=\"ummap_x\",\n",
    "        y=\"ummap_y\",\n",
    "        # color=\"key_or_query\",\n",
    "        color=\"feature_sparsity\",\n",
    "        # color=\"cluster\",\n",
    "        color_continuous_midpoint=-2,\n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        hover_name=\"label\",\n",
    "        hover_data=[\"feature_sparsity\", \"cluster\", \"key_or_query\"],\n",
    "        # opacity=0.1,\n",
    "        template=\"plotly\",\n",
    "    )\n",
    "\n",
    "# don't show legend\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# make points larger\n",
    "fig.update_traces(marker=dict(size=4))\n",
    "\n",
    "# make it wide and tall\n",
    "fig.update_layout(height=1200, width=1600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_label = \"query_feature_18\"\n",
    "query_embedding_feature_normalized = query_embeddings[query_feature_labels.index(feature_label)] / query_embeddings[query_feature_labels.index(feature_label)].norm()\n",
    "umap_df[\"cosine_distance_with_query_feature_18\"] = 1 - (all_embeddings_normalized @ query_embedding_feature_normalized).detach().cpu().numpy()\n",
    "feature_index_in_all_embeddings = query_feature_labels.index(feature_label) + len(key_feature_labels) if \"query\" in feature_label else key_feature_labels.index(feature_label)\n",
    "umap_df[\"umap_distance_from_query_feature_18\"] = np.linalg.norm((ummap_result - ummap_result[feature_index_in_all_embeddings]), axis=1)\n",
    "# umap_df.sort_values(\"distance_from_query_feature_18\", ascending=True).head(10)\n",
    "\n",
    "\n",
    "display(umap_df[(umap_df.label == \"key_feature_86\") | (umap_df.label == \"query_feature_18\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the spearman rank correlation between cosine distance and umap distance\n",
    "from scipy.stats import spearmanr\n",
    "print(spearmanr(umap_df[\"cosine_distance_with_query_feature_18\"], umap_df[\"umap_distance_from_query_feature_18\"]))\n",
    "\n",
    "px.scatter(\n",
    "    umap_df,\n",
    "    x=\"cosine_distance_with_query_feature_18\",\n",
    "    y=\"umap_distance_from_query_feature_18\",\n",
    "    color = \"key_or_query\",\n",
    "    color_continuous_midpoint=0,\n",
    "    color_continuous_scale=\"RdBu\",\n",
    "    hover_name=\"label\",\n",
    "    hover_data=[\"feature_sparsity\", \"cluster\", \"key_or_query\"],\n",
    "    template=\"plotly\",\n",
    "    marginal_x=\"histogram\",\n",
    "    marginal_y=\"histogram\",\n",
    "    height=1000,\n",
    "    width=1000,\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_df.sort_values(\"cosine_distance_with_query_feature_18\", ascending=True).query(\"key_or_query=='key'\").head(10).style.background_gradient(\n",
    "    cmap=\"coolwarm\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by cluster and get the ratio of key to query features, but also track the size\n",
    "cluster_ratio_df = tmp_df.groupby(\"cluster\").agg({\"key_or_query\": lambda x: (x==\"key\").mean(), \"label\": \"count\"}).reset_index()\n",
    "cluster_ratio_df = cluster_ratio_df.rename(columns={\"label\": \"size\"})\n",
    "# remove outlier\n",
    "cluster_ratio_df = cluster_ratio_df[cluster_ratio_df[\"cluster\"]!=\"-1\"]\n",
    "cluster_ratio_df[\"n_key\"] = cluster_ratio_df[\"key_or_query\"] * cluster_ratio_df[\"size\"]\n",
    "cluster_ratio_df[\"n_query\"] = cluster_ratio_df[\"size\"] - cluster_ratio_df[\"n_key\"]\n",
    "\n",
    "px.scatter(cluster_ratio_df, x=\"n_key\", y=\"n_query\", color=\"size\", hover_name=\"cluster\", hover_data=[\"size\", \"key_or_query\"], title=\"Cluster size vs ratio of key to query features\")\n",
    "# px.bar(cluster_ratio_df.sort_values(\"key_or_query\", ascending=False), x=\"cluster\", y=\"key_or_query\", \n",
    "#        color=\"size\",\n",
    "#        title=\"Ratio of key to query features in each cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a cluster and sample the dashboards\n",
    "cluster_of_interest = 913\n",
    "cluster_examples = tmp_df[tmp_df[\"cluster\"]==str(cluster_of_interest)].sample(5)\n",
    "display(cluster_examples)\n",
    "for feature in cluster_examples[\"label\"]:\n",
    "    render_feature_dashboard(feature.split(\"_\")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
