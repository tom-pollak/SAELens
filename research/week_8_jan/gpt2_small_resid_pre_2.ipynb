{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2-Small Resid Pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from importlib import reload\n",
    "from tqdm import tqdm\n",
    "\n",
    "import joseph\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "\n",
    "reload(joseph.analysis)\n",
    "reload(joseph.visualisation)\n",
    "reload(joseph.utils)\n",
    "reload(joseph.data)\n",
    "\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "# turn torch grad tracking off\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# run = wandb.init()\n",
    "# artifact = run.use_artifact('jbloom/mats_sae_training_gpt2_small_resid_pre/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152:v28', type='model')\n",
    "# artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    # \"tiny-stories-2L-33M\",\n",
    "    # \"attn-only-2l\",\n",
    "    # center_unembed=True,\n",
    "    # center_writing_weights=True,\n",
    "    # fold_ln=True,\n",
    "    # refactor_factored_attn_matrices=True,\n",
    "    fold_ln=True,\n",
    ")\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)\n",
    "\n",
    "\n",
    "path = \"./artifacts/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152:v28/1100001280_sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152.pt\"\n",
    "# path = \"./artifacts/sparse_autoencoder_gpt2-small_blocks.5.hook_resid_pre_49152:v9/final_sparse_autoencoder_gpt2-small_blocks.5.hook_resid_pre_49152.pt\"\n",
    "sparse_autoencoder = SparseAutoencoder.load_from_pretrained(path)\n",
    "\n",
    "print(sparse_autoencoder.cfg)\n",
    "\n",
    "\n",
    "# sanity check\n",
    "text = \"Many important transition points in the history of science have been moments when science 'zoomed in.' At these points, we develop a visualization or tool that allows us to see the world in a new level of detail, and a new field of science develops to study the world through this lens.\"\n",
    "model(text, return_type=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_training.utils import LMSparseAutoencoderSessionloader\n",
    "model, sparse_autoencoder, activation_store = LMSparseAutoencoderSessionloader.load_session_from_pretrained(\n",
    "    path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def estimate_feature_sparsity_using_n_tokens_per_prompt(\n",
    "    sparse_autoencoder, activation_store, n_batches,\n",
    "    n_tokens_per_prompt=4):\n",
    "    \n",
    "    total_activations = torch.zeros(sparse_autoencoder.cfg.d_sae).to(sparse_autoencoder.cfg.device)\n",
    "    \n",
    "    pbar = tqdm(range(n_batches))\n",
    "    for _ in pbar:\n",
    "        batch_tokens = activation_store.get_batch_tokens()\n",
    "        _, cache = model.run_with_cache(batch_tokens, prepend_bos=False)\n",
    "        original_act = cache[sparse_autoencoder.cfg.hook_point]\n",
    "        _, feature_acts, _, _, _ = sparse_autoencoder(\n",
    "            original_act\n",
    "        )\n",
    "        # for each batch item, pick 4 random tokens and keep only those\n",
    "        # batch_size x n_tokens x d_sae\n",
    "        random_tok_indices = torch.randint(0, feature_acts.shape[1], (feature_acts.shape[0], n_tokens_per_prompt))\n",
    "        feature_acts = feature_acts[torch.arange(feature_acts.shape[0]).unsqueeze(-1), random_tok_indices]\n",
    "        total_activations += feature_acts.flatten(0,1).sum(0)\n",
    "    \n",
    "    total_tokens = (n_batches * feature_acts.shape[0] * n_tokens_per_prompt)\n",
    "    print(\"Total tokens:\", total_tokens)\n",
    "    \n",
    "    return total_activations / total_tokens\n",
    "\n",
    "\n",
    "# feature_sparsity = estimate_feature_sparsity_using_n_tokens_per_prompt(sparse_autoencoder, activation_store, 5000).detach().cpu()\n",
    "# log_feature_sparsity = torch.log10(feature_sparsity + 1e-10)\n",
    "# torch.save(log_feature_sparsity, \"./artifacts/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152:v28/log_feature_sparsity_5000_4.pt\")\n",
    "\n",
    "# log_feature_sparsity = torch.load(\"./artifacts/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152:v28/log_feature_sparsity_5000_4.pt\")\n",
    "log_feature_sparsity = torch.load(\"./artifacts/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152:v28/log_feature_sparsity_5000_4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(log_feature_sparsity+1e-10, nbins=100, log_x=False, title=\"Feature sparsity (log10) (5000 batches, 4 tokens per prompt)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sae_df(sparse_autoencoder):\n",
    "    \n",
    "    W_enc_normalized = sparse_autoencoder.W_enc / sparse_autoencoder.W_enc.norm(dim=-2, keepdim=True)\n",
    "    d_e_projection = (sparse_autoencoder.W_dec @ sparse_autoencoder.W_enc).diag().detach().cpu()\n",
    "    px.histogram(d_e_projection, nbins=100, log_x=False, title=\"d_e projection\").show()\n",
    "\n",
    "\n",
    "    d_e_projection_normalized = (sparse_autoencoder.W_dec @ W_enc_normalized).diag().detach().cpu()\n",
    "    px.histogram(d_e_projection_normalized, nbins=100, log_x=False, title=\"d_e projection\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "W_enc_normalized = sparse_autoencoder.W_enc / sparse_autoencoder.W_enc.norm(dim=-2, keepdim=True)\n",
    "d_e_projection = (sparse_autoencoder.W_dec @ sparse_autoencoder.W_enc).diag().detach().cpu()\n",
    "px.histogram(d_e_projection, nbins=100, log_x=False, title=\"d_e projection\").show()\n",
    "\n",
    "\n",
    "d_e_projection_normalized = (sparse_autoencoder.W_dec @ W_enc_normalized).diag().detach().cpu()\n",
    "px.histogram(d_e_projection_normalized, nbins=100, log_x=False, title=\"d_e projection\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({\n",
    "    \"log_feature_sparsity\": log_feature_sparsity,\n",
    "    \"d_e_projection\": d_e_projection,\n",
    "    \"d_e_projection_normalized\": d_e_projection_normalized,\n",
    "    \"b_enc\": sparse_autoencoder.b_enc.detach().cpu(),\n",
    "    \"feature\": [f\"feature_{i}\" for i in range(sparse_autoencoder.cfg.d_sae)],\n",
    "    \"index\": torch.arange(sparse_autoencoder.cfg.d_sae)\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=30)\n",
    "clusterer.fit(temp_df[[\"log_feature_sparsity\", \"d_e_projection\", \"b_enc\"]].values)\n",
    "temp_df[\"cluster\"] = clusterer.labels_\n",
    "temp_df[\"cluster_categorical\"] = temp_df[\"cluster\"].astype(str)\n",
    "temp_df[\"outlier\"] = (temp_df.log_feature_sparsity < -9) | (temp_df.cluster == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(temp_df.cluster.value_counts().reset_index(),\n",
    "       y = \"count\",\n",
    "       color = \"cluster\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter_3d(\n",
    "    # temp_df,#[~temp_df.outlier],\n",
    "    temp_df[~temp_df.outlier],\n",
    "    x=\"log_feature_sparsity\",\n",
    "    y=\"d_e_projection\",\n",
    "    z=\"b_enc\",\n",
    "    color=\"cluster\",\n",
    "    # color=\"index\",\n",
    "    hover_name=\"feature\",\n",
    ")\n",
    "fig.update_layout(\n",
    "    scene = dict(\n",
    "        xaxis_title='log10 feature sparsity',\n",
    "        yaxis_title='D/E Projection',\n",
    "        zaxis_title='Encoder Bias',\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_traces(marker_size = 2)\n",
    "fig.update_layout(\n",
    "    title=\"Feature Sparsity vs D/E projection vs Encoder Bias (Excluding Outliers)\",\n",
    "    width=1400,\n",
    "    height=1300,\n",
    ") \n",
    "\n",
    "# increase font size everywhere\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "\n",
    "# increase marker size in legend (only)\n",
    "fig.update_layout(legend= {'itemsizing': 'constant'})\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_matrix(\n",
    "    temp_df[~temp_df.outlier],\n",
    "    dimensions = [\"log_feature_sparsity\", \"d_e_projection\", \"b_enc\"],\n",
    "    color=\"cluster\",\n",
    "    hover_name=\"feature\",\n",
    "    opacity=0.3,\n",
    "    height=1400,\n",
    "    width =1400,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.parallel_coordinates(\n",
    "    temp_df[~temp_df.outlier],\n",
    "    color=\"cluster\",\n",
    "    dimensions = [\"log_feature_sparsity\", \"d_e_projection\", \"b_enc\",\"cluster\", \"index\"],\n",
    "    # color_continuous_scale=px.colors.diverging.Tealrose,\n",
    "    height=1400,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in temp_df[~temp_df.outlier].cluster.unique():\n",
    "    print(f\"Cluster {cluster}\")\n",
    "    display(temp_df[temp_df.cluster == cluster].sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    temp_df[~temp_df.outlier], \n",
    "    x=\"b_enc\", color=\"cluster\", title=\"Cluster sizes\", barmode=\"overlay\",\n",
    "    histnorm=\"percent\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alive_features = (log_feature_sparsity > -8).nonzero()\n",
    "print(len(alive_features) / log_feature_sparsity.shape[0])\n",
    "\n",
    "dead_features = (log_feature_sparsity <= -8).nonzero()\n",
    "print(len(dead_features) / log_feature_sparsity.shape[0])\n",
    "\n",
    "dense_mode_features = ((log_feature_sparsity > -3.5) & (log_feature_sparsity < -1) ).nonzero()\n",
    "print(len(dense_mode_features) / log_feature_sparsity.shape[0])\n",
    "\n",
    "sparse_mode_features = ((log_feature_sparsity > -7) & (log_feature_sparsity < -4) ).nonzero()\n",
    "print(len(sparse_mode_features) / log_feature_sparsity.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 13\n",
    "cluster_13_features = temp_df[(temp_df.cluster == 13)].index.values\n",
    "print(len(cluster_13_features) / log_feature_sparsity.shape[0])\n",
    "print(len(cluster_13_features))\n",
    "\n",
    "cluster_10_features = temp_df[(temp_df.cluster == 10)].index.values\n",
    "print(len(cluster_10_features) / log_feature_sparsity.shape[0])\n",
    "print(len(cluster_10_features))\n",
    "\n",
    "W_dec_cluster_10_features = sparse_autoencoder.W_dec[cluster_13_features].squeeze(1)\n",
    "W_dec_cluster_13_features = sparse_autoencoder.W_dec[cluster_10_features].squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = sparse_autoencoder.cfg.hook_point_layer\n",
    "print(layer)\n",
    "W_QK_10 = torch.stack(\n",
    "    [model.W_Q[layer,i] @ model.W_K[layer,i].T for i in range(12)],\n",
    "    dim=0\n",
    ")\n",
    "\n",
    "W_dec_alive_features = sparse_autoencoder.W_dec[alive_features].squeeze(1)\n",
    "W_dec_dead_features = sparse_autoencoder.W_dec[dead_features].squeeze(1)\n",
    "W_dec_dense_mode_features = sparse_autoencoder.W_dec[dense_mode_features].squeeze(1)\n",
    "W_dec_sparse_mode_features = sparse_autoencoder.W_dec[sparse_mode_features].squeeze(1)\n",
    "\n",
    "\n",
    "def get_feature_weight_proj(W_dec_features, feature_indices):\n",
    "\n",
    "\n",
    "    # query_proj_dec_weights = sparse_autoencoder.W_dec @ W_QK_10\n",
    "    query_proj_dec_weights = W_dec_features @ W_QK_10\n",
    "    # query_proj_dec_weights = W_dec_features @ model.W_Q[10,:]\n",
    "    query_proj_dec_weights_df = pd.DataFrame(\n",
    "        query_proj_dec_weights.norm(dim=-1).detach().cpu().numpy().T,\n",
    "        columns = [f\"L{layer}H\" + str(i) for i in range(12)],\n",
    "        index = [f\"feature_{i}\" for i in feature_indices])\n",
    "\n",
    "    print(query_proj_dec_weights_df.shape)\n",
    "    px.histogram(\n",
    "        query_proj_dec_weights_df,\n",
    "        x=query_proj_dec_weights_df.columns,\n",
    "        facet_col='variable',\n",
    "        facet_col_wrap=3,\n",
    "        # barmode='overlay',\n",
    "        title = \"Query projection onto decoder weights\",\n",
    "    ).show()\n",
    "\n",
    "    # key_proj_dec_weights = sparse_autoencoder.W_dec @ W_QK_10.transpose(2,1)\n",
    "    key_proj_dec_weights = W_dec_features @ W_QK_10.transpose(2,1)\n",
    "    # key_proj_dec_weights = W_dec_features @ model.W_K[10,:]\n",
    "    key_proj_dec_weights_df = pd.DataFrame(\n",
    "        key_proj_dec_weights.norm(dim=-1).detach().cpu().numpy().T,\n",
    "        columns = [f\"L{layer}H\" + str(i) for i in range(12)],\n",
    "        index = [f\"feature_{i}\" for i in feature_indices])\n",
    "    \n",
    "    \n",
    "    print(key_proj_dec_weights_df.shape)\n",
    "    px.histogram(\n",
    "        key_proj_dec_weights_df,\n",
    "        x=key_proj_dec_weights_df.columns,\n",
    "        facet_col='variable',\n",
    "        facet_col_wrap=3,\n",
    "        # barmode='overlay',\n",
    "        title = \"Key projection onto decoder weights\",\n",
    "    ).show()\n",
    "\n",
    "    return query_proj_dec_weights_df, key_proj_dec_weights_df\n",
    "\n",
    "\n",
    "# print(\"All Alive Features\")\n",
    "# query_proj_dec_weights_df, key_proj_dec_weights_df = get_feature_weight_proj(W_dec_alive_features, alive_features)\n",
    "print(\"Dense Mode Features\")\n",
    "query_proj_dec_weights_df, key_proj_dec_weights_df = get_feature_weight_proj(W_dec_dense_mode_features, dense_mode_features)\n",
    "\n",
    "print(\"Sparse Mode Features\")\n",
    "query_proj_dec_weights_df, key_proj_dec_weights_df = get_feature_weight_proj(W_dec_sparse_mode_features, sparse_mode_features)\n",
    "\n",
    "\n",
    "for cluster in [11]:#temp_df[~temp_df.outlier].cluster.unique():\n",
    "    print(f\"Cluster {cluster}\")\n",
    "    cluster_x_features = temp_df[(temp_df.cluster == cluster)].index.values\n",
    "    print(len(cluster_x_features) / log_feature_sparsity.shape[0])\n",
    "    print(len(cluster_x_features))\n",
    "    W_dec_cluster_x_features = sparse_autoencoder.W_dec[cluster_x_features].squeeze(1)\n",
    "    query_proj_dec_weights_df_16, key_proj_dec_weights_df_16 = get_feature_weight_proj(W_dec_cluster_x_features, cluster_x_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 10\n",
    "print(model.W_Q.shape)\n",
    "W_QK_10 = torch.stack(\n",
    "    [model.W_Q[layer,i] @ model.W_K[layer,i].T for i in range(model.cfg.n_heads)],\n",
    "    dim=0\n",
    ")\n",
    "\n",
    "# calculate the singular values of the query projection matrix\n",
    "U, S, V = torch.svd(W_QK_10)\n",
    "print(S.shape)\n",
    "print(U.shape)\n",
    "print(V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_dec_sparse_mode_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram((W_dec_sparse_mode_features @ U)[0].diag().detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram((W_dec_sparse_mode_features @ V)[0].diag().detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_proj_dec_weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_proj_dec_weights_df_16.index = temp_df_16.index.astype(str).str.replace(\"feature_\", \"\")\n",
    "query_proj_dec_weights_df_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(\n",
    "    query_proj_dec_weights_df_16,\n",
    "    dimensions=query_proj_dec_weights_df_16.columns,\n",
    "    color=log_feature_sparsity[temp_df_16.index],\n",
    "    # color=range(sparse_autoencoder.cfg.d_sae),\n",
    "    color_continuous_scale='RdBu',\n",
    "    opacity=0.3,\n",
    "    hover_data=[query_proj_dec_weights_df_16.index],\n",
    ")\n",
    "fig.update_layout(width = 1800, height = 1800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(\n",
    "    key_proj_dec_weights_df_16,\n",
    "    dimensions=key_proj_dec_weights_df_16.columns,\n",
    "    color=log_feature_sparsity[temp_df_16.index],\n",
    "    # color=range(sparse_autoencoder.cfg.d_sae),\n",
    "    color_continuous_scale='RdBu',\n",
    "    opacity=0.3,\n",
    "    hover_data=[key_proj_dec_weights_df_16.index],\n",
    ")\n",
    "fig.update_layout(width = 1800, height = 1800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    y = key_proj_dec_weights_df_16[\"L10H7\"],\n",
    "    x=log_feature_sparsity[temp_df_16.index],\n",
    "    # color=range(sparse_autoencoder.cfg.d_sae),\n",
    "    color_continuous_scale='RdBu',\n",
    "    opacity=0.3,\n",
    "    hover_data=[key_proj_dec_weights_df_16.index],\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap \n",
    "import hdbscan\n",
    "\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.01,\n",
    "    n_components=2,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "ummap_result = reducer.fit_transform(sparse_autoencoder.W_dec.detach().cpu())\n",
    "temp_df[\"ummap_x\"] = ummap_result[:,0]\n",
    "temp_df[\"ummap_y\"] = ummap_result[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "        temp_df,#[~temp_df.outlier],\n",
    "        x=\"ummap_x\",\n",
    "        y=\"ummap_y\",\n",
    "        color=\"cluster_categorical\",\n",
    "        # color_continuous_midpoint=0,\n",
    "        # color_continuous_scale=\"RdBu\",\n",
    "        hover_name=\"feature\",\n",
    "        opacity=0.5,\n",
    "        template=\"plotly\",\n",
    "    )\n",
    "\n",
    "# make points larger\n",
    "# fig.update_traces(marker=dict(size=12))\n",
    "\n",
    "# make it wide and tall\n",
    "fig.update_layout(height=800, width=1200)\n",
    "    \n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.iloc[[\n",
    "    14627,44798,6259, \n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_proj_dec_weights_df, key_proj_dec_weights_df = get_feature_weight_proj(W_dec_sparse_mode_features, sparse_mode_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " temp_df[~temp_df.outlier].cluster.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x = 13\n",
    "# cluster_13_features = temp_df[(temp_df.cluster == 13)].index.values\n",
    "# print(len(cluster_13_features) / log_feature_sparsity.shape[0])\n",
    "# print(len(cluster_13_features))\n",
    "\n",
    "# cluster_10_features = temp_df[(temp_df.cluster == 10)].index.values\n",
    "# print(len(cluster_10_features) / log_feature_sparsity.shape[0])\n",
    "# print(len(cluster_10_features))\n",
    "\n",
    "# W_dec_cluster_10_features = sparse_autoencoder.W_dec[cluster_13_features].squeeze(1)\n",
    "W_dec_cluster_13_features = sparse_autoencoder.W_dec[cluster_10_features].squeeze(1)\n",
    "\n",
    "lines = []\n",
    "for cluster in temp_df[~temp_df.outlier].cluster.unique():\n",
    "    feature_idxs =  temp_df[(temp_df.cluster == cluster)].index.values\n",
    "    # features =  sparse_autoencoder.W_dec[cluster_13_features]\n",
    "    print(sparse_autoencoder.W_dec[feature_idxs].mean(0).detach().cpu().shape)\n",
    "    lines.append(\n",
    "        sparse_autoencoder.W_dec[feature_idxs].mean(0).detach().cpu()\n",
    "    )\n",
    "\n",
    "\n",
    "lines = torch.stack(lines).T\n",
    "px.line(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in temp_df[~temp_df.outlier].cluster.unique():\n",
    "    # get the first 10 features\n",
    "    cluster_x_features = temp_df[(temp_df.cluster == cluster)].index.values\n",
    "    px.line(sparse_autoencoder.W_dec[cluster_x_features].mean(0).detach().cpu(), title=f\"Cluster {cluster} mean W_dec\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(query_proj_dec_weights_df.corr(), color_continuous_scale='RdBu', title = \"Query projection weights\", color_continuous_midpoint=0).show()\n",
    "px.imshow(key_proj_dec_weights_df.corr(), color_continuous_scale='RdBu', title = \"Key projection weights\", color_continuous_midpoint=0).show()\n",
    "# px.imshow(value_proj_dec_weights_df.corr(), color_continuous_scale='RdBu', title = \"Value projection weights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(query_proj_dec_weights_df_16.corr(), color_continuous_scale='RdBu', title = \"Query projection weights\", color_continuous_midpoint=0).show()\n",
    "px.imshow(key_proj_dec_weights_df_16.corr(), color_continuous_scale='RdBu', title = \"Key projection weights\", color_continuous_midpoint=0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = W_QK_10 @ sparse_autoencoder.b_dec\n",
    "px.bar(tmp.norm(dim=-1).detach().cpu().numpy().T, title=\"Query projection onto decoder bias\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = W_QK_10.transpose(2,1) @ sparse_autoencoder.b_dec\n",
    "px.bar(tmp.norm(dim=-1).detach().cpu().numpy().T, title=\"Query projection onto decoder bias\").show()\n",
    "px.scatter(\n",
    "    y = (W_QK_10.transpose(2,1) @ sparse_autoencoder.b_dec).norm(dim=-1).detach().cpu().numpy().T,\n",
    "    x = (W_QK_10 @ sparse_autoencoder.b_dec).norm(dim=-1).detach().cpu().numpy().T,\n",
    "    hover_name = [f\"L10H{i}\" for i in range(12)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_proj_dec_weights_df, key_proj_dec_weights_df = get_feature_weight_proj(W_dec_alive_features, alive_features)\n",
    "query_proj_dec_weights_df, key_proj_dec_weights_df = get_feature_weight_proj(W_dec_sparse_mode_features, sparse_mode_features)\n",
    "query_proj_dec_weights_df, key_proj_dec_weights_df = get_feature_weight_proj(W_dec_sparse_mode_features, sparse_mode_features)\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    query_proj_dec_weights_df,\n",
    "    dimensions=query_proj_dec_weights_df.columns,\n",
    "    color=log_feature_sparsity,\n",
    "    # color=range(sparse_autoencoder.cfg.d_sae),\n",
    "    color_continuous_scale='RdBu',\n",
    "    opacity=0.3,\n",
    "    hover_data=[query_proj_dec_weights_df.index],\n",
    ")\n",
    "fig.update_layout(width = 1800, height = 1800)\n",
    "fig.show()\n",
    "\n",
    "# fig = px.scatter_matrix(\n",
    "#     key_proj_dec_weights_df,\n",
    "#     dimensions=key_proj_dec_weights_df.columns,\n",
    "#     color=range(sparse_autoencoder.cfg.d_sae),\n",
    "#     # color=log_feature_sparsity,\n",
    "#     opacity=0.3,\n",
    "#     hover_data=[key_proj_dec_weights_df.index],\n",
    "# )\n",
    "# fig.update_layout(width = 1800, height = 1800)\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter(\n",
    "    x = query_proj_dec_weights_df[\"L10H5\"],\n",
    "    y = log_feature_sparsity,\n",
    "    hover_name=query_proj_dec_weights_df.index,\n",
    "    opacity=0.5,\n",
    "    marginal_x=\"histogram\",\n",
    "    marginal_y=\"histogram\",\n",
    "    labels={\n",
    "        \"x\": \"Feature Norm after Query Projection\",\n",
    "        \"y\": \"Feature Norm after Key Projection\",\n",
    "        \"color\": \"Sparsity\",\n",
    "    },\n",
    ")\n",
    "fig.update_layout(width = 1200, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    query_proj_dec_weights_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate first 8192 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(sparse_autoencoder.W_dec.norm(dim=-1).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(sparse_autoencoder.W_enc.norm(dim=0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_autoencoder.W_enc.norm(dim=0, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_W_enc = sparse_autoencoder.W_enc / sparse_autoencoder.W_enc.norm(dim=0, keepdim=True)\n",
    "\n",
    "sim = normalized_W_enc.T @ normalized_W_enc\n",
    "print(sim.shape)\n",
    "px.imshow(sim[:1000,:1000].detach().cpu().numpy(), color_continuous_scale='RdBu', title = \"Encoder weight similarity (first 1000)\").show()\n",
    "print(sim[:1000,:1000].detach().cpu().numpy().flatten().mean())\n",
    "px.imshow(sim[-1000:,-1000:].detach().cpu().numpy(), color_continuous_scale='RdBu', title = \"Encoder weight similarity (last 1000)\").show()\n",
    "print(sim[-1000:,-1000:].detach().cpu().numpy().flatten().mean())\n",
    "px.imshow(sim[:1000,-1000:].detach().cpu().numpy(), color_continuous_scale='RdBu', title = \"Encoder weight similarity (first 1000 to last 1000)\").show()\n",
    "print(sim[:1000,-1000:].detach().cpu().numpy().flatten().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = sparse_autoencoder.W_dec @ sparse_autoencoder.W_dec.T\n",
    "print(sim.shape)\n",
    "px.imshow(sim[:1000,:1000].detach().cpu().numpy(), color_continuous_scale='RdBu', title = \"Decoder weight similarity (first 1000)\").show()\n",
    "print(sim[:1000,:1000].detach().cpu().numpy().flatten().mean())\n",
    "px.imshow(sim[-1000:,-1000:].detach().cpu().numpy(), color_continuous_scale='RdBu', title = \"Decoder weight similarity (last 1000)\").show()\n",
    "print(sim[-1000:,-1000:].detach().cpu().numpy().flatten().mean())\n",
    "px.imshow(sim[:1000,-1000:].detach().cpu().numpy(), color_continuous_scale='RdBu', title = \"Decoder weight similarity (first 1000 to last 1000)\").show()\n",
    "print(sim[:1000,-1000:].detach().cpu().numpy().flatten().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(sparse_autoencoder.b_dec.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_norm_b_dec = sparse_autoencoder.b_dec / sparse_autoencoder.b_dec.norm(dim=-1, keepdim=True)\n",
    "px.line(unit_norm_b_dec.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line((sparse_autoencoder.W_dec[:500] @ unit_norm_b_dec).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    x = range(sparse_autoencoder.cfg.d_sae),\n",
    "    y = (sparse_autoencoder.W_dec @ unit_norm_b_dec).detach().cpu(),\n",
    "    marginal_y=\"histogram\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centred_W_dec = sparse_autoencoder.W_dec  - sparse_autoencoder.W_dec.mean(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_with_bias = sparse_autoencoder.W_dec @ unit_norm_b_dec\n",
    "most_sim_values, most_sim_indices = torch.topk(cosine_similarity_with_bias, 10, dim=0)\n",
    "px.line(sparse_autoencoder.W_dec[most_sim_indices].detach().cpu().T).show()\n",
    "least_sim_values, least_sim_indices = torch.topk(cosine_similarity_with_bias, 10, dim=0, largest=False)\n",
    "px.line(sparse_autoencoder.W_dec[least_sim_indices].detach().cpu().T).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_examples = ((cosine_similarity_with_bias > -0.01) & (cosine_similarity_with_bias < 0.01)).nonzero(as_tuple=True)[0][:10]\n",
    "px.line(sparse_autoencoder.W_dec[normal_examples].detach().cpu().mean(dim=0, keepdim=True).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_peak_examples = ((cosine_similarity_with_bias > 0.09) & (cosine_similarity_with_bias < 0.11)).nonzero(as_tuple=True)[0][:10]\n",
    "px.line(sparse_autoencoder.W_dec[weird_peak_examples].detach().cpu().mean(dim=0).unsqueeze(0).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(sparse_autoencoder.W_dec[:8192].detach().abs().cpu().mean(dim=0).unsqueeze(0).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    sparse_autoencoder.W_dec[:8192].detach().abs().cpu().mean(dim=0).unsqueeze(0).T -sparse_autoencoder.W_dec[8192:].detach().cpu().abs().mean(dim=0).unsqueeze(0).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Tangent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter(\n",
    "    y = query_proj_dec_weights_df[\"L5H5\"],\n",
    "    x = range(len(query_proj_dec_weights_df)),\n",
    "    hover_name=query_proj_dec_weights_df.index,\n",
    "    opacity=0.5,\n",
    "    marginal_x=\"histogram\",\n",
    "    marginal_y=\"histogram\",\n",
    "    labels={\n",
    "        \"y\": \"Feature Norm after Query Projection\",\n",
    "        \"x\": \"Index\",\n",
    "    },\n",
    ")\n",
    "fig.update_layout(width = 1200, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter(\n",
    "    x = query_proj_dec_weights_df[\"L10H6\"],\n",
    "    y = log_feature_sparsity,\n",
    "    hover_name=query_proj_dec_weights_df.index,\n",
    "    opacity=0.5,\n",
    "    marginal_x=\"histogram\",\n",
    "    marginal_y=\"histogram\",\n",
    "    labels={\n",
    "        \"x\": \"Feature Norm after Query Projection\",\n",
    "        \"y\": \"Sparsity\",\n",
    "    },\n",
    ")\n",
    "fig.update_layout(width = 1200, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter(\n",
    "    x = key_proj_dec_weights_df[\"L10H7\"],\n",
    "    y = log_feature_sparsity,\n",
    "    hover_name=query_proj_dec_weights_df.index,\n",
    "    opacity=0.5,\n",
    "    marginal_x=\"histogram\",\n",
    "    marginal_y=\"histogram\",\n",
    "    labels={\n",
    "        \"x\": \"Feature Norm after Query Projection\",\n",
    "        \"y\": \"Sparisity\",\n",
    "    },\n",
    ")\n",
    "fig.update_layout(width = 1200, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter(\n",
    "    x = query_proj_dec_weights_df[\"L10H9\"],\n",
    "    y = key_proj_dec_weights_df[\"L10H9\"],\n",
    "    hover_name=query_proj_dec_weights_df.index,\n",
    "    color = [i for i in range(sparse_autoencoder.cfg.d_sae)],# log_feature_sparsity,\n",
    "    opacity=0.5,\n",
    "    marginal_x=\"histogram\",\n",
    "    marginal_y=\"histogram\",\n",
    "    labels={\n",
    "        \"x\": \"Feature Norm after Query Projection\",\n",
    "        \"y\": \"Feature Norm after Key Projection\",\n",
    "        \"color\": \"Sparsity\",\n",
    "    },\n",
    ")\n",
    "fig.update_layout(width = 1200, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all the files in the directy \"gpt2_small_features\"\n",
    "import os\n",
    "\n",
    "feature_list = [int(i.split(\".html\")[0].split(\"data_\")[1]) for i in os.listdir(\"./gpt2_small_features\")]\n",
    "feature_list_df = pd.DataFrame(\n",
    "    {\"features\": feature_list,\n",
    "    \"sparsity\": log_feature_sparsity[feature_list],\n",
    "    \"query_norm\": query_proj_dec_weights_df[\"L10H7\"][feature_list],\n",
    "    \"key_norm\": key_proj_dec_weights_df[\"L10H7\"][feature_list]}\n",
    ")\n",
    "feature_list_df.sort_values(\"sparsity\").head(10)\n",
    "\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    feature_list_df,\n",
    "    dimensions=[\"query_norm\", \"key_norm\", \"sparsity\"],\n",
    "    color = feature_list_df[\"features\"],\n",
    "    hover_name = feature_list_df[\"features\"],\n",
    "    opacity=0.5,\n",
    "    # marginal_x=\"histogram\",\n",
    "    # marginal_y=\"histogram\",\n",
    "    labels={\n",
    "        \"x\": \"Feature Norm after Query Projection\",\n",
    "        \"y\": \"Feature Norm after Key Projection\",\n",
    "        \"color\": \"Sparsity\",\n",
    "    },\n",
    ")\n",
    "fig.update_layout(width = 1200, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(sparse_autoencoder.W_dec.norm(dim=-1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qk_full = sparse_autoencoder.W_dec[feature_list] @ W_QK_10 @ sparse_autoencoder.W_dec[feature_list].T\n",
    "fig = px.imshow(qk_full.detach().cpu().numpy(), animation_frame=0,\n",
    "          color_continuous_scale='RdBu', color_continuous_midpoint=0, title = \"Query Key Correlation\")\n",
    "\n",
    "# add feature labels to ticks\n",
    "fig.update_xaxes(ticktext=feature_list_df[\"features\"], tickvals=feature_list_df.index)\n",
    "fig.update_yaxes(ticktext=feature_list_df[\"features\"], tickvals=feature_list_df.index)\n",
    "\n",
    "fig.update_layout(width = 800, height = 1200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacement_hook(mlp_post, hook, encoder):\n",
    "    mlp_post_reconstr = encoder(mlp_post)[0]\n",
    "    return mlp_post_reconstr\n",
    "hook_point = activation_store.cfg.hook_point\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_tokens = activation_store.get_batch_tokens()\n",
    "    _, cache = model.run_with_cache(batch_tokens, prepend_bos=False)\n",
    "    original_act = cache[sparse_autoencoder.cfg.hook_point]#[:,:,sparse_autoencoder.cfg.hook_point_head_index]\n",
    "    sae_out, feature_acts, loss, mse_loss, l1_loss = sparse_autoencoder(\n",
    "        original_act\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(original_act.flatten(0,1).mean(0).detach().cpu().numpy(), title=\"Original Activation by Position\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_str_tokens(batch_tokens.flatten())\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_act.flatten(0,1)[:,outlier_dimensions].detach().cpu().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_dimensions = (original_act.flatten(0,1).mean(0).detach().cpu().abs() >20).nonzero().squeeze().tolist()\n",
    "control_dimensions = (original_act.flatten(0,1).mean(0).detach().cpu().abs() <1).nonzero().squeeze().tolist()[:len(outlier_dimensions)]\n",
    "df1 = pd.DataFrame(\n",
    "    original_act.flatten(0,1)[:,outlier_dimensions].detach().cpu().numpy(),\n",
    "    columns = [f\"outlier_dim_{i}\" for i in outlier_dimensions],\n",
    "    index = tokens)\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    original_act.flatten(0,1)[:,control_dimensions].detach().cpu().numpy(),\n",
    "    columns = [f\"control_dim_{i}\" for i in control_dimensions],\n",
    "    index = tokens)\n",
    "\n",
    "df = pd.concat([df1, df2], axis=1)\n",
    "px.strip(df[df.index != \"<|endoftext|>\"], log_y=True, hover_name=df.index[df.index != \"<|endoftext|>\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outlier_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(sparse_autoencoder.W_dec[:,outlier_dimensions].detach().cpu(), barmode='overlay', log_y=False,).show()\n",
    "px.histogram(sparse_autoencoder.W_dec[:,control_dimensions].detach().cpu(), barmode='overlay', log_y=False,).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(model.W_out[9,:,outlier_dimensions].detach().cpu(), barmode='overlay', log_y=False,).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(model.W_out[9,:,control_dimensions].detach().cpu(), barmode='overlay', log_y=False,).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[utils.get_act_name(\"mlp_out\", 9)].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Token Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tokens, random_token_groups = generate_random_token_prompt(model, n_random_tokens=5, n_repeat_tokens=2)\n",
    "prompt = model.to_string(random_tokens)\n",
    "token_df, original_cache, cache_reconstructed_query, feature_acts = eval_prompt([prompt], model, sparse_autoencoder, head_idx_override=7)\n",
    "print(token_df.columns)\n",
    "filter_cols = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\"]\n",
    "token_df[filter_cols].tail(10).style.background_gradient(\n",
    "    subset=[\"loss_diff\", \"mse_loss\",\"explained_variance\", \"num_active_features\", \"kl_divergence\"],\n",
    "    cmap=\"coolwarm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD_IDX = 7\n",
    "LAYER_IDX = sparse_autoencoder.cfg.hook_point_layer\n",
    "patterns_original = original_cache[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")\n",
    "patterns_original = original_cache[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_INTEREST = feature_acts.shape[0] - 1 # index from 0.\n",
    "\n",
    "# reload(joseph.visualisation)\n",
    "# from joseph.visualisation import *\n",
    "\n",
    "print(token_df[\"unique_token\"][POS_INTEREST]) # bos gone.\n",
    "plot_line_with_top_10_labels(feature_acts[POS_INTEREST], \"\", 10)\n",
    "\n",
    "vals, inds = torch.topk(feature_acts[POS_INTEREST],5)\n",
    "\n",
    "print(inds)\n",
    "# plot_attn_score_by_feature(model, sparse_autoencoder, inds, original_cache, token_df, pos_interest=POS_INTEREST, vals = vals)\n",
    "# plot_unembed_score_by_feature(model, sparse_autoencoder, inds, token_df, vals=vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pandas columns allowed to be as wide as they want.\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "filter_columns = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\"]\n",
    "# features = torch.randint(0, sparse_autoencoder.cfg.d_sae, (50,))\n",
    "# features = torch.tensor([24519,22818,31246])\n",
    "for feature in inds:\n",
    "    all_token_df[f\"feature_{feature}\"] = all_token_features[:,feature].detach().cpu()\n",
    "    mean_activation = (all_token_df[f\"feature_{feature}\"] > 0).mean()\n",
    "    if mean_activation > 0.001:\n",
    "        print(feature.item(), (all_token_df[f\"feature_{feature}\"] > 0).mean()) # super super dense feature.\n",
    "        display(all_token_df.sort_values(f\"feature_{feature}\", ascending=False)[filter_columns + [f\"feature_{feature}\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_webtext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_token_list = []\n",
    "loss_list = []\n",
    "ablated_loss_list = []\n",
    "# data = get_webtext()\n",
    "\n",
    "NUM_PROMPTS = 30\n",
    "# MAX_PROMPT_LEN = 100\n",
    "# BATCH_SIZE = 10\n",
    "dataframe_list = []\n",
    "feature_acts_list = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(NUM_PROMPTS)):\n",
    "        \n",
    "        # Get Token Data\n",
    "        prompt = data[i]\n",
    "        # new_str = data[BATCH_SIZE * i: BATCH_SIZE * (i + 1)]\n",
    "        \n",
    "\n",
    "        token_df, _, _, feature_acts = eval_prompt(prompt, model, sparse_autoencoder, head_idx_override=7)\n",
    "        feature_acts_list.append(feature_acts)\n",
    "        dataframe_list.append(token_df)\n",
    "        \n",
    "all_token_df = pd.concat(dataframe_list)\n",
    "all_token_df.reset_index(drop=True)\n",
    "all_token_features = torch.cat(feature_acts_list)\n",
    "\n",
    "print(all_token_df.shape)\n",
    "print(all_token_df.columns)\n",
    "all_token_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_mask = (all_token_df.pos.values < 128)\n",
    "all_token_df = all_token_df[all_token_df.pos < 128]\n",
    "all_token_features = all_token_features[torch.tensor(pos_mask)]\n",
    "\n",
    "num_active_features_mask = (all_token_df.num_active_features.values < 100)\n",
    "all_token_df = all_token_df[all_token_df.num_active_features < 100]\n",
    "all_token_features = all_token_features[torch.tensor(num_active_features_mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = (all_token_features > 0).float().mean(dim=0).detach().cpu()\n",
    "log_sparsity = torch.log10(sparsity)\n",
    "print((sparsity > 0).float().mean())\n",
    "print((sparsity > 0).float().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(log_sparsity, nbins=100).show()\n",
    "px.strip(log_sparsity, hover_data=[[i for i in range(sparse_autoencoder.cfg.d_sae)]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(all_token_df.num_active_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_columns = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\"]\n",
    "features = torch.randint(0, sparse_autoencoder.cfg.d_sae, (5,))\n",
    "# features = torch.tensor([24519,22818,31246])\n",
    "for feature in features:\n",
    "    all_token_df[f\"feature_{feature}\"] = all_token_features[:,feature].detach().cpu()\n",
    "    mean_activation = (all_token_df[f\"feature_{feature}\"] > 0).mean()\n",
    "    if mean_activation > 0.0001:\n",
    "        print(feature.item(), (all_token_df[f\"feature_{feature}\"] > 0).mean()) # super super dense feature.\n",
    "        display(all_token_df.sort_values(f\"feature_{feature}\", ascending=False)[filter_columns + [f\"feature_{feature}\"]].head(10))\n",
    "    # else:``\n",
    "        # print(f\"feature {feature.item()} is dead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"When John and Mary went to the shops, John gave the shopping to\"\n",
    "answer = \" Mary\"\n",
    "# prompt = \"All's fair in love and\"\n",
    "# answer = \" war\"\n",
    "# prompt = \" The cat is cute. The dog is\"\n",
    "# prompt = \" Alice, with her keen intelligence and artistic talent, discussed philosophy with Bob, who shared her intellect and also possessed remarkable culinary skills, while\"\n",
    "# answer = \" cute\"\n",
    "model.reset_hooks()\n",
    "utils.test_prompt(prompt, answer, model)\n",
    "\n",
    "HEAD_HOOK_RESULT_NAME = \"blocks.10.attn.hook_z\"\n",
    "LAYER_IDX = sparse_autoencoder.cfg.hook_point_layer\n",
    "HEAD_IDX = 7\n",
    "def hook_to_ablate_head(head_output: Float[Tensor, \"batch seq_len head_idx d_head\"], hook: HookPoint, head = (LAYER_IDX, HEAD_IDX)):\n",
    "    print(hook.layer(), hook.name)\n",
    "    assert head[0] == hook.layer(), f\"{head[0]} != {hook.layer()}\"\n",
    "    assert (\"result\" in hook.name) or (\"q\" in hook.name) or (\"z\" in hook.name)\n",
    "    head_output[:, :, head[1], :] = 0\n",
    "    return head_output\n",
    "\n",
    "with model.hooks(fwd_hooks=[(HEAD_HOOK_RESULT_NAME, hook_to_ablate_head)]):\n",
    "    utils.test_prompt(prompt, answer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joseph\n",
    "reload(joseph.analysis)\n",
    "from joseph.analysis import *\n",
    "\n",
    "\n",
    "token_df, original_cache, cache_reconstructed_query, feature_acts = eval_prompt([prompt + answer], model, sparse_autoencoder, head_idx_override=7)\n",
    "print(token_df.columns)\n",
    "filter_cols = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\",\n",
    "               \"top_k_features\"]\n",
    "token_df[filter_cols].style.background_gradient(\n",
    "    subset=[\"loss_diff\", \"mse_loss\",\"explained_variance\", \"num_active_features\", \"kl_divergence\"],\n",
    "    cmap=\"coolwarm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(feature_acts > 0).float().sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn(patterns, token_df, title=\"\", facet_col_labels = [\"Original\", \"Reconstructed\"]):\n",
    "    '''\n",
    "    # patterns_original = cache[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "    # patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "    patterns_original = cache[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "    patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "    both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "    plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")\n",
    "    \n",
    "    '''\n",
    "    fig = px.imshow(patterns, text_auto=\".2f\", title=title,\n",
    "                    facet_col=0,\n",
    "                    color_continuous_midpoint=0,\n",
    "                    color_continuous_scale=\"RdBu\",\n",
    "                    )\n",
    "    \n",
    "    tickvals = np.arange(patterns.shape[2])\n",
    "    ticktext = token_df[\"unique_token\"].tolist()\n",
    "    \n",
    "    # add tokens as x-ticks and y-ticks, for each facet\n",
    "    # Update x-ticks and y-ticks for each facet\n",
    "    for i in range(len(facet_col_labels)):\n",
    "        fig.update_xaxes(\n",
    "            dict(tickmode='array', tickvals=tickvals, ticktext=ticktext),\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            dict(tickmode='array', tickvals=tickvals, ticktext=ticktext),\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # add facet col labels:\n",
    "    for i, label in enumerate(facet_col_labels):\n",
    "        fig.layout.annotations[i].text = label\n",
    "        fig.layout.annotations[i].font.size = 20\n",
    "        \n",
    "    fig.update_layout(\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "LAYER_IDX = sparse_autoencoder.cfg.hook_point_layer\n",
    "HEAD_IDX = 7\n",
    "patterns_original = original_cache[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")\n",
    "patterns_original = original_cache[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_INTEREST = 14# index from 0.\n",
    "print(token_df.shape)\n",
    "print(feature_acts.shape)\n",
    "print(token_df[\"unique_token\"][POS_INTEREST]) \n",
    "feature_acts_of_interest = feature_acts[POS_INTEREST]\n",
    "plot_line_with_top_10_labels(feature_acts_of_interest, \"\", 30)\n",
    "vals, inds = torch.topk(feature_acts_of_interest,64)\n",
    "print(vals.nonzero().shape)\n",
    "print(inds)\n",
    "# plot_attn_score_by_feature(model, sparse_autoencoder, inds, original_cache, token_df, pos_interest=POS_INTEREST, vals = vals)\n",
    "# plot_unembed_score_by_feature(model, sparse_autoencoder, inds, token_df, vals=vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.strip(\n",
    "    (sparse_autoencoder.W_dec @ model.W_U[:,model.to_single_token(\" Mary\")]).detach().cpu().numpy(), \n",
    "    color = [i in inds for i in range(sparse_autoencoder.cfg.d_sae)],\n",
    "    hover_data=[[i for i in range(sparse_autoencoder.cfg.d_sae)]],\n",
    "    ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pandas not to truncate witdth \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# set pandas not to use elipses \n",
    "# pd.set_option('display.max_cols', None)\n",
    "k = 64\n",
    "virtual_weights = (sparse_autoencoder.W_dec[inds]  @ model.W_U)\n",
    "top_k_tokens = virtual_weights.topk(k, dim=-1).indices\n",
    "tokens = pd.DataFrame(top_k_tokens.detach().cpu().T, columns = [f\"feature_{i}\" for i in inds], index = [f\"top_{i}\" for i in range(k)])\n",
    "df = tokens.applymap(lambda x: model.to_string(x))\n",
    "df.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(\n",
    "    x = [str(i.item()) for i in inds],\n",
    "    y = (sparse_autoencoder.W_dec[inds] @ model.W_U[:,model.to_single_token(\" Mary\")]).detach().cpu().numpy()).show()\n",
    "\n",
    "px.bar(\n",
    "    x = [str(i.item()) for i in inds],\n",
    "    y = (sparse_autoencoder.W_dec[inds] @ model.W_U[:,model.to_single_token(\" John\")]).detach().cpu().numpy()).show()\n",
    "\n",
    "px.bar(\n",
    "    x = [str(i.item()) for i in inds],\n",
    "    y = (sparse_autoencoder.W_dec[inds] @ (model.W_U[:,model.to_single_token(\" Mary\")] - model.W_U[:,model.to_single_token(\" John\")] )).detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [] \n",
    "for layer in range(8,12):\n",
    "    \n",
    "    logit_lens_at_layer_10 = original_cache.apply_ln_to_stack(original_cache[utils.get_act_name(\"resid_pre\", layer)]) \n",
    "    logit_lens_at_layer_10 = logit_lens_at_layer_10[0, POS_INTEREST] @ model.W_U\n",
    "    vals, inds = torch.topk(logit_lens_at_layer_10.detach().cpu(), 50)\n",
    "    df_list.append(pd.DataFrame({f\"token_{layer}\": [model.to_string(i) for i in inds], f\"logit_len_{layer}\": vals}).head(30))\n",
    "\n",
    "pd.concat(df_list, axis=1).style.background_gradient(\n",
    "    subset=[f\"logit_len_{layer}\" for layer in range(8,12)],\n",
    "    cmap=\"coolwarm\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_score_by_feature(\n",
    "    model: HookedTransformer, \n",
    "    sparse_autoencoder: SparseAutoencoder, \n",
    "    feature_ids, \n",
    "    cache, \n",
    "    token_df, \n",
    "    pos_interest, \n",
    "    vals = None,\n",
    "    head_index = None):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    layer_index = sparse_autoencoder.cfg.hook_point_layer\n",
    "    head_index = sparse_autoencoder.cfg.hook_point_head_index if head_index is None else head_index\n",
    "\n",
    "    k = cache[f\"blocks.{layer_index}.attn.hook_k\"][0,:(1+pos_interest),head_index]\n",
    "    # score_contributions = sparse_autoencoder.W_enc[:,inds].T @ k.T\n",
    "    score_contributions = (sparse_autoencoder.W_dec[feature_ids] @ model.W_Q[10,7]) @ k.T\n",
    "\n",
    "    if vals is not None:\n",
    "        score_contributions = score_contributions.cpu() * vals.unsqueeze(1).cpu()\n",
    "    fig = px.imshow(score_contributions.detach().cpu(), \n",
    "                    color_continuous_scale=\"RdBu\",\n",
    "                    color_continuous_midpoint=0,\n",
    "                    labels = dict(y=\"Feature\", x=\"Token\"),\n",
    "                    text_auto=\".2f\", title=\"\")\n",
    "    # add xticks and y ticks\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            tickmode='array',\n",
    "            tickvals=1+np.arange(score_contributions.shape[1]),\n",
    "            ticktext=token_df[\"str_tokens\"].tolist(),\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            tickmode='array',\n",
    "            tickvals=np.arange(score_contributions.shape[0]),\n",
    "            ticktext=list(feature_ids.detach().cpu().numpy()),\n",
    "        ),\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "print(POS_INTEREST)\n",
    "fig = plot_attn_score_by_feature(model, sparse_autoencoder, inds[:10], original_cache, token_df, pos_interest=POS_INTEREST+1, head_index = 7, vals = vals[:10])\n",
    "fig.update_layout(width = 1000, height = 1200)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_out, feature_acts, loss, mse_loss, l1_loss = sparse_autoencoder(original_cache[sparse_autoencoder.cfg.hook_point])\n",
    "query_features_firing = (feature_acts[0, POS_INTEREST] > 0)\n",
    "print(query_features_firing.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feature_projections = (feature_acts[0, :-1] @ sparse_autoencoder.W_dec) @ model.W_K[10,7]\n",
    "tmp = key_feature_projections @ cache_reconstructed_query[\"blocks.10.attn.hook_q\"][0, POS_INTEREST, 7].T\n",
    "px.line(\n",
    "    x = token_df.unique_token.tolist()[1:-1],\n",
    "    y = tmp[1:].detach().cpu().numpy()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pos = 2\n",
    "query_pos = POS_INTEREST\n",
    "\n",
    "key_features_firing = (feature_acts[0, key_pos] > 0)\n",
    "print(key_features_firing.sum())\n",
    "\n",
    "query_features_firing = (feature_acts[0, query_pos] > 0)\n",
    "print(query_features_firing.sum())\n",
    "\n",
    "key_features = (feature_acts[0, key_pos, key_features_firing] * sparse_autoencoder.W_dec[key_features_firing].T[:, None, :]).transpose(2,0)\n",
    "print(key_features.shape)\n",
    "query_features = (feature_acts[0, query_pos, query_features_firing] * sparse_autoencoder.W_dec[query_features_firing].T)\n",
    "print(query_features.shape)\n",
    "scores = key_features @ query_features\n",
    "df = pd.DataFrame(scores[:,0].detach().cpu().numpy(), \n",
    "                  index = key_features_firing.nonzero().squeeze().tolist(), \n",
    "                  columns = query_features_firing.nonzero().squeeze().tolist())\n",
    "fig = px.imshow(df.values, \n",
    "                title = \" Key / Query Feature Scores (ignore LN) for Mary / to\",\n",
    "                color_continuous_midpoint=0, \n",
    "                color_continuous_scale=\"RdBu\")\n",
    "# update xticks and yticks\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=np.arange(df.shape[1]),\n",
    "        ticktext=list(df.columns),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=np.arange(df.shape[0]),\n",
    "        ticktext=list(df.index),\n",
    "    ),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_features = interesting_features + key_features_firing.nonzero().squeeze().tolist()\n",
    "interesting_features = interesting_features + query_features_firing.nonzero().squeeze().tolist()\n",
    "interesting_features = list(set(interesting_features))\n",
    "len(interesting_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pos = 4\n",
    "query_pos = POS_INTEREST\n",
    "\n",
    "key_features_firing = (feature_acts[0, key_pos] > 0)\n",
    "print(key_features_firing.sum())\n",
    "\n",
    "query_features_firing = (feature_acts[0, query_pos] > 0)\n",
    "print(query_features_firing.sum())\n",
    "\n",
    "key_features = (feature_acts[0, key_pos, key_features_firing] * sparse_autoencoder.W_dec[key_features_firing].T[:, None, :]).transpose(2,0)\n",
    "print(key_features.shape)\n",
    "query_features = (feature_acts[0, query_pos, query_features_firing] * sparse_autoencoder.W_dec[query_features_firing].T)\n",
    "print(query_features.shape)\n",
    "scores = key_features @ query_features\n",
    "df = pd.DataFrame(scores[:,0].detach().cpu().numpy(), \n",
    "                  index = key_features_firing.nonzero().squeeze().tolist(), \n",
    "                  columns = query_features_firing.nonzero().squeeze().tolist())\n",
    "fig = px.imshow(df.values, \n",
    "                title = \" Key / Query Feature Scores (ignore LN) for Mary / to\",\n",
    "                color_continuous_midpoint=0, \n",
    "                color_continuous_scale=\"RdBu\")\n",
    "# update xticks and yticks\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=np.arange(df.shape[1]),\n",
    "        ticktext=list(df.columns),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=np.arange(df.shape[0]),\n",
    "        ticktext=list(df.index),\n",
    "    ),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_features = interesting_features + key_features_firing.nonzero().squeeze().tolist()\n",
    "interesting_features = interesting_features + query_features_firing.nonzero().squeeze().tolist()\n",
    "interesting_features = list(set(interesting_features))\n",
    "len(interesting_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interventions on Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to experiment with deleting a feature. To do this with the resid pre SAE, we need to generate the query from the resid_pre and then minus the feature and then patch the hook q with the new hook_q."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"When John and Mary went to the shops, John gave the shopping to\"\n",
    "answer = \" Mary\"\n",
    "tokens = model.to_tokens(prompt)\n",
    "\n",
    "token_df, original_cache, cache_reconstructed_query, feature_acts = eval_prompt(prompt, model, sparse_autoencoder, head_idx_override=7)\n",
    "filter_cols = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\",\n",
    "               \"top_k_features\"]\n",
    "token_df[filter_cols].style.background_gradient(\n",
    "    subset=[\"loss_diff\", \"mse_loss\",\"explained_variance\", \"num_active_features\", \"kl_divergence\"],\n",
    "    cmap=\"coolwarm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, inds = torch.topk(feature_acts[-1],30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = sparse_autoencoder.cfg.hook_point_layer\n",
    "head_idx = 7\n",
    "head_hook_query_name = utils.get_act_name(\"q\", layer_idx)\n",
    "\n",
    "\n",
    "attn_df = make_token_df(model, tokens)\n",
    "patterns = original_cache[f\"blocks.{layer_idx}.attn.hook_pattern\"][0,HEAD_IDX].detach().cpu()\n",
    "attn_df[\"original_attn\"] = patterns[-1,]\n",
    "patterns = cache_reconstructed_query[f\"blocks.{layer_idx}.attn.hook_pattern\"][0,HEAD_IDX].detach().cpu()\n",
    "attn_df[\"reconstructed_attn\"] = patterns[-1,]\n",
    "\n",
    "for feature in inds:\n",
    "    features_to_remove = [feature]\n",
    "    original_act = original_cache[sparse_autoencoder.cfg.hook_point]\n",
    "    sae_out, feature_acts, _, mse_loss, _ = sparse_autoencoder(original_act)\n",
    "\n",
    "    # need to generate query\n",
    "    def replacement_hook(resid_pre, hook, new_resid_pre=sae_out):\n",
    "        return new_resid_pre\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(utils.get_act_name(\"resid_pre\", sparse_autoencoder.cfg.hook_point_layer), replacement_hook)]):\n",
    "        _, resid_pre_cache = model.run_with_cache(tokens, return_type=\"loss\", loss_per_token=True)\n",
    "        sae_out = resid_pre_cache[head_hook_query_name][:,:,head_idx]\n",
    "\n",
    "\n",
    "    def remove_feature_hook(hook_in, hook, position=-1, features_to_remove = features_to_remove):\n",
    "        for feature_to_remove in features_to_remove:\n",
    "            # print(feature_acts[0,position,feature_to_remove].item())\n",
    "            feature_dir = feature_acts[0,position,feature_to_remove]*sparse_autoencoder.W_dec[feature_to_remove]\n",
    "            hook_in -= feature_dir\n",
    "        return hook_in\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(sparse_autoencoder.cfg.hook_point, remove_feature_hook)]):\n",
    "        _, cache_removed_feature = model.run_with_cache(tokens, return_type=\"loss\", loss_per_token=True)\n",
    "\n",
    "    patterns = cache_removed_feature[f\"blocks.{layer_idx}.attn.hook_pattern\"][0,HEAD_IDX].detach().cpu()\n",
    "    attn_df[f\"ablated_feature_{feature}\"] = patterns[-1,]\n",
    "\n",
    "fig = px.line(attn_df, \n",
    "            x=\"unique_token\",\n",
    "            y=[\"original_attn\",\"reconstructed_attn\"] + [f\"ablated_feature_{feature}\" for feature in inds],\n",
    "            hover_name=\"str_tokens\", \n",
    "            hover_data=[\"pos\", \"batch\", \"label\"], \n",
    "            title=\"Original vs Reconstructed attention\")\n",
    "\n",
    "# increase figure height\n",
    "fig.update_layout(height=800)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = px.bar(\n",
    "    x= attn_df.T[[2,4]][8:].index,\n",
    "    y=attn_df.T.iloc[8:,4] / attn_df.T.iloc[8:,2],\n",
    "    hover_name= attn_df.T[[2,4]][8:].index,\n",
    "    labels= {\"x\": \"Ablated Feature\", \"y\": \"Mary Attn / John Attn\"})\n",
    "print(attn_df.T.iloc[7,4] / attn_df.T.iloc[7,2])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.line(attn_df, \n",
    "            x=\"unique_token\",\n",
    "            y=[\"original_attn\",\"reconstructed_attn\"] + [f\"ablated_feature_{feature}\" for feature in inds],\n",
    "            hover_name=\"str_tokens\", \n",
    "            hover_data=[\"pos\", \"batch\", \"label\", \"variable\"], \n",
    "            title=\"Original vs Reconstructed attention\")\n",
    "\n",
    "# increase figure height\n",
    "fig.update_layout(height=800)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(attn_df.iloc[4,6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(x = attn_df.iloc[4, 8:].index, y = attn_df.iloc[4, 8:].values).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature DLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp, labels = original_cache.get_full_resid_decomposition(layer =  10, expand_neurons=False, return_labels=True)\n",
    "print(decomp[:,0,-1].shape)\n",
    "\n",
    "test = (decomp[:,0,-1] @ sparse_autoencoder.W_enc[:,inds])\n",
    "# test = (decomp[:,0,-1] @ sparse_autoencoder.W_dec[inds].T) / sparse_autoencoder.W_enc[:,inds].norm(dim=0)\n",
    "tmp = pd.DataFrame(test.detach().cpu().numpy().T, columns = labels, index = [f\"feature_{i}\" for i in inds])\n",
    "px.line(\n",
    "    tmp.T[tmp.T.index.str.contains(\"mlp\")]\n",
    ").show()\n",
    "\n",
    "px.line(\n",
    "    tmp.T[tmp.T.index.str.contains(\"L\")]\n",
    ").show()\n",
    "\n",
    "# test = (decomp[:,0,-1] @ sparse_autoencoder.W_enc[:,inds])\n",
    "test = (decomp[:,0,-1] @ sparse_autoencoder.W_dec[inds].T) / sparse_autoencoder.W_enc[:,inds].norm(dim=0)\n",
    "tmp = pd.DataFrame(test.detach().cpu().numpy().T, columns = labels, index = [f\"feature_{i}\" for i in inds])\n",
    "px.line(\n",
    "    tmp.T[tmp.T.index.str.contains(\"mlp\")]\n",
    ").show()\n",
    "px.line(\n",
    "    tmp.T[tmp.T.index.str.contains(\"L\")]\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Check for Outlier Dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_features = feature_acts[-1] > 0\n",
    "firing_features_labels = [f\"feature_{i}\" for i in firing_features.nonzero().squeeze().tolist()]\n",
    "tmp = pd.DataFrame( sparse_autoencoder.W_dec[firing_features].detach().cpu(), index = firing_features_labels)\n",
    "px.line(\n",
    "   tmp.T,\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_out = feature_acts[-1] @ sparse_autoencoder.W_dec + sparse_autoencoder.b_dec\n",
    "\n",
    "for j in range(10,11):\n",
    "    px.line(\n",
    "        torch.stack(\n",
    "            [original_cache[utils.get_act_name(\"resid_pre\", i)][0,j].detach().cpu().squeeze() for i in range(12)]).squeeze(0).T).show()\n",
    "px.line(sae_out.detach().cpu()).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line((all_token_features > 0).float().mean(0).detach().cpu()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "sim = sparse_autoencoder.W_dec[inds] @ sparse_autoencoder.W_dec[inds].T\n",
    "sim = sim.detach().cpu().numpy()\n",
    "labels = [f\"feature_{i}\" for i in inds]\n",
    "linkage = hierarchy.linkage(sim)\n",
    "dendrogram = hierarchy.dendrogram(linkage, no_plot=True, color_threshold=-np.inf)\n",
    "reordered_ind = list(reversed(dendrogram[\"leaves\"]))\n",
    "reordered_labels = [labels[i] for i in reordered_ind]\n",
    "reordered_arr = sim[reordered_ind][:, reordered_ind]\n",
    "px.imshow(reordered_arr, x=reordered_labels, y=reordered_labels, color_continuous_midpoint=0, color_continuous_scale=\"RdBu\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "labels = [f\"feature_{i}\" for i in inds]\n",
    "linkage = hierarchy.linkage(sim)\n",
    "dendrogram = hierarchy.dendrogram(linkage, no_plot=True, color_threshold=-np.inf)\n",
    "reordered_ind = list(reversed(dendrogram[\"leaves\"]))\n",
    "reordered_labels = [labels[i] for i in reordered_ind]\n",
    "reordered_arr = sim[reordered_ind][:, reordered_ind]\n",
    "px.imshow(reordered_arr, x=reordered_labels, y=reordered_labels, color_continuous_midpoint=0, color_continuous_scale=\"RdBu\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_autoencoder.b_dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_autoencoder.b_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geom_median.torch import compute_geometric_median\n",
    "out = compute_geometric_median(sae_out[0].detach().cpu())\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_out[0].detach().cpu().numpy() - out.median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_webtext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_token_list = []\n",
    "loss_list = []\n",
    "ablated_loss_list = []\n",
    "# data = get_webtext()\n",
    "\n",
    "NUM_PROMPTS = 200\n",
    "# MAX_PROMPT_LEN = 100\n",
    "# BATCH_SIZE = 10\n",
    "dataframe_list = []\n",
    "feature_acts_list = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(NUM_PROMPTS)):\n",
    "        \n",
    "        # Get Token Data\n",
    "        prompt = model.to_string(model.to_tokens(data[i])[0,:128])\n",
    "        token_df, _, _, feature_acts = eval_prompt(prompt, model, sparse_autoencoder, head_idx_override=7)\n",
    "        feature_acts_list.append(feature_acts)\n",
    "        dataframe_list.append(token_df)\n",
    "        \n",
    "all_token_df = pd.concat(dataframe_list)\n",
    "all_token_df.reset_index(drop=True)\n",
    "all_token_features = torch.cat(feature_acts_list)\n",
    "\n",
    "print(all_token_df.shape)\n",
    "print(all_token_df.columns)\n",
    "all_token_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_mask = (all_token_df.pos.values < 128)\n",
    "all_token_df = all_token_df[all_token_df.pos < 128]\n",
    "all_token_features = all_token_features[torch.tensor(pos_mask)]\n",
    "\n",
    "sparsity = (all_token_features > 0).float().mean(dim=0).detach().cpu()\n",
    "log_sparsity = torch.log10(sparsity)\n",
    "print((sparsity > 0).float().mean())\n",
    "print((sparsity > 0).float().sum())\n",
    "\n",
    "num_active_features_mask = (all_token_df.num_active_features.values < 100)\n",
    "all_token_df = all_token_df[all_token_df.num_active_features < 100]\n",
    "all_token_features = all_token_features[torch.tensor(num_active_features_mask)]\n",
    "\n",
    "sparsity = (all_token_features > 0).float().mean(dim=0).detach().cpu()\n",
    "log_sparsity = torch.log10(sparsity)\n",
    "print((sparsity > 0).float().mean())\n",
    "print((sparsity > 0).float().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(log_sparsity, nbins=100).show()\n",
    "px.strip(log_sparsity, hover_data=[[i for i in range(sparse_autoencoder.cfg.d_sae)]]).show()\n",
    "px.histogram(all_token_df.num_active_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_columns = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\"]\n",
    "features = torch.randint(0, sparse_autoencoder.cfg.d_sae, (5,))\n",
    "# features = torch.tensor([24519,22818,31246])\n",
    "for feature in features:\n",
    "    all_token_df[f\"feature_{feature}\"] = all_token_features[:,feature].detach().cpu()\n",
    "    mean_activation = (all_token_df[f\"feature_{feature}\"] > 0).mean()\n",
    "    if mean_activation > 0.0001:\n",
    "        print(feature.item(), (all_token_df[f\"feature_{feature}\"] > 0).mean()) # super super dense feature.\n",
    "        display(all_token_df.sort_values(f\"feature_{feature}\", ascending=False)[filter_columns + [f\"feature_{feature}\"]].head(10))\n",
    "    # else:``\n",
    "        # print(f\"feature {feature.item()} is dead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interventions on Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic Feature Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_list = []\n",
    "pbar = tqdm(range(128*6))\n",
    "for i in pbar:\n",
    "    all_tokens_list.append(activation_store.get_batch_tokens())\n",
    "all_tokens = torch.cat(all_tokens_list, dim=0)\n",
    "print(all_tokens.shape)\n",
    "all_tokens = all_tokens[torch.randperm(all_tokens.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = all_tokens[torch.randperm(all_tokens.shape[0])]\n",
    "tokens = all_tokens[:4096*6]\n",
    "del all_tokens\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_analysis.visualizer import data_fns, model_fns, html_fns\n",
    "import importlib\n",
    "\n",
    "importlib.reload(data_fns)\n",
    "importlib.reload(html_fns)\n",
    "from sae_analysis.visualizer.data_fns import get_feature_data, FeatureData\n",
    "\n",
    "# Currently, don't think much more time can be squeezed out of it. Maybe the best saving would be to\n",
    "# make the entire sequence indexing parallelized, but that's possibly not worth it right now.\n",
    "\n",
    "max_batch_size = 512\n",
    "total_batch_size = 4096*6\n",
    "feature_idx = [i for i in range(sparse_autoencoder.cfg.d_sae)]\n",
    "feature_idx = torch.tensor(feature_idx).reshape(512, -1)\n",
    "feature_idx = [feature_idx[i].tolist() for i in range(512)]\n",
    "# max_batch_size = 512\n",
    "# total_batch_size = 16384\n",
    "# feature_idx = list(range(1000))\n",
    "\n",
    "\n",
    "# shuffle\n",
    "\n",
    "for interesting_features in tqdm(feature_idx):\n",
    "    print(interesting_features)\n",
    "    feature_data = get_feature_data(\n",
    "        encoder=sparse_autoencoder,\n",
    "        # encoder_B=sparse_autoencoder,\n",
    "        model=model,\n",
    "        hook_point=sparse_autoencoder.cfg.hook_point,\n",
    "        hook_point_layer=sparse_autoencoder.cfg.hook_point_layer,\n",
    "        hook_point_head_index=None,\n",
    "        tokens=tokens,\n",
    "        feature_idx=interesting_features,\n",
    "        max_batch_size=max_batch_size,\n",
    "        left_hand_k = 3,\n",
    "        buffer = (5, 5),\n",
    "        n_groups = 10,\n",
    "        first_group_size = 20,\n",
    "        other_groups_size = 5,\n",
    "        verbose = True,\n",
    "    )\n",
    "\n",
    "\n",
    "    for test_idx in list(interesting_features):\n",
    "        html_str = feature_data[test_idx].get_all_html()\n",
    "        with open(f\"gpt2_small_features_layer_5/data_{test_idx:04}.html\", \"w\") as f:\n",
    "            f.write(html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_analysis.visualizer import data_fns, model_fns, html_fns\n",
    "import importlib\n",
    "\n",
    "importlib.reload(data_fns)\n",
    "importlib.reload(html_fns)\n",
    "from sae_analysis.visualizer.data_fns import get_feature_data, FeatureData\n",
    "\n",
    "# Currently, don't think much more time can be squeezed out of it. Maybe the best saving would be to\n",
    "# make the entire sequence indexing parallelized, but that's possibly not worth it right now.\n",
    "\n",
    "max_batch_size = 512\n",
    "total_batch_size = 4096*6\n",
    "feature_idx = [i for i in range(sparse_autoencoder.cfg.d_sae)]\n",
    "feature_idx = torch.tensor(feature_idx).reshape(512, -1)\n",
    "feature_idx = [feature_idx[i].tolist() for i in range(512)]\n",
    "# max_batch_size = 512\n",
    "# total_batch_size = 16384\n",
    "# feature_idx = list(range(1000))\n",
    "\n",
    "\n",
    "# shuffle\n",
    "interesting_features = temp_df\n",
    "\n",
    "feature_data = get_feature_data(\n",
    "    encoder=sparse_autoencoder,\n",
    "    # encoder_B=sparse_autoencoder,\n",
    "    model=model,\n",
    "    hook_point=sparse_autoencoder.cfg.hook_point,\n",
    "    hook_point_layer=sparse_autoencoder.cfg.hook_point_layer,\n",
    "    hook_point_head_index=None,\n",
    "    tokens=tokens,\n",
    "    feature_idx=interesting_features,\n",
    "    max_batch_size=max_batch_size,\n",
    "    left_hand_k = 3,\n",
    "    buffer = (5, 5),\n",
    "    n_groups = 10,\n",
    "    first_group_size = 20,\n",
    "    other_groups_size = 5,\n",
    "    verbose = True,\n",
    ")\n",
    "\n",
    "\n",
    "for test_idx in list(interesting_features):\n",
    "    html_str = feature_data[test_idx].get_all_html()\n",
    "    with open(f\"gpt2_small_features_layer_5/data_{test_idx:04}.html\", \"w\") as f:\n",
    "        f.write(html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[temp_df.cluster == 15].index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
