{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2-Small Resid Pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from importlib import reload\n",
    "from tqdm import tqdm\n",
    "\n",
    "import joseph\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "\n",
    "reload(joseph.analysis)\n",
    "reload(joseph.visualisation)\n",
    "reload(joseph.utils)\n",
    "reload(joseph.data)\n",
    "\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "# turn torch grad tracking off\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# run = wandb.init()\n",
    "# artifact = run.use_artifact('jbloom/mats_sae_training_gpt2_small_resid_pre/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152:v28', type='model')\n",
    "# artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    # \"tiny-stories-2L-33M\",\n",
    "    # \"attn-only-2l\",\n",
    "    # center_unembed=True,\n",
    "    # center_writing_weights=True,\n",
    "    # fold_ln=True,\n",
    "    # refactor_factored_attn_matrices=True,\n",
    ")\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)\n",
    "\n",
    "\n",
    "path = \"./artifacts/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152:v28/1100001280_sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152.pt\"\n",
    "sparse_autoencoder = SparseAutoencoder.load_from_pretrained(path)\n",
    "\n",
    "print(sparse_autoencoder.cfg)\n",
    "\n",
    "\n",
    "# sanity check\n",
    "text = \"Many important transition points in the history of science have been moments when science 'zoomed in.' At these points, we develop a visualization or tool that allows us to see the world in a new level of detail, and a new field of science develops to study the world through this lens.\"\n",
    "model(text, return_type=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_training.utils import LMSparseAutoencoderSessionloader\n",
    "model, sparse_autoencoder, activation_store = LMSparseAutoencoderSessionloader.load_session_from_pretrained(\n",
    "    path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_autoencoder.W_dec.norm(dim=0).detach().cpu().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.strip(y=sparse_autoencoder.W_dec.norm(dim=1).detach().cpu(),\n",
    "         hover_name=[f\"feature_{i}\" for i in range(sparse_autoencoder.cfg.d_sae)]).show()\n",
    "\n",
    "outlier_dimensions = torch.where(sparse_autoencoder.W_dec.norm(dim=0) > 20)[0].tolist()\n",
    "print(\"outlier_dimensions = \", outlier_dimensions)\n",
    "px.strip(y=sparse_autoencoder.W_dec.norm(dim=0).detach().cpu(),\n",
    "         log_y=True,\n",
    "         hover_name=[f\"basis_{i}\" for i in range(sparse_autoencoder.cfg.d_in)]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(sparse_autoencoder.W_dec[:,outlier_dimensions].detach().cpu(),\n",
    "                index=[f\"feature_{i}\" for i in range(sparse_autoencoder.cfg.d_sae)],\n",
    "                columns=[f\"basis_{i}\" for i in outlier_dimensions]).round(2)\n",
    "tmp[\"sparsity\"] = (all_token_features > 0).float().sum(0).detach().cpu()\n",
    "fig = px.scatter(tmp, x=\"sparsity\", y=tmp.columns[:-1], hover_name=tmp.index, \n",
    "                 log_x=False,\n",
    "                 opacity=0.5,\n",
    "                 marginal_y=\"histogram\",\n",
    "                 labels= {\"index\": \"sparsity\", \"value\": \"weight\", \"variable\": \"basis vector\"})\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=500,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(all_token_features.sum(0).detach().cpu()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_dense_features = [14627, 30276, 26085,10109]\n",
    "px.imshow(sparse_autoencoder.W_dec[weird_dense_features][:,outlier_dimensions].detach().cpu(), color_continuous_midpoint=0, color_continuous_scale=\"RdBu\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_proj_dec_weights = sparse_autoencoder.W_dec @ model.W_Q[10,:]\n",
    "query_proj_dec_weights_df = pd.DataFrame(\n",
    "    query_proj_dec_weights.norm(dim=-1).detach().cpu().numpy().T,\n",
    "    columns = [\"L10H\" + str(i) for i in range(12)],\n",
    "    index = [f\"feature_{i}\" for i in range(sparse_autoencoder.cfg.d_sae)])\n",
    "\n",
    "px.histogram(\n",
    "    query_proj_dec_weights_df,\n",
    "    x=query_proj_dec_weights_df.columns,\n",
    "    facet_col='variable',\n",
    "    facet_col_wrap=3,\n",
    "    # barmode='overlay',\n",
    ").show()\n",
    "\n",
    "\n",
    "key_proj_dec_weights = sparse_autoencoder.W_dec @ model.W_K[10,:]\n",
    "key_proj_dec_weights_df = pd.DataFrame(\n",
    "    key_proj_dec_weights.norm(dim=-1).detach().cpu().numpy().T,\n",
    "    columns = [\"L10H\" + str(i) for i in range(12)],\n",
    "    index = [f\"feature_{i}\" for i in range(sparse_autoencoder.cfg.d_sae)])\n",
    "\n",
    "px.histogram(\n",
    "    key_proj_dec_weights_df,\n",
    "    x=key_proj_dec_weights_df.columns,\n",
    "    facet_col='variable',\n",
    "    facet_col_wrap=3,\n",
    "    # barmode='overlay',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_proj_dec_weights = sparse_autoencoder.W_dec @ model.W_V[10,:]\n",
    "value_proj_dec_weights_df = pd.DataFrame(\n",
    "    value_proj_dec_weights.norm(dim=-1).detach().cpu().numpy().T,\n",
    "    columns = [\"L10H\" + str(i) for i in range(12)],\n",
    "    index = [f\"feature_{i}\" for i in range(sparse_autoencoder.cfg.d_sae)])\n",
    "\n",
    "px.histogram(\n",
    "    value_proj_dec_weights_df,\n",
    "    x=value_proj_dec_weights_df.columns,\n",
    "    facet_col='variable',\n",
    "    facet_col_wrap=3,\n",
    "    # barmode='overlay',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(query_proj_dec_weights_df.corr(), color_continuous_scale='RdBu', title = \"Query projection weights\").show()\n",
    "px.imshow(key_proj_dec_weights_df.corr(), color_continuous_scale='RdBu', title = \"Key projection weights\").show()\n",
    "px.imshow(value_proj_dec_weights_df.corr(), color_continuous_scale='RdBu', title = \"Value projection weights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(\n",
    "    value_proj_dec_weights_df,\n",
    "    dimensions=query_proj_dec_weights_df.columns,\n",
    "    opacity=0.3,\n",
    "    hover_data=[query_proj_dec_weights_df.index],\n",
    ")\n",
    "fig.update_layout(width = 1200, height = 1200)\n",
    "fig.show()\n",
    "\n",
    "# fig = px.scatter_matrix(\n",
    "#     key_proj_dec_weights_df,\n",
    "#     dimensions=key_proj_dec_weights_df.columns,\n",
    "    \n",
    "#     opacity=0.3,\n",
    "#     hover_data=[key_proj_dec_weights_df.index],\n",
    "# )\n",
    "# fig.update_layout(width = 1200, height = 1200)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(\n",
    "    query_proj_dec_weights_df,\n",
    "    y=query_proj_dec_weights_df.columns,\n",
    "    hover_data=[query_proj_dec_weights_df.index],\n",
    ")\n",
    "fig.update_layout(width = 1200, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_proj_dec_weights_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_token_features.sum(0) > 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (all_token_features.sum(0) > 0).detach().cpu().numpy()\n",
    "fig = px.scatter(\n",
    "    x = query_proj_dec_weights_df[\"L10H7\"][mask],\n",
    "    y = key_proj_dec_weights_df[\"L10H7\"][mask],\n",
    "    hover_name=query_proj_dec_weights_df.index[mask],\n",
    "    color = np.log((all_token_features > 0).float().mean(0).detach().cpu().numpy()[mask]),\n",
    "    opacity=0.5,\n",
    "    marginal_x=\"histogram\",\n",
    "    marginal_y=\"histogram\",\n",
    "    labels={\n",
    "        \"x\": \"Feature Norm after Query Projection\",\n",
    "        \"y\": \"Feature Norm after Key Projection\",\n",
    "        \"color\": \"Sparsity\",\n",
    "    },\n",
    ")\n",
    "fig.update_layout(width = 1200, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    x = np.log((all_token_features > 0).float().mean(0).detach().cpu().numpy()[mask]),\n",
    "    y =query_proj_dec_weights_df[\"L10H7\"][mask])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_columns = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\"]\n",
    "# features = torch.randint(0, sparse_autoencoder.cfg.d_sae, (5,))\n",
    "features = torch.tensor((query_proj_dec_weights_df[\"L10H7\"] > 0.6) & (key_proj_dec_weights_df[\"L10H7\"] < 0.2) & mask).nonzero().squeeze()\n",
    "print(features)\n",
    "for feature in features:\n",
    "    all_token_df[f\"feature_{feature}\"] = all_token_features[:,feature].detach().cpu()\n",
    "    print(feature.item(), (all_token_df[f\"feature_{feature}\"] > 0).mean()) # super super dense feature.\n",
    "    display(all_token_df.sort_values(f\"feature_{feature}\", ascending=False)[filter_columns + [f\"feature_{feature}\"]].head(10))\n",
    "    # else:``\n",
    "        # print(f\"feature {feature.item()} is dead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = query_proj_dec_weights_df.iloc[[14627, 30276, 26085,10109]]\n",
    "print(tmp)\n",
    "px.strip(\n",
    "    tmp,\n",
    "    color=tmp.index,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    x = query_proj_dec_weights_df[\"L10H7\"],\n",
    "    y = key_proj_dec_weights_df[\"L10H7\"],\n",
    "    hover_name=query_proj_dec_weights_df.index,\n",
    "    color = query_proj_dec_weights_df.mean(axis=1),\n",
    "    marginal_x=\"histogram\",\n",
    "    marginal_y=\"histogram\",\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacement_hook(mlp_post, hook, encoder):\n",
    "    mlp_post_reconstr = encoder(mlp_post)[0]\n",
    "    return mlp_post_reconstr\n",
    "hook_point = activation_store.cfg.hook_point\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_tokens = activation_store.get_batch_tokens()\n",
    "    _, cache = model.run_with_cache(batch_tokens, prepend_bos=False)\n",
    "    original_act = cache[sparse_autoencoder.cfg.hook_point]#[:,:,sparse_autoencoder.cfg.hook_point_head_index]\n",
    "    sae_out, feature_acts, loss, mse_loss, l1_loss = sparse_autoencoder(\n",
    "        original_act\n",
    "    )\n",
    "    # del cache\n",
    "    \n",
    "    # all round metrics\n",
    "    \n",
    "    # original_act = cache[sparse_autoencoder.cfg.hook_point]#[:,:,sparse_autoencoder.cfg.hook_point_head_index]\n",
    "    # per_token_l2_loss = (sae_out - original_act).pow(2).sum(dim=-1).squeeze()\n",
    "    # total_variance = original_act.pow(2).sum(-1)\n",
    "    # explained_variance = per_token_l2_loss/total_variance\n",
    "\n",
    "    # print(\"explained variance mean:\", explained_variance.mean().item())\n",
    "    # print(\"explained_variance std:\", explained_variance.std().item())\n",
    "    \n",
    "    \n",
    "    # per_token_l2_loss = (sae_out - original_act).pow(2).sum(dim=-1).squeeze()\n",
    "    # px.histogram(per_token_l2_loss.flatten().cpu().numpy()).show()\n",
    "    l0 = (feature_acts > 0).sum(-1).detach()\n",
    "    print(\"average l0\", l0.float().mean().item())\n",
    "    print(\"l0 std\", l0.float().std().item())\n",
    "    px.histogram(l0.flatten().cpu().numpy(), title = \"L0 on Sentences from the Training Data\").show()\n",
    "    \n",
    "    # by position\n",
    "    px.line(l0.float().mean(0).cpu().numpy(), title=\"L0 by Position\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(original_act.flatten(0,1).mean(0).detach().cpu().numpy(), title=\"Original Activation by Position\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_str_tokens(batch_tokens.flatten())\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_act.flatten(0,1)[:,outlier_dimensions].detach().cpu().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_dimensions = (original_act.flatten(0,1).mean(0).detach().cpu().abs() >20).nonzero().squeeze().tolist()\n",
    "control_dimensions = (original_act.flatten(0,1).mean(0).detach().cpu().abs() <1).nonzero().squeeze().tolist()[:len(outlier_dimensions)]\n",
    "df1 = pd.DataFrame(\n",
    "    original_act.flatten(0,1)[:,outlier_dimensions].detach().cpu().numpy(),\n",
    "    columns = [f\"outlier_dim_{i}\" for i in outlier_dimensions],\n",
    "    index = tokens)\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    original_act.flatten(0,1)[:,control_dimensions].detach().cpu().numpy(),\n",
    "    columns = [f\"control_dim_{i}\" for i in control_dimensions],\n",
    "    index = tokens)\n",
    "\n",
    "df = pd.concat([df1, df2], axis=1)\n",
    "px.strip(df[df.index != \"<|endoftext|>\"], log_y=True, hover_name=df.index[df.index != \"<|endoftext|>\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outlier_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(sparse_autoencoder.W_dec[:,outlier_dimensions].detach().cpu(), barmode='overlay', log_y=False,).show()\n",
    "px.histogram(sparse_autoencoder.W_dec[:,control_dimensions].detach().cpu(), barmode='overlay', log_y=False,).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(model.W_out[9,:,outlier_dimensions].detach().cpu(), barmode='overlay', log_y=False,).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(model.W_out[9,:,control_dimensions].detach().cpu(), barmode='overlay', log_y=False,).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[utils.get_act_name(\"mlp_out\", 9)].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Token Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tokens, random_token_groups = generate_random_token_prompt(model, n_random_tokens=5, n_repeat_tokens=2)\n",
    "prompt = model.to_string(random_tokens)\n",
    "token_df, original_cache, cache_reconstructed_query, feature_acts = eval_prompt([prompt], model, sparse_autoencoder, head_idx_override=7)\n",
    "print(token_df.columns)\n",
    "filter_cols = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\"]\n",
    "token_df[filter_cols].tail(10).style.background_gradient(\n",
    "    subset=[\"loss_diff\", \"mse_loss\",\"explained_variance\", \"num_active_features\", \"kl_divergence\"],\n",
    "    cmap=\"coolwarm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD_IDX = 7\n",
    "LAYER_IDX = sparse_autoencoder.cfg.hook_point_layer\n",
    "patterns_original = original_cache[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")\n",
    "patterns_original = original_cache[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_INTEREST = feature_acts.shape[0] - 1 # index from 0.\n",
    "\n",
    "# reload(joseph.visualisation)\n",
    "# from joseph.visualisation import *\n",
    "\n",
    "print(token_df[\"unique_token\"][POS_INTEREST]) # bos gone.\n",
    "plot_line_with_top_10_labels(feature_acts[POS_INTEREST], \"\", 10)\n",
    "\n",
    "vals, inds = torch.topk(feature_acts[POS_INTEREST],5)\n",
    "\n",
    "print(inds)\n",
    "# plot_attn_score_by_feature(model, sparse_autoencoder, inds, original_cache, token_df, pos_interest=POS_INTEREST, vals = vals)\n",
    "# plot_unembed_score_by_feature(model, sparse_autoencoder, inds, token_df, vals=vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pandas columns allowed to be as wide as they want.\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "filter_columns = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\"]\n",
    "# features = torch.randint(0, sparse_autoencoder.cfg.d_sae, (50,))\n",
    "# features = torch.tensor([24519,22818,31246])\n",
    "for feature in inds:\n",
    "    all_token_df[f\"feature_{feature}\"] = all_token_features[:,feature].detach().cpu()\n",
    "    mean_activation = (all_token_df[f\"feature_{feature}\"] > 0).mean()\n",
    "    if mean_activation > 0.001:\n",
    "        print(feature.item(), (all_token_df[f\"feature_{feature}\"] > 0).mean()) # super super dense feature.\n",
    "        display(all_token_df.sort_values(f\"feature_{feature}\", ascending=False)[filter_columns + [f\"feature_{feature}\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_webtext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_token_list = []\n",
    "loss_list = []\n",
    "ablated_loss_list = []\n",
    "# data = get_webtext()\n",
    "\n",
    "NUM_PROMPTS = 30\n",
    "# MAX_PROMPT_LEN = 100\n",
    "# BATCH_SIZE = 10\n",
    "dataframe_list = []\n",
    "feature_acts_list = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(NUM_PROMPTS)):\n",
    "        \n",
    "        # Get Token Data\n",
    "        prompt = data[i]\n",
    "        # new_str = data[BATCH_SIZE * i: BATCH_SIZE * (i + 1)]\n",
    "        \n",
    "\n",
    "        token_df, _, _, feature_acts = eval_prompt(prompt, model, sparse_autoencoder, head_idx_override=7)\n",
    "        feature_acts_list.append(feature_acts)\n",
    "        dataframe_list.append(token_df)\n",
    "        \n",
    "all_token_df = pd.concat(dataframe_list)\n",
    "all_token_df.reset_index(drop=True)\n",
    "all_token_features = torch.cat(feature_acts_list)\n",
    "\n",
    "print(all_token_df.shape)\n",
    "print(all_token_df.columns)\n",
    "all_token_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_mask = (all_token_df.pos.values < 128)\n",
    "all_token_df = all_token_df[all_token_df.pos < 128]\n",
    "all_token_features = all_token_features[torch.tensor(pos_mask)]\n",
    "\n",
    "num_active_features_mask = (all_token_df.num_active_features.values < 100)\n",
    "all_token_df = all_token_df[all_token_df.num_active_features < 100]\n",
    "all_token_features = all_token_features[torch.tensor(num_active_features_mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = (all_token_features > 0).float().mean(dim=0).detach().cpu()\n",
    "log_sparsity = torch.log10(sparsity)\n",
    "print((sparsity > 0).float().mean())\n",
    "print((sparsity > 0).float().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(log_sparsity, nbins=100).show()\n",
    "px.strip(log_sparsity, hover_data=[[i for i in range(sparse_autoencoder.cfg.d_sae)]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(all_token_df.num_active_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_columns = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\"]\n",
    "features = torch.randint(0, sparse_autoencoder.cfg.d_sae, (5,))\n",
    "# features = torch.tensor([24519,22818,31246])\n",
    "for feature in features:\n",
    "    all_token_df[f\"feature_{feature}\"] = all_token_features[:,feature].detach().cpu()\n",
    "    mean_activation = (all_token_df[f\"feature_{feature}\"] > 0).mean()\n",
    "    if mean_activation > 0.0001:\n",
    "        print(feature.item(), (all_token_df[f\"feature_{feature}\"] > 0).mean()) # super super dense feature.\n",
    "        display(all_token_df.sort_values(f\"feature_{feature}\", ascending=False)[filter_columns + [f\"feature_{feature}\"]].head(10))\n",
    "    # else:``\n",
    "        # print(f\"feature {feature.item()} is dead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"When John and Mary went to the shops, John gave the shopping to\"\n",
    "answer = \" Mary\"\n",
    "# prompt = \"All's fair in love and\"\n",
    "# answer = \" war\"\n",
    "# prompt = \" The cat is cute. The dog is\"\n",
    "# prompt = \" Alice, with her keen intelligence and artistic talent, discussed philosophy with Bob, who shared her intellect and also possessed remarkable culinary skills, while\"\n",
    "# answer = \" cute\"\n",
    "model.reset_hooks()\n",
    "utils.test_prompt(prompt, answer, model)\n",
    "\n",
    "HEAD_HOOK_RESULT_NAME = \"blocks.10.attn.hook_z\"\n",
    "LAYER_IDX = sparse_autoencoder.cfg.hook_point_layer\n",
    "HEAD_IDX = 7\n",
    "def hook_to_ablate_head(head_output: Float[Tensor, \"batch seq_len head_idx d_head\"], hook: HookPoint, head = (LAYER_IDX, HEAD_IDX)):\n",
    "    print(hook.layer(), hook.name)\n",
    "    assert head[0] == hook.layer(), f\"{head[0]} != {hook.layer()}\"\n",
    "    assert (\"result\" in hook.name) or (\"q\" in hook.name) or (\"z\" in hook.name)\n",
    "    head_output[:, :, head[1], :] = 0\n",
    "    return head_output\n",
    "\n",
    "with model.hooks(fwd_hooks=[(HEAD_HOOK_RESULT_NAME, hook_to_ablate_head)]):\n",
    "    utils.test_prompt(prompt, answer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joseph\n",
    "reload(joseph.analysis)\n",
    "from joseph.analysis import *\n",
    "\n",
    "\n",
    "token_df, original_cache, cache_reconstructed_query, feature_acts = eval_prompt([prompt + answer], model, sparse_autoencoder, head_idx_override=7)\n",
    "print(token_df.columns)\n",
    "filter_cols = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\",\n",
    "               \"top_k_features\"]\n",
    "token_df[filter_cols].style.background_gradient(\n",
    "    subset=[\"loss_diff\", \"mse_loss\",\"explained_variance\", \"num_active_features\", \"kl_divergence\"],\n",
    "    cmap=\"coolwarm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(feature_acts > 0).float().sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn(patterns, token_df, title=\"\", facet_col_labels = [\"Original\", \"Reconstructed\"]):\n",
    "    '''\n",
    "    # patterns_original = cache[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "    # patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "    patterns_original = cache[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "    patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "    both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "    plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")\n",
    "    \n",
    "    '''\n",
    "    fig = px.imshow(patterns, text_auto=\".2f\", title=title,\n",
    "                    facet_col=0,\n",
    "                    color_continuous_midpoint=0,\n",
    "                    color_continuous_scale=\"RdBu\",\n",
    "                    )\n",
    "    \n",
    "    tickvals = np.arange(patterns.shape[2])\n",
    "    ticktext = token_df[\"unique_token\"].tolist()\n",
    "    \n",
    "    # add tokens as x-ticks and y-ticks, for each facet\n",
    "    # Update x-ticks and y-ticks for each facet\n",
    "    for i in range(len(facet_col_labels)):\n",
    "        fig.update_xaxes(\n",
    "            dict(tickmode='array', tickvals=tickvals, ticktext=ticktext),\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            dict(tickmode='array', tickvals=tickvals, ticktext=ticktext),\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # add facet col labels:\n",
    "    for i, label in enumerate(facet_col_labels):\n",
    "        fig.layout.annotations[i].text = label\n",
    "        fig.layout.annotations[i].font.size = 20\n",
    "        \n",
    "    fig.update_layout(\n",
    "        width=1200,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "LAYER_IDX = sparse_autoencoder.cfg.hook_point_layer\n",
    "HEAD_IDX = 7\n",
    "patterns_original = original_cache[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"attn_scores\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")\n",
    "patterns_original = original_cache[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "patterns_reconstructed = cache_reconstructed_query[utils.get_act_name(\"pattern\", LAYER_IDX)][0,HEAD_IDX].detach().cpu()\n",
    "both_patterns = torch.stack([patterns_original, patterns_reconstructed])\n",
    "plot_attn(both_patterns.detach().cpu(), token_df, title=\"Original and Reconstructed Attention Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_INTEREST = 14# index from 0.\n",
    "print(token_df.shape)\n",
    "print(feature_acts.shape)\n",
    "print(token_df[\"unique_token\"][POS_INTEREST]) \n",
    "feature_acts_of_interest = feature_acts[POS_INTEREST]\n",
    "plot_line_with_top_10_labels(feature_acts_of_interest, \"\", 30)\n",
    "vals, inds = torch.topk(feature_acts_of_interest,64)\n",
    "print(vals.nonzero().shape)\n",
    "print(inds)\n",
    "# plot_attn_score_by_feature(model, sparse_autoencoder, inds, original_cache, token_df, pos_interest=POS_INTEREST, vals = vals)\n",
    "# plot_unembed_score_by_feature(model, sparse_autoencoder, inds, token_df, vals=vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.strip(\n",
    "    (sparse_autoencoder.W_dec @ model.W_U[:,model.to_single_token(\" Mary\")]).detach().cpu().numpy(), \n",
    "    color = [i in inds for i in range(sparse_autoencoder.cfg.d_sae)],\n",
    "    hover_data=[[i for i in range(sparse_autoencoder.cfg.d_sae)]],\n",
    "    ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pandas not to truncate witdth \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# set pandas not to use elipses \n",
    "# pd.set_option('display.max_cols', None)\n",
    "k = 64\n",
    "virtual_weights = (sparse_autoencoder.W_dec[inds]  @ model.W_U)\n",
    "top_k_tokens = virtual_weights.topk(k, dim=-1).indices\n",
    "tokens = pd.DataFrame(top_k_tokens.detach().cpu().T, columns = [f\"feature_{i}\" for i in inds], index = [f\"top_{i}\" for i in range(k)])\n",
    "df = tokens.applymap(lambda x: model.to_string(x))\n",
    "df.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(\n",
    "    x = [str(i.item()) for i in inds],\n",
    "    y = (sparse_autoencoder.W_dec[inds] @ model.W_U[:,model.to_single_token(\" Mary\")]).detach().cpu().numpy()).show()\n",
    "\n",
    "px.bar(\n",
    "    x = [str(i.item()) for i in inds],\n",
    "    y = (sparse_autoencoder.W_dec[inds] @ model.W_U[:,model.to_single_token(\" John\")]).detach().cpu().numpy()).show()\n",
    "\n",
    "px.bar(\n",
    "    x = [str(i.item()) for i in inds],\n",
    "    y = (sparse_autoencoder.W_dec[inds] @ (model.W_U[:,model.to_single_token(\" Mary\")] - model.W_U[:,model.to_single_token(\" John\")] )).detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [] \n",
    "for layer in range(8,12):\n",
    "    \n",
    "    logit_lens_at_layer_10 = original_cache.apply_ln_to_stack(original_cache[utils.get_act_name(\"resid_pre\", layer)]) \n",
    "    logit_lens_at_layer_10 = logit_lens_at_layer_10[0, POS_INTEREST] @ model.W_U\n",
    "    vals, inds = torch.topk(logit_lens_at_layer_10.detach().cpu(), 50)\n",
    "    df_list.append(pd.DataFrame({f\"token_{layer}\": [model.to_string(i) for i in inds], f\"logit_len_{layer}\": vals}).head(30))\n",
    "\n",
    "pd.concat(df_list, axis=1).style.background_gradient(\n",
    "    subset=[f\"logit_len_{layer}\" for layer in range(8,12)],\n",
    "    cmap=\"coolwarm\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_score_by_feature(\n",
    "    model: HookedTransformer, \n",
    "    sparse_autoencoder: SparseAutoencoder, \n",
    "    feature_ids, \n",
    "    cache, \n",
    "    token_df, \n",
    "    pos_interest, \n",
    "    vals = None,\n",
    "    head_index = None):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    layer_index = sparse_autoencoder.cfg.hook_point_layer\n",
    "    head_index = sparse_autoencoder.cfg.hook_point_head_index if head_index is None else head_index\n",
    "\n",
    "    k = cache[f\"blocks.{layer_index}.attn.hook_k\"][0,:(1+pos_interest),head_index]\n",
    "    # score_contributions = sparse_autoencoder.W_enc[:,inds].T @ k.T\n",
    "    score_contributions = (sparse_autoencoder.W_dec[feature_ids] @ model.W_Q[10,7]) @ k.T\n",
    "\n",
    "    if vals is not None:\n",
    "        score_contributions = score_contributions.cpu() * vals.unsqueeze(1).cpu()\n",
    "    fig = px.imshow(score_contributions.detach().cpu(), \n",
    "                    color_continuous_scale=\"RdBu\",\n",
    "                    color_continuous_midpoint=0,\n",
    "                    labels = dict(y=\"Feature\", x=\"Token\"),\n",
    "                    text_auto=\".2f\", title=\"\")\n",
    "    # add xticks and y ticks\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            tickmode='array',\n",
    "            tickvals=1+np.arange(score_contributions.shape[1]),\n",
    "            ticktext=token_df[\"str_tokens\"].tolist(),\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            tickmode='array',\n",
    "            tickvals=np.arange(score_contributions.shape[0]),\n",
    "            ticktext=list(feature_ids.detach().cpu().numpy()),\n",
    "        ),\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "print(POS_INTEREST)\n",
    "fig = plot_attn_score_by_feature(model, sparse_autoencoder, inds[:10], original_cache, token_df, pos_interest=POS_INTEREST+1, head_index = 7, vals = vals[:10])\n",
    "fig.update_layout(width = 1000, height = 1200)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_out, feature_acts, loss, mse_loss, l1_loss = sparse_autoencoder(original_cache[sparse_autoencoder.cfg.hook_point])\n",
    "query_features_firing = (feature_acts[0, POS_INTEREST] > 0)\n",
    "print(query_features_firing.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_feature_projections = (feature_acts[0, :-1] @ sparse_autoencoder.W_dec) @ model.W_K[10,7]\n",
    "tmp = key_feature_projections @ cache_reconstructed_query[\"blocks.10.attn.hook_q\"][0, POS_INTEREST, 7].T\n",
    "px.line(\n",
    "    x = token_df.unique_token.tolist()[1:-1],\n",
    "    y = tmp[1:].detach().cpu().numpy()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pos = 2\n",
    "query_pos = POS_INTEREST\n",
    "\n",
    "key_features_firing = (feature_acts[0, key_pos] > 0)\n",
    "print(key_features_firing.sum())\n",
    "\n",
    "query_features_firing = (feature_acts[0, query_pos] > 0)\n",
    "print(query_features_firing.sum())\n",
    "\n",
    "key_features = (feature_acts[0, key_pos, key_features_firing] * sparse_autoencoder.W_dec[key_features_firing].T[:, None, :]).transpose(2,0)\n",
    "print(key_features.shape)\n",
    "query_features = (feature_acts[0, query_pos, query_features_firing] * sparse_autoencoder.W_dec[query_features_firing].T)\n",
    "print(query_features.shape)\n",
    "scores = key_features @ query_features\n",
    "df = pd.DataFrame(scores[:,0].detach().cpu().numpy(), \n",
    "                  index = key_features_firing.nonzero().squeeze().tolist(), \n",
    "                  columns = query_features_firing.nonzero().squeeze().tolist())\n",
    "fig = px.imshow(df.values, \n",
    "                title = \" Key / Query Feature Scores (ignore LN) for Mary / to\",\n",
    "                color_continuous_midpoint=0, \n",
    "                color_continuous_scale=\"RdBu\")\n",
    "# update xticks and yticks\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=np.arange(df.shape[1]),\n",
    "        ticktext=list(df.columns),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=np.arange(df.shape[0]),\n",
    "        ticktext=list(df.index),\n",
    "    ),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_features = interesting_features + key_features_firing.nonzero().squeeze().tolist()\n",
    "interesting_features = interesting_features + query_features_firing.nonzero().squeeze().tolist()\n",
    "interesting_features = list(set(interesting_features))\n",
    "len(interesting_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pos = 4\n",
    "query_pos = POS_INTEREST\n",
    "\n",
    "key_features_firing = (feature_acts[0, key_pos] > 0)\n",
    "print(key_features_firing.sum())\n",
    "\n",
    "query_features_firing = (feature_acts[0, query_pos] > 0)\n",
    "print(query_features_firing.sum())\n",
    "\n",
    "key_features = (feature_acts[0, key_pos, key_features_firing] * sparse_autoencoder.W_dec[key_features_firing].T[:, None, :]).transpose(2,0)\n",
    "print(key_features.shape)\n",
    "query_features = (feature_acts[0, query_pos, query_features_firing] * sparse_autoencoder.W_dec[query_features_firing].T)\n",
    "print(query_features.shape)\n",
    "scores = key_features @ query_features\n",
    "df = pd.DataFrame(scores[:,0].detach().cpu().numpy(), \n",
    "                  index = key_features_firing.nonzero().squeeze().tolist(), \n",
    "                  columns = query_features_firing.nonzero().squeeze().tolist())\n",
    "fig = px.imshow(df.values, \n",
    "                title = \" Key / Query Feature Scores (ignore LN) for Mary / to\",\n",
    "                color_continuous_midpoint=0, \n",
    "                color_continuous_scale=\"RdBu\")\n",
    "# update xticks and yticks\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=np.arange(df.shape[1]),\n",
    "        ticktext=list(df.columns),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=np.arange(df.shape[0]),\n",
    "        ticktext=list(df.index),\n",
    "    ),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_features = interesting_features + key_features_firing.nonzero().squeeze().tolist()\n",
    "interesting_features = interesting_features + query_features_firing.nonzero().squeeze().tolist()\n",
    "interesting_features = list(set(interesting_features))\n",
    "len(interesting_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_list = []\n",
    "for i in range(128*6):\n",
    "    all_tokens_list.append(activation_store.get_batch_tokens())\n",
    "all_tokens = torch.cat(all_tokens_list, dim=0)\n",
    "print(all_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "all_tokens = all_tokens[torch.randperm(all_tokens.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interventions on Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to experiment with deleting a feature. To do this with the resid pre SAE, we need to generate the query from the resid_pre and then minus the feature and then patch the hook q with the new hook_q."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"When John and Mary went to the shops, John gave the shopping to\"\n",
    "answer = \" Mary\"\n",
    "tokens = model.to_tokens(prompt)\n",
    "\n",
    "token_df, original_cache, cache_reconstructed_query, feature_acts = eval_prompt(prompt, model, sparse_autoencoder, head_idx_override=7)\n",
    "filter_cols = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\",\n",
    "               \"top_k_features\"]\n",
    "token_df[filter_cols].style.background_gradient(\n",
    "    subset=[\"loss_diff\", \"mse_loss\",\"explained_variance\", \"num_active_features\", \"kl_divergence\"],\n",
    "    cmap=\"coolwarm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, inds = torch.topk(feature_acts[-1],30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = sparse_autoencoder.cfg.hook_point_layer\n",
    "head_idx = 7\n",
    "head_hook_query_name = utils.get_act_name(\"q\", layer_idx)\n",
    "\n",
    "\n",
    "attn_df = make_token_df(model, tokens)\n",
    "patterns = original_cache[f\"blocks.{layer_idx}.attn.hook_pattern\"][0,HEAD_IDX].detach().cpu()\n",
    "attn_df[\"original_attn\"] = patterns[-1,]\n",
    "patterns = cache_reconstructed_query[f\"blocks.{layer_idx}.attn.hook_pattern\"][0,HEAD_IDX].detach().cpu()\n",
    "attn_df[\"reconstructed_attn\"] = patterns[-1,]\n",
    "\n",
    "for feature in inds:\n",
    "    features_to_remove = [feature]\n",
    "    original_act = original_cache[sparse_autoencoder.cfg.hook_point]\n",
    "    sae_out, feature_acts, _, mse_loss, _ = sparse_autoencoder(original_act)\n",
    "\n",
    "    # need to generate query\n",
    "    def replacement_hook(resid_pre, hook, new_resid_pre=sae_out):\n",
    "        return new_resid_pre\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(utils.get_act_name(\"resid_pre\", sparse_autoencoder.cfg.hook_point_layer), replacement_hook)]):\n",
    "        _, resid_pre_cache = model.run_with_cache(tokens, return_type=\"loss\", loss_per_token=True)\n",
    "        sae_out = resid_pre_cache[head_hook_query_name][:,:,head_idx]\n",
    "\n",
    "\n",
    "    def remove_feature_hook(hook_in, hook, position=-1, features_to_remove = features_to_remove):\n",
    "        for feature_to_remove in features_to_remove:\n",
    "            # print(feature_acts[0,position,feature_to_remove].item())\n",
    "            feature_dir = feature_acts[0,position,feature_to_remove]*sparse_autoencoder.W_dec[feature_to_remove]\n",
    "            hook_in -= feature_dir\n",
    "        return hook_in\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(sparse_autoencoder.cfg.hook_point, remove_feature_hook)]):\n",
    "        _, cache_removed_feature = model.run_with_cache(tokens, return_type=\"loss\", loss_per_token=True)\n",
    "\n",
    "    patterns = cache_removed_feature[f\"blocks.{layer_idx}.attn.hook_pattern\"][0,HEAD_IDX].detach().cpu()\n",
    "    attn_df[f\"ablated_feature_{feature}\"] = patterns[-1,]\n",
    "\n",
    "fig = px.line(attn_df, \n",
    "            x=\"unique_token\",\n",
    "            y=[\"original_attn\",\"reconstructed_attn\"] + [f\"ablated_feature_{feature}\" for feature in inds],\n",
    "            hover_name=\"str_tokens\", \n",
    "            hover_data=[\"pos\", \"batch\", \"label\"], \n",
    "            title=\"Original vs Reconstructed attention\")\n",
    "\n",
    "# increase figure height\n",
    "fig.update_layout(height=800)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = px.bar(\n",
    "    x= attn_df.T[[2,4]][8:].index,\n",
    "    y=attn_df.T.iloc[8:,4] / attn_df.T.iloc[8:,2],\n",
    "    hover_name= attn_df.T[[2,4]][8:].index,\n",
    "    labels= {\"x\": \"Ablated Feature\", \"y\": \"Mary Attn / John Attn\"})\n",
    "print(attn_df.T.iloc[7,4] / attn_df.T.iloc[7,2])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.line(attn_df, \n",
    "            x=\"unique_token\",\n",
    "            y=[\"original_attn\",\"reconstructed_attn\"] + [f\"ablated_feature_{feature}\" for feature in inds],\n",
    "            hover_name=\"str_tokens\", \n",
    "            hover_data=[\"pos\", \"batch\", \"label\", \"variable\"], \n",
    "            title=\"Original vs Reconstructed attention\")\n",
    "\n",
    "# increase figure height\n",
    "fig.update_layout(height=800)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(attn_df.iloc[4,6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(x = attn_df.iloc[4, 8:].index, y = attn_df.iloc[4, 8:].values).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature DLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp, labels = original_cache.get_full_resid_decomposition(layer =  10, expand_neurons=False, return_labels=True)\n",
    "print(decomp[:,0,-1].shape)\n",
    "\n",
    "test = (decomp[:,0,-1] @ sparse_autoencoder.W_enc[:,inds])\n",
    "# test = (decomp[:,0,-1] @ sparse_autoencoder.W_dec[inds].T) / sparse_autoencoder.W_enc[:,inds].norm(dim=0)\n",
    "tmp = pd.DataFrame(test.detach().cpu().numpy().T, columns = labels, index = [f\"feature_{i}\" for i in inds])\n",
    "px.line(\n",
    "    tmp.T[tmp.T.index.str.contains(\"mlp\")]\n",
    ").show()\n",
    "\n",
    "px.line(\n",
    "    tmp.T[tmp.T.index.str.contains(\"L\")]\n",
    ").show()\n",
    "\n",
    "# test = (decomp[:,0,-1] @ sparse_autoencoder.W_enc[:,inds])\n",
    "test = (decomp[:,0,-1] @ sparse_autoencoder.W_dec[inds].T) / sparse_autoencoder.W_enc[:,inds].norm(dim=0)\n",
    "tmp = pd.DataFrame(test.detach().cpu().numpy().T, columns = labels, index = [f\"feature_{i}\" for i in inds])\n",
    "px.line(\n",
    "    tmp.T[tmp.T.index.str.contains(\"mlp\")]\n",
    ").show()\n",
    "px.line(\n",
    "    tmp.T[tmp.T.index.str.contains(\"L\")]\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Check for Outlier Dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_features = feature_acts[-1] > 0\n",
    "firing_features_labels = [f\"feature_{i}\" for i in firing_features.nonzero().squeeze().tolist()]\n",
    "tmp = pd.DataFrame( sparse_autoencoder.W_dec[firing_features].detach().cpu(), index = firing_features_labels)\n",
    "px.line(\n",
    "   tmp.T,\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_out = feature_acts[-1] @ sparse_autoencoder.W_dec + sparse_autoencoder.b_dec\n",
    "\n",
    "for j in range(10,11):\n",
    "    px.line(\n",
    "        torch.stack(\n",
    "            [original_cache[utils.get_act_name(\"resid_pre\", i)][0,j].detach().cpu().squeeze() for i in range(12)]).squeeze(0).T).show()\n",
    "px.line(sae_out.detach().cpu()).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line((all_token_features > 0).float().mean(0).detach().cpu()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "sim = sparse_autoencoder.W_dec[inds] @ sparse_autoencoder.W_dec[inds].T\n",
    "sim = sim.detach().cpu().numpy()\n",
    "labels = [f\"feature_{i}\" for i in inds]\n",
    "linkage = hierarchy.linkage(sim)\n",
    "dendrogram = hierarchy.dendrogram(linkage, no_plot=True, color_threshold=-np.inf)\n",
    "reordered_ind = list(reversed(dendrogram[\"leaves\"]))\n",
    "reordered_labels = [labels[i] for i in reordered_ind]\n",
    "reordered_arr = sim[reordered_ind][:, reordered_ind]\n",
    "px.imshow(reordered_arr, x=reordered_labels, y=reordered_labels, color_continuous_midpoint=0, color_continuous_scale=\"RdBu\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "labels = [f\"feature_{i}\" for i in inds]\n",
    "linkage = hierarchy.linkage(sim)\n",
    "dendrogram = hierarchy.dendrogram(linkage, no_plot=True, color_threshold=-np.inf)\n",
    "reordered_ind = list(reversed(dendrogram[\"leaves\"]))\n",
    "reordered_labels = [labels[i] for i in reordered_ind]\n",
    "reordered_arr = sim[reordered_ind][:, reordered_ind]\n",
    "px.imshow(reordered_arr, x=reordered_labels, y=reordered_labels, color_continuous_midpoint=0, color_continuous_scale=\"RdBu\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_autoencoder.b_dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_autoencoder.b_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geom_median.torch import compute_geometric_median\n",
    "out = compute_geometric_median(sae_out[0].detach().cpu())\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_out[0].detach().cpu().numpy() - out.median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_webtext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_token_list = []\n",
    "loss_list = []\n",
    "ablated_loss_list = []\n",
    "# data = get_webtext()\n",
    "\n",
    "NUM_PROMPTS = 200\n",
    "# MAX_PROMPT_LEN = 100\n",
    "# BATCH_SIZE = 10\n",
    "dataframe_list = []\n",
    "feature_acts_list = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(NUM_PROMPTS)):\n",
    "        \n",
    "        # Get Token Data\n",
    "        prompt = model.to_string(model.to_tokens(data[i])[0,:128])\n",
    "        token_df, _, _, feature_acts = eval_prompt(prompt, model, sparse_autoencoder, head_idx_override=7)\n",
    "        feature_acts_list.append(feature_acts)\n",
    "        dataframe_list.append(token_df)\n",
    "        \n",
    "all_token_df = pd.concat(dataframe_list)\n",
    "all_token_df.reset_index(drop=True)\n",
    "all_token_features = torch.cat(feature_acts_list)\n",
    "\n",
    "print(all_token_df.shape)\n",
    "print(all_token_df.columns)\n",
    "all_token_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_mask = (all_token_df.pos.values < 128)\n",
    "all_token_df = all_token_df[all_token_df.pos < 128]\n",
    "all_token_features = all_token_features[torch.tensor(pos_mask)]\n",
    "\n",
    "sparsity = (all_token_features > 0).float().mean(dim=0).detach().cpu()\n",
    "log_sparsity = torch.log10(sparsity)\n",
    "print((sparsity > 0).float().mean())\n",
    "print((sparsity > 0).float().sum())\n",
    "\n",
    "num_active_features_mask = (all_token_df.num_active_features.values < 100)\n",
    "all_token_df = all_token_df[all_token_df.num_active_features < 100]\n",
    "all_token_features = all_token_features[torch.tensor(num_active_features_mask)]\n",
    "\n",
    "sparsity = (all_token_features > 0).float().mean(dim=0).detach().cpu()\n",
    "log_sparsity = torch.log10(sparsity)\n",
    "print((sparsity > 0).float().mean())\n",
    "print((sparsity > 0).float().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(log_sparsity, nbins=100).show()\n",
    "px.strip(log_sparsity, hover_data=[[i for i in range(sparse_autoencoder.cfg.d_sae)]]).show()\n",
    "px.histogram(all_token_df.num_active_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_columns = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\"]\n",
    "features = torch.randint(0, sparse_autoencoder.cfg.d_sae, (5,))\n",
    "# features = torch.tensor([24519,22818,31246])\n",
    "for feature in features:\n",
    "    all_token_df[f\"feature_{feature}\"] = all_token_features[:,feature].detach().cpu()\n",
    "    mean_activation = (all_token_df[f\"feature_{feature}\"] > 0).mean()\n",
    "    if mean_activation > 0.0001:\n",
    "        print(feature.item(), (all_token_df[f\"feature_{feature}\"] > 0).mean()) # super super dense feature.\n",
    "        display(all_token_df.sort_values(f\"feature_{feature}\", ascending=False)[filter_columns + [f\"feature_{feature}\"]].head(10))\n",
    "    # else:``\n",
    "        # print(f\"feature {feature.item()} is dead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interventions on Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic Feature Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_analysis.visualizer import data_fns, model_fns, html_fns\n",
    "import importlib\n",
    "\n",
    "importlib.reload(data_fns)\n",
    "importlib.reload(html_fns)\n",
    "from sae_analysis.visualizer.data_fns import get_feature_data, FeatureData\n",
    "\n",
    "# Currently, don't think much more time can be squeezed out of it. Maybe the best saving would be to\n",
    "# make the entire sequence indexing parallelized, but that's possibly not worth it right now.\n",
    "\n",
    "max_batch_size = 512\n",
    "total_batch_size = 4096*6\n",
    "feature_idx = interesting_features\n",
    "# max_batch_size = 512\n",
    "# total_batch_size = 16384\n",
    "# feature_idx = list(range(1000))\n",
    "\n",
    "tokens = all_tokens[:total_batch_size]\n",
    "\n",
    "feature_data = get_feature_data(\n",
    "    encoder=sparse_autoencoder,\n",
    "    # encoder_B=sparse_autoencoder,\n",
    "    model=model,\n",
    "    hook_point=sparse_autoencoder.cfg.hook_point,\n",
    "    hook_point_layer=sparse_autoencoder.cfg.hook_point_layer,\n",
    "    hook_point_head_index=None,\n",
    "    tokens=tokens,\n",
    "    feature_idx=feature_idx,\n",
    "    max_batch_size=max_batch_size,\n",
    "    left_hand_k = 3,\n",
    "    buffer = (5, 5),\n",
    "    n_groups = 10,\n",
    "    first_group_size = 20,\n",
    "    other_groups_size = 5,\n",
    "    verbose = True,\n",
    ")\n",
    "\n",
    "\n",
    "for test_idx in list(interesting_features):\n",
    "    html_str = feature_data[test_idx].get_all_html()\n",
    "    with open(f\"gpt2_small_features/data_{test_idx:04}.html\", \"w\") as f:\n",
    "        f.write(html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
