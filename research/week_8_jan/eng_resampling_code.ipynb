{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import joseph\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "\n",
    "reload(joseph.analysis)\n",
    "reload(joseph.visualisation)\n",
    "reload(joseph.utils)\n",
    "reload(joseph.data)\n",
    "\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "# turn torch grad tracking off\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    # \"tiny-stories-2L-33M\",\n",
    "    # \"attn-only-2l\",\n",
    "    # center_unembed=True,\n",
    "    # center_writing_weights=True,\n",
    "    # fold_ln=True,\n",
    "    # refactor_factored_attn_matrices=True,\n",
    ")\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('jbloom/mats_sae_training_gpt2_small_resid_pre_5/sparse_autoencoder_gpt2-small_blocks.5.hook_resid_pre_49152:v9', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"./artifacts/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152:v28/1100001280_sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_49152.pt\"\n",
    "# path = \"/Users/josephbloom/GithubRepositories/mats_sae_training/artifacts/sparse_autoencoder_gelu-2l_blocks.0.hook_mlp_out_32768:v40/final_sparse_autoencoder_gelu-2l_blocks.0.hook_mlp_out_32768.pt\"\n",
    "# path = \"./artifacts/sparse_autoencoder_gpt2-small_blocks.5.hook_resid_pre_49152:v9/final_sparse_autoencoder_gpt2-small_blocks.5.hook_resid_pre_49152.pt\"\n",
    "sparse_autoencoder = SparseAutoencoder.load_from_pretrained(path)\n",
    "\n",
    "print(sparse_autoencoder.cfg)\n",
    "\n",
    "\n",
    "# sanity check\n",
    "text = \"Many important transition points in the history of science have been moments when science 'zoomed in.' At these points, we develop a visualization or tool that allows us to see the world in a new level of detail, and a new field of science develops to study the world through this lens.\"\n",
    "model(text, return_type=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_training.utils import LMSparseAutoencoderSessionloader\n",
    "model, sparse_autoencoder, activation_store = LMSparseAutoencoderSessionloader.load_session_from_pretrained(\n",
    "    path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def estimate_feature_sparsity_using_shuffled_activations(sparse_autoencoder, activation_store, n_batches):\n",
    "    \n",
    "    total_activations = torch.zeros(sparse_autoencoder.cfg.d_sae).to(sparse_autoencoder.cfg.device)\n",
    "    \n",
    "    pbar = tqdm(range(n_batches))\n",
    "    for _ in pbar:\n",
    "        # batch_tokens = activation_store.get_batch_tokens()\n",
    "        # _, cache = model.run_with_cache(batch_tokens, prepend_bos=False)\n",
    "        # original_act = cache[sparse_autoencoder.cfg.hook_point]\n",
    "        original_act = activation_store.next_batch()\n",
    "        _, feature_acts, _, _, _ = sparse_autoencoder(\n",
    "            original_act\n",
    "        )\n",
    "        # for each batch item, pick 4 random tokens and keep only those\n",
    "        # batch_size x n_tokens x d_sae\n",
    "        # random_tok_indices = torch.randint(0, feature_acts.shape[1], (feature_acts.shape[0], 4))\n",
    "        # feature_acts = feature_acts[torch.arange(feature_acts.shape[0]).unsqueeze(-1), random_tok_indices]\n",
    "        total_activations += feature_acts.sum(0)\n",
    "    \n",
    "    total_tokens = (n_batches * feature_acts.shape[0]\n",
    "                    )\n",
    "    print(\"Total tokens:\", total_tokens)\n",
    "    \n",
    "    return total_activations / total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def estimate_feature_sparsity_using_n_features_per_prompt(\n",
    "    sparse_autoencoder, activation_store, n_batches,\n",
    "    n_tokens_per_prompt=4):\n",
    "    \n",
    "    total_activations = torch.zeros(sparse_autoencoder.cfg.d_sae).to(sparse_autoencoder.cfg.device)\n",
    "    \n",
    "    pbar = tqdm(range(n_batches))\n",
    "    for _ in pbar:\n",
    "        batch_tokens = activation_store.get_batch_tokens()\n",
    "        _, cache = model.run_with_cache(batch_tokens, prepend_bos=False)\n",
    "        original_act = cache[sparse_autoencoder.cfg.hook_point]\n",
    "        _, feature_acts, _, _, _ = sparse_autoencoder(\n",
    "            original_act\n",
    "        )\n",
    "        # for each batch item, pick 4 random tokens and keep only those\n",
    "        # batch_size x n_tokens x d_sae\n",
    "        random_tok_indices = torch.randint(0, feature_acts.shape[1], (feature_acts.shape[0], n_tokens_per_prompt))\n",
    "        feature_acts = feature_acts[torch.arange(feature_acts.shape[0]).unsqueeze(-1), random_tok_indices]\n",
    "        total_activations += feature_acts.flatten(0,1).sum(0)\n",
    "    \n",
    "    total_tokens = (n_batches * feature_acts.shape[0] * n_tokens_per_prompt)\n",
    "    print(\"Total tokens:\", total_tokens)\n",
    "    \n",
    "    return total_activations / total_tokens\n",
    "\n",
    "\n",
    "\n",
    "n_prompts_per_batch, n_tokens_per_prompt = activation_store.get_batch_tokens().shape\n",
    "log_feature_sparsities = []\n",
    "n_dead_features_list = []\n",
    "n_batches_list = [10, 100, 500]\n",
    "n_tokens = [n_prompts_per_batch * n_tokens_per_prompt * i for i in n_batches_list]\n",
    "for n_batches in tqdm(n_batches_list):\n",
    "    feature_sparsity = estimate_feature_sparsity_using_n_features_per_prompt(sparse_autoencoder, activation_store, n_batches).detach().cpu()\n",
    "    n_dead_features = (feature_sparsity == 0).sum()\n",
    "    n_dead_features_list.append(n_dead_features.tolist())\n",
    "    log_feature_sparsities.append(torch.log10(feature_sparsity + 1e-10).tolist())\n",
    "    \n",
    "tmp = pd.DataFrame(log_feature_sparsities, index=n_batches_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    tmp.T,#[tmp.T > -10],\n",
    "    # color = tmp.columns,\n",
    "    title=\"Feature Sparsity\", \n",
    "    barmode=\"overlay\",\n",
    "    facet_col=\"variable\",\n",
    "    # log_y=True,\n",
    "    labels={\"value\": \"log10(sparsity)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line((tmp.T ==  -10).sum() / tmp.shape[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.parallel_coordinates(\n",
    "    tmp.T,\n",
    "    color = tmp.columns,\n",
    "    title=\"Feature Sparsity\", \n",
    "    # range=[-10, 10],\n",
    "    height=1000,\n",
    "    labels={\"value\": \"log10(sparsity)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    x = ((activation_store.storage_buffer > 0).sum(0).log10() + 1e-10).detach().cpu(),\n",
    "    y = tmp.T.iloc[:,-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(tmp.T.corr().values, title=\"Feature Sparsity (320 prompts), 10 times\", labels={\"value\": \"log10(sparsity)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_loss_increases, global_input_activations = sparse_autoencoder.collect_anthropic_resampling_losses(\n",
    "    model, activation_store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_autoencoder.cfg.resample_batches * sparse_autoencoder.cfg.store_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_loss_increases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(global_loss_increases.flatten().detach().cpu(), log_y=False, title=\"Loss Increases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = global_loss_increases / global_loss_increases.sum()\n",
    "px.histogram(probs.flatten().detach().cpu(), log_y=False, title=\"Loss Increases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap \n",
    "import hdbscan\n",
    "\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=4,\n",
    "    min_dist=0.15,\n",
    "    n_components=2,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "ummap_result = reducer.fit_transform(global_input_activations.detach().cpu())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10)\n",
    "clusterer.fit(ummap_result)\n",
    "print(clusterer.labels_)\n",
    "\n",
    "fig = px.scatter(\n",
    "        ummap_result, \n",
    "        x= 0,\n",
    "        y=1,\n",
    "        color=[str(i) for i in clusterer.labels_],\n",
    "        opacity=0.5,\n",
    "        template=\"plotly\",\n",
    "    )\n",
    "\n",
    "# make points larger\n",
    "# fig.update_traces(marker=dict(size=12))\n",
    "\n",
    "# make it wide and tall\n",
    "fig.update_layout(height=800, width=1200)\n",
    "    \n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "fig = px.scatter(\n",
    "        ummap_result, \n",
    "        x= 0,\n",
    "        y=1,\n",
    "        color=global_loss_increases.flatten().detach().cpu(),\n",
    "        # color_continuous_midpoint=0,\n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        opacity=0.5,\n",
    "        template=\"plotly\",\n",
    "    )\n",
    "\n",
    "# make points larger\n",
    "# fig.update_traces(marker=dict(size=12))\n",
    "\n",
    "# make it wide and tall\n",
    "fig.update_layout(height=800, width=1200)\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(clusterer.labels_.max()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(\n",
    "    {\n",
    "        \"global_loss_increases\": global_loss_increases.flatten().detach().cpu(),\n",
    "        \"cluster\": clusterer.labels_,\n",
    "    }\n",
    ")\n",
    "cluster_df = pd.DataFrame(\n",
    "    {\n",
    "        \"cluster\": range(clusterer.labels_.max()+2),\n",
    "        \"n_points\": list(tmp.groupby(\"cluster\").size().values),\n",
    "        \"mean_loss_increase\": tmp.groupby(\"cluster\").mean().values.T[0],\n",
    "        \"std\": tmp.groupby(\"cluster\").std().values.T[0],\n",
    "    }\n",
    ")\n",
    "cluster_df.sort_values(\"mean_loss_increase\", ascending=False).head(10).style.background_gradient(\n",
    "    cmap=\"RdBu\", subset=[\"mean_loss_increase\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_specific_products = global_input_activations.cpu()[clusterer.labels_ == 298,] @ sparse_autoencoder.W_dec.T.detach().cpu()\n",
    "px.histogram(group_specific_products.T, barmode=\"overlay\", title=\"Group Specific Products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer.labels_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_input_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (global_input_activations @ sparse_autoencoder.W_dec.T)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
